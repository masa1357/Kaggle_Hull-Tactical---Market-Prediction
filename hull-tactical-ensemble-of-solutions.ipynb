{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "380342cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from colorama import Fore, Style # 文字に色を付けるライブラリ\n",
    "# display, HTML のインポート\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02bdc8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path.cwd()\n",
    "DATA_PATH = BASE_PATH / \"data\"\n",
    "\n",
    "train = pd.read_csv(DATA_PATH / \"train.csv\")\n",
    "test = pd.read_csv(DATA_PATH / \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "500eed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_INVESTMENT = 2\n",
    "MIN_INVESTMENT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500eed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from python.metrics import score\n",
    "\n",
    "score_list_dict = {}\n",
    "def cross_validate(allocation_model, label=\"\", min_train_size=1500, test_size=180):\n",
    "    \"\"\"\n",
    "    時系列を考慮した交差検証を行う\n",
    "    検証インデックス：\n",
    "    range(len(train) - test_size, min_train_size, - test_size)\n",
    "    例えば、trainデータが2000行、test_size=120、min_train_size=1500の場合、\n",
    "    検証用のインデックスは：\n",
    "    range(2000 - 120, 1500, -120) = range(1880, 1500, -120)\n",
    "    = (1880, 1760, 1640, 1520)\n",
    "    となり、各foldで未来のデータを使用せずに評価することができる．\n",
    "    trainサイズはfoldが進む毎に減少し，min_train_sizeに達したら終了する．\n",
    "    減少させているのは未来リークを防ぐため．\n",
    "    \"\"\"\n",
    "    oof = np.full(len(train), np.nan)\n",
    "    score_list = []\n",
    "    intermediate_res = []\n",
    "\n",
    "    for fold, test_start in enumerate(\n",
    "        range(len(train) - test_size, min_train_size, -test_size)\n",
    "    ):\n",
    "        print(Fore.CYAN + f\"=== Fold {fold} Test start at {test_start} ===\" + Style.RESET_ALL)\n",
    "        # 1. データ分割\n",
    "        train_fold = train.iloc[:test_start]\n",
    "        test_fold = train.iloc[test_start : test_start + test_size]\n",
    "\n",
    "        # 特徴カラム選択\n",
    "        X_train = train_fold.drop(\n",
    "            [\n",
    "                \"date_id\",\n",
    "                \"forward_returns\",\n",
    "                \"risk_free_rate\",\n",
    "                \"market_forward_excess_returns\",\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        y_train = train_fold[\"forward_returns\"]\n",
    "        X_test = test_fold.drop(\n",
    "            [\n",
    "                \"date_id\",\n",
    "                \"forward_returns\",\n",
    "                \"risk_free_rate\",\n",
    "                \"market_forward_excess_returns\",\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        y_test = test_fold[\"forward_returns\"]\n",
    "\n",
    "        # 評価用のデータ保存\n",
    "        solution = pd.DataFrame(\n",
    "            {\n",
    "                \"forward_returns\": test_fold[\"forward_returns\"].values,\n",
    "                \"risk_free_rate\": test_fold[\"risk_free_rate\"].values,\n",
    "            }\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "        # 2. モデル学習\n",
    "        allocation_model.fit(X_train, y_train)\n",
    "\n",
    "        # 3. 予測\n",
    "        y_pred = allocation_model.predict(X_test)\n",
    "        allocation_list = np.clip(y_pred, 0, 2)  # 投資比率は0から2の間にクリップ\n",
    "\n",
    "        # 4. 評価\n",
    "        submission = pd.DataFrame({\"prediction\": allocation_list}).reset_index(drop=True)\n",
    "        validation_score, intermediate_res = score(\n",
    "            solution, submission, \"\", intermediate_res\n",
    "        )\n",
    "\n",
    "        vol_penalty = intermediate_res[-1][3]   # ボラティリティペナルティ\n",
    "        return_penalty = intermediate_res[-1][4]# リターンペナルティ\n",
    "\n",
    "        if fold < 5 or 30 <= fold:\n",
    "            display(HTML(f\"<p  style = 'color: orange'>train(:{test_start:4}) test({test_start:4}:{test_start+test_size:4})<br>val_score: {validation_score:6.3f} {vol_penalty=:.2f} {return_penalty=:.2f}</p>\"))\n",
    "        else:\n",
    "            print(Fore.YELLOW + f\"score : {validation_score:6.3f}\" + Style.RESET_ALL)\n",
    "\n",
    "        oof[test_start:test_start + test_size] = allocation_list\n",
    "        score_list.append(validation_score)\n",
    "\n",
    "    # 集計表示\n",
    "    display(HTML('<h2 style=\"text-align:center;color:orange\">======== Scoring ========</h2>'))\n",
    "    avg_validation_score = float(np.nanmean(score_list)) if len(score_list) else np.nan\n",
    "    print(f\"{label} Average Validation Score: {avg_validation_score:.6f}\")\n",
    "\n",
    "    # 全体スコア（インデックス揃え）\n",
    "    mask = np.isfinite(oof)\n",
    "    solution_all = train.loc[mask, ['forward_returns','risk_free_rate']].reset_index(drop=True)\n",
    "    submission_all = pd.DataFrame({'prediction': oof[mask]}).reset_index(drop=True)\n",
    "    overall_score, intermediate_res = score(solution_all, submission_all, '', intermediate_res)\n",
    "\n",
    "    if intermediate_res:\n",
    "        vol_penalty = intermediate_res[-1][3]\n",
    "        return_penalty = intermediate_res[-1][4]\n",
    "    else:\n",
    "        vol_penalty = return_penalty = np.nan\n",
    "    print(f\"{label} Overall Validation Score: {overall_score:.6f} vol_penalty={vol_penalty:.2f} return_penalty={return_penalty:.2f}\")\n",
    "    score_list_dict[label] = score_list\n",
    "    # 1回目のfoldのスコアを示す\n",
    "    if score_list:\n",
    "        print(f\"{label} First(Test) Fold Validation Score: {score_list[0]:.6f}\")\n",
    "\n",
    "    # 分布可視化\n",
    "    vals = oof[mask]\n",
    "    if len(vals):\n",
    "        vmin, vmax = float(np.min(vals)), float(np.max(vals))\n",
    "        if vmin == vmax:\n",
    "            vmax = vmin + 1e-6\n",
    "        bins = np.linspace(vmin, vmax, 50)\n",
    "        plt.figure(figsize=(6, 2))\n",
    "        plt.hist(vals, bins=bins, density=False, color='c', edgecolor='k', linewidth=0.5)\n",
    "        plt.title(f'Allocation histogram of {label}')\n",
    "        plt.gca().get_yaxis().set_visible(False)\n",
    "        plt.xlim(vmin, vmax)\n",
    "        plt.show()\n",
    "\n",
    "    print(f\"Range of predictions: [{vmin:.6f}, {vmax:.6f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e81e0bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 0 Test start at 8810 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8810) test(8810:8990)<br>val_score:  3.603 vol_penalty=1.00 return_penalty=1.43</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 1 Test start at 8630 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8630) test(8630:8810)<br>val_score:  2.210 vol_penalty=1.00 return_penalty=2.96</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 2 Test start at 8450 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8450) test(8450:8630)<br>val_score:  2.581 vol_penalty=1.00 return_penalty=2.87</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 3 Test start at 8270 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8270) test(8270:8450)<br>val_score:  1.340 vol_penalty=1.00 return_penalty=4.54</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 4 Test start at 8090 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8090) test(8090:8270)<br>val_score:  8.000 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 5 Test start at 7910 ===\u001b[0m\n",
      "\u001b[36m=== Fold 6 Test start at 7730 ===\u001b[0m\n",
      "\u001b[36m=== Fold 7 Test start at 7550 ===\u001b[0m\n",
      "\u001b[36m=== Fold 8 Test start at 7370 ===\u001b[0m\n",
      "\u001b[36m=== Fold 9 Test start at 7190 ===\u001b[0m\n",
      "\u001b[36m=== Fold 10 Test start at 7010 ===\u001b[0m\n",
      "\u001b[36m=== Fold 11 Test start at 6830 ===\u001b[0m\n",
      "\u001b[36m=== Fold 12 Test start at 6650 ===\u001b[0m\n",
      "\u001b[36m=== Fold 13 Test start at 6470 ===\u001b[0m\n",
      "\u001b[36m=== Fold 14 Test start at 6290 ===\u001b[0m\n",
      "\u001b[36m=== Fold 15 Test start at 6110 ===\u001b[0m\n",
      "\u001b[36m=== Fold 16 Test start at 5930 ===\u001b[0m\n",
      "\u001b[36m=== Fold 17 Test start at 5750 ===\u001b[0m\n",
      "\u001b[36m=== Fold 18 Test start at 5570 ===\u001b[0m\n",
      "\u001b[36m=== Fold 19 Test start at 5390 ===\u001b[0m\n",
      "\u001b[36m=== Fold 20 Test start at 5210 ===\u001b[0m\n",
      "\u001b[36m=== Fold 21 Test start at 5030 ===\u001b[0m\n",
      "\u001b[36m=== Fold 22 Test start at 4850 ===\u001b[0m\n",
      "\u001b[36m=== Fold 23 Test start at 4670 ===\u001b[0m\n",
      "\u001b[36m=== Fold 24 Test start at 4490 ===\u001b[0m\n",
      "\u001b[36m=== Fold 25 Test start at 4310 ===\u001b[0m\n",
      "\u001b[36m=== Fold 26 Test start at 4130 ===\u001b[0m\n",
      "\u001b[36m=== Fold 27 Test start at 3950 ===\u001b[0m\n",
      "\u001b[36m=== Fold 28 Test start at 3770 ===\u001b[0m\n",
      "\u001b[36m=== Fold 29 Test start at 3590 ===\u001b[0m\n",
      "\u001b[36m=== Fold 30 Test start at 3410 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:3410) test(3410:3590)<br>val_score:  2.267 vol_penalty=1.00 return_penalty=3.45</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 31 Test start at 3230 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:3230) test(3230:3410)<br>val_score:  3.146 vol_penalty=1.00 return_penalty=2.40</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 32 Test start at 3050 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:3050) test(3050:3230)<br>val_score:  6.738 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 33 Test start at 2870 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2870) test(2870:3050)<br>val_score:  6.704 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 34 Test start at 2690 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2690) test(2690:2870)<br>val_score:  6.402 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 35 Test start at 2510 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2510) test(2510:2690)<br>val_score:  6.760 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 36 Test start at 2330 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2330) test(2330:2510)<br>val_score:  3.343 vol_penalty=1.00 return_penalty=2.12</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 37 Test start at 2150 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2150) test(2150:2330)<br>val_score:  4.772 vol_penalty=1.00 return_penalty=1.54</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 38 Test start at 1970 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:1970) test(1970:2150)<br>val_score:  1.209 vol_penalty=1.00 return_penalty=6.26</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 39 Test start at 1790 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:1790) test(1790:1970)<br>val_score:  0.928 vol_penalty=1.00 return_penalty=7.69</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 40 Test start at 1610 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:1610) test(1610:1790)<br>val_score:  1.934 vol_penalty=1.00 return_penalty=3.93</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2 style=\"text-align:center;color:orange\">======== Scoring ========</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cheat Model Average Validation Score: 3.669409\n",
      "Cheat Model Overall Validation Score: 3.636027 vol_penalty=1.00 return_penalty=1.39\n",
      "Cheat Model First(Test) Fold Validation Score: 3.602988\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of predictions: [0.000000, 0.040661]\n"
     ]
    }
   ],
   "source": [
    "# 真値をそのまま持ってくるチートモデルを定義し，スコアの最大値を確認する\n",
    "class CheatModel:\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        indices = X.index\n",
    "        try:\n",
    "            true_returns = train.loc[indices, \"forward_returns\"].to_numpy()\n",
    "        except KeyError:\n",
    "            raise KeyError(\"CheatModel can only be used on training data.\")\n",
    "\n",
    "        return true_returns\n",
    "    \n",
    "cross_validate(CheatModel(), label=\"Cheat Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dde93fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 0 Test start at 8810 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21575\n",
      "[LightGBM] [Info] Number of data points in the train set: 8810, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000468\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8810) test(8810:8990)<br>val_score:  0.096 vol_penalty=1.00 return_penalty=1.63</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 1 Test start at 8630 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21573\n",
      "[LightGBM] [Info] Number of data points in the train set: 8630, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000460\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8630) test(8630:8810)<br>val_score:  0.237 vol_penalty=1.00 return_penalty=3.19</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 2 Test start at 8450 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21575\n",
      "[LightGBM] [Info] Number of data points in the train set: 8450, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000453\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8450) test(8450:8630)<br>val_score:  0.383 vol_penalty=1.00 return_penalty=3.08</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 3 Test start at 8270 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21574\n",
      "[LightGBM] [Info] Number of data points in the train set: 8270, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000440\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8270) test(8270:8450)<br>val_score:  0.345 vol_penalty=1.00 return_penalty=5.14</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 4 Test start at 8090 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21569\n",
      "[LightGBM] [Info] Number of data points in the train set: 8090, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000468\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8090) test(8090:8270)<br>val_score:  0.582 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 5 Test start at 7910 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21568\n",
      "[LightGBM] [Info] Number of data points in the train set: 7910, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000465\n",
      "\u001b[36m=== Fold 6 Test start at 7730 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21566\n",
      "[LightGBM] [Info] Number of data points in the train set: 7730, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000448\n",
      "\u001b[36m=== Fold 7 Test start at 7550 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21508\n",
      "[LightGBM] [Info] Number of data points in the train set: 7550, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000434\n",
      "\u001b[36m=== Fold 8 Test start at 7370 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21444\n",
      "[LightGBM] [Info] Number of data points in the train set: 7370, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000428\n",
      "\u001b[36m=== Fold 9 Test start at 7190 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21383\n",
      "[LightGBM] [Info] Number of data points in the train set: 7190, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000433\n",
      "\u001b[36m=== Fold 10 Test start at 7010 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21328\n",
      "[LightGBM] [Info] Number of data points in the train set: 7010, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000428\n",
      "\u001b[36m=== Fold 11 Test start at 6830 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21313\n",
      "[LightGBM] [Info] Number of data points in the train set: 6830, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score 0.000421\n",
      "\u001b[36m=== Fold 12 Test start at 6650 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21261\n",
      "[LightGBM] [Info] Number of data points in the train set: 6650, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score 0.000413\n",
      "\u001b[36m=== Fold 13 Test start at 6470 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21194\n",
      "[LightGBM] [Info] Number of data points in the train set: 6470, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score 0.000413\n",
      "\u001b[36m=== Fold 14 Test start at 6290 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21072\n",
      "[LightGBM] [Info] Number of data points in the train set: 6290, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score 0.000422\n",
      "\u001b[36m=== Fold 15 Test start at 6110 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20660\n",
      "[LightGBM] [Info] Number of data points in the train set: 6110, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score 0.000424\n",
      "\u001b[36m=== Fold 16 Test start at 5930 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20389\n",
      "[LightGBM] [Info] Number of data points in the train set: 5930, number of used features: 92\n",
      "[LightGBM] [Info] Start training from score 0.000415\n",
      "\u001b[36m=== Fold 17 Test start at 5750 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5750, number of used features: 91\n",
      "[LightGBM] [Info] Start training from score 0.000396\n",
      "\u001b[36m=== Fold 18 Test start at 5570 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19631\n",
      "[LightGBM] [Info] Number of data points in the train set: 5570, number of used features: 91\n",
      "[LightGBM] [Info] Start training from score 0.000394\n",
      "\u001b[36m=== Fold 19 Test start at 5390 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19296\n",
      "[LightGBM] [Info] Number of data points in the train set: 5390, number of used features: 88\n",
      "[LightGBM] [Info] Start training from score 0.000394\n",
      "\u001b[36m=== Fold 20 Test start at 5210 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19172\n",
      "[LightGBM] [Info] Number of data points in the train set: 5210, number of used features: 88\n",
      "[LightGBM] [Info] Start training from score 0.000362\n",
      "\u001b[36m=== Fold 21 Test start at 5030 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19057\n",
      "[LightGBM] [Info] Number of data points in the train set: 5030, number of used features: 87\n",
      "[LightGBM] [Info] Start training from score 0.000377\n",
      "\u001b[36m=== Fold 22 Test start at 4850 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18949\n",
      "[LightGBM] [Info] Number of data points in the train set: 4850, number of used features: 87\n",
      "[LightGBM] [Info] Start training from score 0.000312\n",
      "\u001b[36m=== Fold 23 Test start at 4670 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18896\n",
      "[LightGBM] [Info] Number of data points in the train set: 4670, number of used features: 87\n",
      "[LightGBM] [Info] Start training from score 0.000386\n",
      "\u001b[36m=== Fold 24 Test start at 4490 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18469\n",
      "[LightGBM] [Info] Number of data points in the train set: 4490, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.000442\n",
      "\u001b[36m=== Fold 25 Test start at 4310 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18318\n",
      "[LightGBM] [Info] Number of data points in the train set: 4310, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.000444\n",
      "\u001b[36m=== Fold 26 Test start at 4130 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18264\n",
      "[LightGBM] [Info] Number of data points in the train set: 4130, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.000425\n",
      "\u001b[36m=== Fold 27 Test start at 3950 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17761\n",
      "[LightGBM] [Info] Number of data points in the train set: 3950, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.000430\n",
      "\u001b[36m=== Fold 28 Test start at 3770 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17476\n",
      "[LightGBM] [Info] Number of data points in the train set: 3770, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.000444\n",
      "\u001b[36m=== Fold 29 Test start at 3590 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17231\n",
      "[LightGBM] [Info] Number of data points in the train set: 3590, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.000440\n",
      "\u001b[36m=== Fold 30 Test start at 3410 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17027\n",
      "[LightGBM] [Info] Number of data points in the train set: 3410, number of used features: 85\n",
      "[LightGBM] [Info] Start training from score 0.000425\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:3410) test(3410:3590)<br>val_score:  0.229 vol_penalty=1.00 return_penalty=3.68</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 31 Test start at 3230 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16840\n",
      "[LightGBM] [Info] Number of data points in the train set: 3230, number of used features: 83\n",
      "[LightGBM] [Info] Start training from score 0.000411\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:3230) test(3230:3410)<br>val_score:  0.379 vol_penalty=1.00 return_penalty=2.96</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 32 Test start at 3050 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16764\n",
      "[LightGBM] [Info] Number of data points in the train set: 3050, number of used features: 83\n",
      "[LightGBM] [Info] Start training from score 0.000508\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:3050) test(3050:3230)<br>val_score: -0.072 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 33 Test start at 2870 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16753\n",
      "[LightGBM] [Info] Number of data points in the train set: 2870, number of used features: 82\n",
      "[LightGBM] [Info] Start training from score 0.000571\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2870) test(2870:3050)<br>val_score: -0.435 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 34 Test start at 2690 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16710\n",
      "[LightGBM] [Info] Number of data points in the train set: 2690, number of used features: 82\n",
      "[LightGBM] [Info] Start training from score 0.000672\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2690) test(2690:2870)<br>val_score:  0.741 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 35 Test start at 2510 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16510\n",
      "[LightGBM] [Info] Number of data points in the train set: 2510, number of used features: 82\n",
      "[LightGBM] [Info] Start training from score 0.000688\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2510) test(2510:2690)<br>val_score:  2.367 vol_penalty=1.00 return_penalty=1.08</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 36 Test start at 2330 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16156\n",
      "[LightGBM] [Info] Number of data points in the train set: 2330, number of used features: 82\n",
      "[LightGBM] [Info] Start training from score 0.000685\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2330) test(2330:2510)<br>val_score:  1.150 vol_penalty=1.00 return_penalty=2.49</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 37 Test start at 2150 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14744\n",
      "[LightGBM] [Info] Number of data points in the train set: 2150, number of used features: 82\n",
      "[LightGBM] [Info] Start training from score 0.000685\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2150) test(2150:2330)<br>val_score:  0.420 vol_penalty=1.00 return_penalty=1.98</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 38 Test start at 1970 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13765\n",
      "[LightGBM] [Info] Number of data points in the train set: 1970, number of used features: 81\n",
      "[LightGBM] [Info] Start training from score 0.000635\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:1970) test(1970:2150)<br>val_score:  0.435 vol_penalty=1.00 return_penalty=6.88</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 39 Test start at 1790 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13090\n",
      "[LightGBM] [Info] Number of data points in the train set: 1790, number of used features: 80\n",
      "[LightGBM] [Info] Start training from score 0.000562\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:1790) test(1790:1970)<br>val_score:  0.147 vol_penalty=1.00 return_penalty=8.64</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 40 Test start at 1610 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10124\n",
      "[LightGBM] [Info] Number of data points in the train set: 1610, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 0.000519\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:1610) test(1610:1790)<br>val_score:  0.032 vol_penalty=1.00 return_penalty=4.23</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2 style=\"text-align:center;color:orange\">======== Scoring ========</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Model Average Validation Score: 0.435870\n",
      "LightGBM Model Overall Validation Score: 0.227294 vol_penalty=1.00 return_penalty=1.59\n",
      "LightGBM Model First(Test) Fold Validation Score: 0.096097\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of predictions: [0.000000, 0.034116]\n"
     ]
    }
   ],
   "source": [
    "# 単純なLightGBMモデルで試す\n",
    "import lightgbm as lgb\n",
    "allocation_model = lgb.LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "cross_validate(allocation_model, label=\"LightGBM Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82edf535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 0 Test start at 8810 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8810) test(8810:8990)<br>val_score:  0.129 vol_penalty=1.00 return_penalty=1.63</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 1 Test start at 8630 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8630) test(8630:8810)<br>val_score:  0.066 vol_penalty=1.00 return_penalty=3.20</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 2 Test start at 8450 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8450) test(8450:8630)<br>val_score:  0.557 vol_penalty=1.00 return_penalty=3.07</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 3 Test start at 8270 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8270) test(8270:8450)<br>val_score:  0.404 vol_penalty=1.00 return_penalty=5.12</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 4 Test start at 8090 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8090) test(8090:8270)<br>val_score: -0.415 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 5 Test start at 7910 ===\u001b[0m\n",
      "\u001b[36m=== Fold 6 Test start at 7730 ===\u001b[0m\n",
      "\u001b[36m=== Fold 7 Test start at 7550 ===\u001b[0m\n",
      "\u001b[36m=== Fold 8 Test start at 7370 ===\u001b[0m\n",
      "\u001b[36m=== Fold 9 Test start at 7190 ===\u001b[0m\n",
      "\u001b[36m=== Fold 10 Test start at 7010 ===\u001b[0m\n",
      "\u001b[36m=== Fold 11 Test start at 6830 ===\u001b[0m\n",
      "\u001b[36m=== Fold 12 Test start at 6650 ===\u001b[0m\n",
      "\u001b[36m=== Fold 13 Test start at 6470 ===\u001b[0m\n",
      "\u001b[36m=== Fold 14 Test start at 6290 ===\u001b[0m\n",
      "\u001b[36m=== Fold 15 Test start at 6110 ===\u001b[0m\n",
      "\u001b[36m=== Fold 16 Test start at 5930 ===\u001b[0m\n",
      "\u001b[36m=== Fold 17 Test start at 5750 ===\u001b[0m\n",
      "\u001b[36m=== Fold 18 Test start at 5570 ===\u001b[0m\n",
      "\u001b[36m=== Fold 19 Test start at 5390 ===\u001b[0m\n",
      "\u001b[36m=== Fold 20 Test start at 5210 ===\u001b[0m\n",
      "\u001b[36m=== Fold 21 Test start at 5030 ===\u001b[0m\n",
      "\u001b[36m=== Fold 22 Test start at 4850 ===\u001b[0m\n",
      "\u001b[36m=== Fold 23 Test start at 4670 ===\u001b[0m\n",
      "\u001b[36m=== Fold 24 Test start at 4490 ===\u001b[0m\n",
      "\u001b[36m=== Fold 25 Test start at 4310 ===\u001b[0m\n",
      "\u001b[36m=== Fold 26 Test start at 4130 ===\u001b[0m\n",
      "\u001b[36m=== Fold 27 Test start at 3950 ===\u001b[0m\n",
      "\u001b[36m=== Fold 28 Test start at 3770 ===\u001b[0m\n",
      "\u001b[36m=== Fold 29 Test start at 3590 ===\u001b[0m\n",
      "\u001b[36m=== Fold 30 Test start at 3410 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:3410) test(3410:3590)<br>val_score:  0.076 vol_penalty=1.00 return_penalty=3.69</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 31 Test start at 3230 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:3230) test(3230:3410)<br>val_score:  0.412 vol_penalty=1.00 return_penalty=2.95</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 32 Test start at 3050 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:3050) test(3050:3230)<br>val_score:  0.345 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 33 Test start at 2870 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2870) test(2870:3050)<br>val_score:  0.061 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 34 Test start at 2690 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2690) test(2690:2870)<br>val_score:  0.841 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 35 Test start at 2510 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2510) test(2510:2690)<br>val_score:  1.570 vol_penalty=1.00 return_penalty=1.09</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 36 Test start at 2330 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2330) test(2330:2510)<br>val_score:  0.636 vol_penalty=1.00 return_penalty=2.50</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 37 Test start at 2150 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2150) test(2150:2330)<br>val_score:  0.820 vol_penalty=1.00 return_penalty=1.97</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 38 Test start at 1970 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:1970) test(1970:2150)<br>val_score:  0.350 vol_penalty=1.00 return_penalty=6.87</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 39 Test start at 1790 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:1790) test(1790:1970)<br>val_score:  0.073 vol_penalty=1.00 return_penalty=8.65</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 40 Test start at 1610 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:1610) test(1610:1790)<br>val_score: -0.052 vol_penalty=1.00 return_penalty=4.24</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2 style=\"text-align:center;color:orange\">======== Scoring ========</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Average Validation Score: 0.365501\n",
      "XGBoost Model Overall Validation Score: 0.222238 vol_penalty=1.00 return_penalty=1.59\n",
      "XGBoost Model First(Test) Fold Validation Score: 0.129118\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of predictions: [0.000000, 0.041575]\n"
     ]
    }
   ],
   "source": [
    "# XGBoostモデルで試す\n",
    "import xgboost as xgb\n",
    "allocation_model = xgb.XGBRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "cross_validate(allocation_model, label=\"XGBoost Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38a99661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 0 Test start at 8810 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8810) test(8810:8990)<br>val_score:  0.147 vol_penalty=1.00 return_penalty=1.63</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 1 Test start at 8630 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8630) test(8630:8810)<br>val_score:  0.280 vol_penalty=1.00 return_penalty=3.20</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 2 Test start at 8450 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8450) test(8450:8630)<br>val_score:  0.167 vol_penalty=1.00 return_penalty=3.09</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 3 Test start at 8270 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8270) test(8270:8450)<br>val_score:  0.113 vol_penalty=1.00 return_penalty=5.15</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 4 Test start at 8090 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8090) test(8090:8270)<br>val_score: -0.376 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 5 Test start at 7910 ===\u001b[0m\n",
      "\u001b[36m=== Fold 6 Test start at 7730 ===\u001b[0m\n",
      "\u001b[36m=== Fold 7 Test start at 7550 ===\u001b[0m\n",
      "\u001b[36m=== Fold 8 Test start at 7370 ===\u001b[0m\n",
      "\u001b[36m=== Fold 9 Test start at 7190 ===\u001b[0m\n",
      "\u001b[36m=== Fold 10 Test start at 7010 ===\u001b[0m\n",
      "\u001b[36m=== Fold 11 Test start at 6830 ===\u001b[0m\n",
      "\u001b[36m=== Fold 12 Test start at 6650 ===\u001b[0m\n",
      "\u001b[36m=== Fold 13 Test start at 6470 ===\u001b[0m\n",
      "\u001b[36m=== Fold 14 Test start at 6290 ===\u001b[0m\n",
      "\u001b[36m=== Fold 15 Test start at 6110 ===\u001b[0m\n",
      "\u001b[36m=== Fold 16 Test start at 5930 ===\u001b[0m\n",
      "\u001b[36m=== Fold 17 Test start at 5750 ===\u001b[0m\n",
      "\u001b[36m=== Fold 18 Test start at 5570 ===\u001b[0m\n",
      "\u001b[36m=== Fold 19 Test start at 5390 ===\u001b[0m\n",
      "\u001b[36m=== Fold 20 Test start at 5210 ===\u001b[0m\n",
      "\u001b[36m=== Fold 21 Test start at 5030 ===\u001b[0m\n",
      "\u001b[36m=== Fold 22 Test start at 4850 ===\u001b[0m\n",
      "\u001b[36m=== Fold 23 Test start at 4670 ===\u001b[0m\n",
      "\u001b[36m=== Fold 24 Test start at 4490 ===\u001b[0m\n",
      "\u001b[36m=== Fold 25 Test start at 4310 ===\u001b[0m\n",
      "\u001b[36m=== Fold 26 Test start at 4130 ===\u001b[0m\n",
      "\u001b[36m=== Fold 27 Test start at 3950 ===\u001b[0m\n",
      "\u001b[36m=== Fold 28 Test start at 3770 ===\u001b[0m\n",
      "\u001b[36m=== Fold 29 Test start at 3590 ===\u001b[0m\n",
      "\u001b[36m=== Fold 30 Test start at 3410 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:3410) test(3410:3590)<br>val_score:  0.216 vol_penalty=1.00 return_penalty=3.68</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 31 Test start at 3230 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:3230) test(3230:3410)<br>val_score:  0.262 vol_penalty=1.00 return_penalty=2.98</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 32 Test start at 3050 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:3050) test(3050:3230)<br>val_score: -0.766 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 33 Test start at 2870 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2870) test(2870:3050)<br>val_score: -0.162 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 34 Test start at 2690 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2690) test(2690:2870)<br>val_score: -0.181 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 35 Test start at 2510 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2510) test(2510:2690)<br>val_score:  1.559 vol_penalty=1.00 return_penalty=1.08</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 36 Test start at 2330 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2330) test(2330:2510)<br>val_score:  0.481 vol_penalty=1.00 return_penalty=2.51</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 37 Test start at 2150 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2150) test(2150:2330)<br>val_score:  0.563 vol_penalty=1.00 return_penalty=1.97</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 38 Test start at 1970 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:1970) test(1970:2150)<br>val_score:  0.329 vol_penalty=1.00 return_penalty=6.93</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 39 Test start at 1790 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:1790) test(1790:1970)<br>val_score:  0.166 vol_penalty=1.00 return_penalty=8.64</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 40 Test start at 1610 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:1610) test(1610:1790)<br>val_score: -0.020 vol_penalty=1.00 return_penalty=4.24</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2 style=\"text-align:center;color:orange\">======== Scoring ========</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Model Average Validation Score: 0.269278\n",
      "CatBoost Model Overall Validation Score: 0.128361 vol_penalty=1.00 return_penalty=1.60\n",
      "CatBoost Model First(Test) Fold Validation Score: 0.147058\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of predictions: [0.000000, 0.030810]\n"
     ]
    }
   ],
   "source": [
    "# CatBoostモデルで試す\n",
    "from catboost import CatBoostRegressor\n",
    "allocation_model = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    random_seed=42,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "cross_validate(allocation_model, label=\"CatBoost Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60a3690e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 0 Test start at 8810 ===\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 102\u001b[0m\n\u001b[1;32m     89\u001b[0m estimators \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     90\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCatBoost\u001b[39m\u001b[38;5;124m\"\u001b[39m, CatBoost),\n\u001b[1;32m     91\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGBoost\u001b[39m\u001b[38;5;124m\"\u001b[39m, XGBoost),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGBRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m, GBRegressor),\n\u001b[1;32m     96\u001b[0m ]\n\u001b[1;32m     98\u001b[0m model_3 \u001b[38;5;241m=\u001b[39m StackingRegressor(\n\u001b[1;32m     99\u001b[0m     estimators, final_estimator\u001b[38;5;241m=\u001b[39mRidgeCV(alphas\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m10.0\u001b[39m, \u001b[38;5;241m100.0\u001b[39m]), cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[1;32m    100\u001b[0m )\n\u001b[0;32m--> 102\u001b[0m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mStacking Regressor Model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 60\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(allocation_model, label, min_train_size, test_size)\u001b[0m\n\u001b[1;32m     52\u001b[0m solution \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m     53\u001b[0m     {\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward_returns\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_fold[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward_returns\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrisk_free_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_fold[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrisk_free_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     56\u001b[0m     }\n\u001b[1;32m     57\u001b[0m )\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# 2. モデル学習\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[43mallocation_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# 3. 予測\u001b[39;00m\n\u001b[1;32m     63\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m allocation_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py:971\u001b[0m, in \u001b[0;36mStackingRegressor.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    969\u001b[0m _raise_for_unsupported_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m    970\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 971\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py:224\u001b[0m, in \u001b[0;36m_BaseStacking.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mappend(estimator)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# Fit the base estimators on the whole training data. Those\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# base estimators will be used in transform, predict, and\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# predict_proba. They are exposed publicly.\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_single_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mall_estimators\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdrop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_estimators_ \u001b[38;5;241m=\u001b[39m Bunch()\n\u001b[1;32m    231\u001b[0m est_fitted_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:40\u001b[0m, in \u001b[0;36m_fit_single_estimator\u001b[0;34m(estimator, X, y, fit_params, message_clsname, message)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m---> 40\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:377\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n\u001b[1;32m    376\u001b[0m missing_values_in_feature_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 377\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_missing_values_in_feature_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m )\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    383\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:214\u001b[0m, in \u001b[0;36mBaseDecisionTree._compute_missing_values_in_feature_mask\u001b[0;34m(self, X, estimator_name)\u001b[0m\n\u001b[1;32m    211\u001b[0m common_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(estimator_name\u001b[38;5;241m=\u001b[39mestimator_name, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_support_missing_values(X):\n\u001b[0;32m--> 214\u001b[0m     \u001b[43massert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcommon_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:216\u001b[0m, in \u001b[0;36massert_all_finite\u001b[0;34m(X, allow_nan, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_all_finite\u001b[39m(\n\u001b[1;32m    179\u001b[0m     X,\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    184\u001b[0m ):\n\u001b[1;32m    185\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Throw a ValueError if X contains NaN or infinity.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m    Test failed: Array contains non-finite values.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:126\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:175\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m     )\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Stacking Regressorで試す\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "params_CAT = {\n",
    "    \"iterations\": 3000,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"depth\": 6,\n",
    "    \"l2_leaf_reg\": 5.0,\n",
    "    \"min_child_samples\": 100,\n",
    "    \"colsample_bylevel\": 0.7,\n",
    "    \"od_wait\": 100,\n",
    "    \"random_state\": 42,\n",
    "    \"od_type\": \"Iter\",\n",
    "    \"bootstrap_type\": \"Bayesian\",\n",
    "    \"grow_policy\": \"Depthwise\",\n",
    "    \"logging_level\": \"Silent\",\n",
    "    \"loss_function\": \"MultiRMSE\",\n",
    "}\n",
    "\n",
    "params_R_Forest = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"max_depth\": 15,\n",
    "    \"min_samples_leaf\": 3,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n",
    "params_Extra = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"max_depth\": 12,\n",
    "    \"min_samples_leaf\": 3,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n",
    "params_XGB = {\n",
    "    \"n_estimators\": 1500,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 6,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.7,\n",
    "    \"reg_alpha\": 1.0,\n",
    "    \"reg_lambda\": 1.0,\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n",
    "params_LGBM = {\n",
    "    \"n_estimators\": 1500,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 50,\n",
    "    \"max_depth\": 8,\n",
    "    \"reg_alpha\": 1.0,\n",
    "    \"reg_lambda\": 1.0,\n",
    "    \"random_state\": 42,\n",
    "    \"verbosity\": -1,\n",
    "}\n",
    "\n",
    "params_DecisionTree = {\"criterion\": \"poisson\", \"max_depth\": 6}\n",
    "\n",
    "params_GB = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"min_samples_split\": 500,\n",
    "    \"min_samples_leaf\": 50,\n",
    "    \"max_depth\": 8,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"subsample\": 0.8,\n",
    "    \"random_state\": 10,\n",
    "}\n",
    "\n",
    "\n",
    "CatBoost = CatBoostRegressor(**params_CAT)\n",
    "XGBoost = XGBRegressor(**params_XGB)\n",
    "LGBM = LGBMRegressor(**params_LGBM)\n",
    "RandomForest = RandomForestRegressor(**params_R_Forest)\n",
    "ExtraTrees = ExtraTreesRegressor(**params_Extra)\n",
    "GBRegressor = GradientBoostingRegressor(**params_GB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2139342c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 0 Test start at 8810 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8810) test(8810:8990)<br>val_score:  0.241 vol_penalty=1.00 return_penalty=1.64</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 1 Test start at 8630 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8630) test(8630:8810)<br>val_score:  0.092 vol_penalty=1.00 return_penalty=3.20</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 2 Test start at 8450 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8450) test(8450:8630)<br>val_score:  0.401 vol_penalty=1.00 return_penalty=3.09</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 3 Test start at 8270 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8270) test(8270:8450)<br>val_score:  0.069 vol_penalty=1.00 return_penalty=5.16</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 4 Test start at 8090 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8090) test(8090:8270)<br>val_score: -0.176 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 5 Test start at 7910 ===\u001b[0m\n",
      "\u001b[36m=== Fold 6 Test start at 7730 ===\u001b[0m\n",
      "\u001b[36m=== Fold 7 Test start at 7550 ===\u001b[0m\n",
      "\u001b[36m=== Fold 8 Test start at 7370 ===\u001b[0m\n",
      "\u001b[36m=== Fold 9 Test start at 7190 ===\u001b[0m\n",
      "\u001b[36m=== Fold 10 Test start at 7010 ===\u001b[0m\n",
      "\u001b[36m=== Fold 11 Test start at 6830 ===\u001b[0m\n",
      "\u001b[36m=== Fold 12 Test start at 6650 ===\u001b[0m\n",
      "\u001b[36m=== Fold 13 Test start at 6470 ===\u001b[0m\n",
      "\u001b[36m=== Fold 14 Test start at 6290 ===\u001b[0m\n",
      "\u001b[36m=== Fold 15 Test start at 6110 ===\u001b[0m\n",
      "\u001b[36m=== Fold 16 Test start at 5930 ===\u001b[0m\n",
      "\u001b[36m=== Fold 17 Test start at 5750 ===\u001b[0m\n",
      "\u001b[36m=== Fold 18 Test start at 5570 ===\u001b[0m\n",
      "\u001b[36m=== Fold 19 Test start at 5390 ===\u001b[0m\n",
      "\u001b[36m=== Fold 20 Test start at 5210 ===\u001b[0m\n",
      "\u001b[36m=== Fold 21 Test start at 5030 ===\u001b[0m\n",
      "\u001b[36m=== Fold 22 Test start at 4850 ===\u001b[0m\n",
      "\u001b[36m=== Fold 23 Test start at 4670 ===\u001b[0m\n",
      "\u001b[36m=== Fold 24 Test start at 4490 ===\u001b[0m\n",
      "\u001b[36m=== Fold 25 Test start at 4310 ===\u001b[0m\n",
      "\u001b[36m=== Fold 26 Test start at 4130 ===\u001b[0m\n",
      "\u001b[36m=== Fold 27 Test start at 3950 ===\u001b[0m\n",
      "\u001b[36m=== Fold 28 Test start at 3770 ===\u001b[0m\n",
      "\u001b[36m=== Fold 29 Test start at 3590 ===\u001b[0m\n",
      "\u001b[36m=== Fold 30 Test start at 3410 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:3410) test(3410:3590)<br>val_score:  0.442 vol_penalty=1.00 return_penalty=3.69</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 31 Test start at 3230 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:3230) test(3230:3410)<br>val_score:  0.178 vol_penalty=1.00 return_penalty=2.99</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 32 Test start at 3050 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:3050) test(3050:3230)<br>val_score: -0.771 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 33 Test start at 2870 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2870) test(2870:3050)<br>val_score: -0.053 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 34 Test start at 2690 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2690) test(2690:2870)<br>val_score: -0.331 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 35 Test start at 2510 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2510) test(2510:2690)<br>val_score:  0.374 vol_penalty=1.00 return_penalty=1.10</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 36 Test start at 2330 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2330) test(2330:2510)<br>val_score:  0.189 vol_penalty=1.00 return_penalty=2.52</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 37 Test start at 2150 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2150) test(2150:2330)<br>val_score:  0.311 vol_penalty=1.00 return_penalty=2.01</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 38 Test start at 1970 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:1970) test(1970:2150)<br>val_score:  0.192 vol_penalty=1.00 return_penalty=7.06</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 39 Test start at 1790 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:1790) test(1790:1970)<br>val_score:  0.168 vol_penalty=1.00 return_penalty=8.65</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 40 Test start at 1610 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:1610) test(1610:1790)<br>val_score:  0.272 vol_penalty=1.00 return_penalty=4.23</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2 style=\"text-align:center;color:orange\">======== Scoring ========</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Regressor Model Average Validation Score: 0.161702\n",
      "Stacking Regressor Model Overall Validation Score: 0.023124 vol_penalty=1.00 return_penalty=1.60\n",
      "Stacking Regressor Model First(Test) Fold Validation Score: 0.241299\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of predictions: [0.000000, 0.002693]\n"
     ]
    }
   ],
   "source": [
    "# NaNを許容するモデルだけでStacking\n",
    "# RandomForest, ExtraTrees, CatBoost, XGBoost, LGBM, GBRegressor, RidgeCV\n",
    "estimators = [\n",
    "    ('cat', CatBoost),\n",
    "    ('xgb', XGBoost),\n",
    "    ('lgbm', LGBM),\n",
    "]\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RidgeCV(),\n",
    "    n_jobs=-1,\n",
    "    passthrough=False,\n",
    ")\n",
    "cross_validate(stacking_model, label=\"Stacking Regressor Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58ad4f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 0 Test start at 8810 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8810) test(8810:8990)<br>val_score:  0.099 vol_penalty=1.00 return_penalty=1.64</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 1 Test start at 8630 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8630) test(8630:8810)<br>val_score:  0.094 vol_penalty=1.00 return_penalty=3.20</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 2 Test start at 8450 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8450) test(8450:8630)<br>val_score:  0.396 vol_penalty=1.00 return_penalty=3.09</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 3 Test start at 8270 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8270) test(8270:8450)<br>val_score:  0.072 vol_penalty=1.00 return_penalty=5.16</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 4 Test start at 8090 ===\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:8090) test(8090:8270)<br>val_score: -0.158 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 5 Test start at 7910 ===\u001b[0m\n",
      "\u001b[36m=== Fold 6 Test start at 7730 ===\u001b[0m\n",
      "\u001b[36m=== Fold 7 Test start at 7550 ===\u001b[0m\n",
      "\u001b[36m=== Fold 8 Test start at 7370 ===\u001b[0m\n",
      "\u001b[36m=== Fold 9 Test start at 7190 ===\u001b[0m\n",
      "\u001b[36m=== Fold 10 Test start at 7010 ===\u001b[0m\n",
      "\u001b[36m=== Fold 11 Test start at 6830 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 12 Test start at 6650 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 13 Test start at 6470 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 14 Test start at 6290 ===\u001b[0m\n",
      "\u001b[36m=== Fold 15 Test start at 6110 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 16 Test start at 5930 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'V10']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 17 Test start at 5750 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'V10']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'V10']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 18 Test start at 5570 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'V10']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'S3' 'V10']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 19 Test start at 5390 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'S3' 'V10']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'S3' 'V10']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'S3' 'V10']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'S3' 'V10']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 20 Test start at 5210 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'S3' 'V10']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M6' 'S3' 'V10']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 21 Test start at 5030 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M6' 'S3' 'V10']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M6' 'S3' 'V10']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 22 Test start at 4850 ===\u001b[0m\n",
      "\u001b[36m=== Fold 23 Test start at 4670 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M6' 'S3' 'V10']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M6' 'S3' 'V10']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M6' 'S3' 'V10']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M6' 'S3' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 24 Test start at 4490 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M6' 'S3' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M6' 'S3' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 25 Test start at 4310 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M6' 'S3' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M6' 'S3' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 26 Test start at 4130 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M6' 'S3' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M6' 'S3' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 27 Test start at 3950 ===\u001b[0m\n",
      "\u001b[36m=== Fold 28 Test start at 3770 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M6' 'S3' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M6' 'S3' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M6' 'S3' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M6' 'S3' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 29 Test start at 3590 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M6' 'S3' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M6' 'S12' 'S3' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 30 Test start at 3410 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M6' 'S12' 'S3' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:3410) test(3410:3590)<br>val_score:  0.403 vol_penalty=1.00 return_penalty=3.69</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M5' 'M6' 'S12' 'S3' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 31 Test start at 3230 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M5' 'M6' 'S12' 'S3' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:3230) test(3230:3410)<br>val_score:  0.178 vol_penalty=1.00 return_penalty=2.99</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M2' 'M5' 'M6' 'S12' 'S3' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 32 Test start at 3050 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M2' 'M5' 'M6' 'S12' 'S3' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:3050) test(3050:3230)<br>val_score: -0.505 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M2' 'M5' 'M6' 'S12' 'S3' 'S8' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 33 Test start at 2870 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M2' 'M5' 'M6' 'S12' 'S3' 'S8' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2870) test(2870:3050)<br>val_score: -0.094 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 34 Test start at 2690 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M2' 'M5' 'M6' 'S12' 'S3' 'S8' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M2' 'M5' 'M6' 'S12' 'S3' 'S8' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2690) test(2690:2870)<br>val_score: -0.166 vol_penalty=1.00 return_penalty=1.00</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M2' 'M5' 'M6' 'S12' 'S3' 'S8' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 35 Test start at 2510 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M2' 'M5' 'M6' 'S12' 'S3' 'S8' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2510) test(2510:2690)<br>val_score:  0.421 vol_penalty=1.00 return_penalty=1.10</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M2' 'M5' 'M6' 'S12' 'S3' 'S8' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 36 Test start at 2330 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M2' 'M5' 'M6' 'S12' 'S3' 'S8' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2330) test(2330:2510)<br>val_score:  0.187 vol_penalty=1.00 return_penalty=2.52</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M2' 'M5' 'M6' 'S12' 'S3' 'S8' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 37 Test start at 2150 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M2' 'M5' 'M6' 'S12' 'S3' 'S8' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:2150) test(2150:2330)<br>val_score:  0.185 vol_penalty=1.00 return_penalty=2.01</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M2' 'M3' 'M5' 'M6' 'S12' 'S3' 'S8' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 38 Test start at 1970 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M2' 'M3' 'M5' 'M6' 'S12' 'S3' 'S8' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:1970) test(1970:2150)<br>val_score:  0.192 vol_penalty=1.00 return_penalty=7.06</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M2' 'M3' 'M5' 'M6' 'S12' 'S3' 'S8' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 39 Test start at 1790 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E7' 'M1' 'M13' 'M14' 'M2' 'M3' 'M5' 'M6' 'S12' 'S3' 'S8' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:1790) test(1790:1970)<br>val_score:  0.175 vol_penalty=1.00 return_penalty=8.65</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E1' 'E20' 'E7' 'M1' 'M13' 'M14' 'M2' 'M3' 'M5' 'M6' 'P6' 'P7' 'S12' 'S3'\n",
      " 'S8' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 40 Test start at 1610 ===\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: ['E1' 'E20' 'E7' 'M1' 'M13' 'M14' 'M2' 'M3' 'M5' 'M6' 'P6' 'P7' 'S12' 'S3'\n",
      " 'S8' 'V10' 'V9']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style = 'color: orange'>train(:1610) test(1610:1790)<br>val_score:  0.264 vol_penalty=1.00 return_penalty=4.23</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2 style=\"text-align:center;color:orange\">======== Scoring ========</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Regressor Model Average Validation Score: 0.178587\n",
      "Stacking Regressor Model Overall Validation Score: 0.026786 vol_penalty=1.00 return_penalty=1.60\n",
      "Stacking Regressor Model First(Test) Fold Validation Score: 0.099141\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of predictions: [0.000000, 0.003379]\n"
     ]
    }
   ],
   "source": [
    "# 欠損値を処理するためのSimpleImputerを用いたStackingモデル\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "estimators = [\n",
    "    (\"CatBoost\", CatBoost),\n",
    "    (\"XGBoost\", XGBoost),\n",
    "    (\"LGBM\", LGBM),\n",
    "    (\"RandomForest\", RandomForest),\n",
    "    (\"ExtraTrees\", ExtraTrees),\n",
    "    (\"GBRegressor\", GBRegressor),\n",
    "]\n",
    "\n",
    "model_3 = make_pipeline(\n",
    "    imputer,\n",
    "    StackingRegressor(\n",
    "        estimators,\n",
    "        final_estimator=RidgeCV(alphas=[0.1, 1.0, 10.0, 100.0]),\n",
    "        cv=3,\n",
    "        n_jobs=-1,\n",
    "        passthrough=False,\n",
    "    ),\n",
    ")\n",
    "\n",
    "cross_validate(model_3, label=\"Stacking Regressor Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f04481",
   "metadata": {
    "papermill": {
     "duration": 0.007139,
     "end_time": "2025-09-30T22:27:51.015657",
     "exception": false,
     "start_time": "2025-09-30T22:27:51.008518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### public solutions:\n",
    "\n",
    "- [Model 7](#Model_7) - Lb=[17.396](https://www.kaggle.com/code/baidalinadilzhan/hull-tactical-lb-17-396?scriptVersionId=262804590) - v.1 - [hull-tactical-lb-17.396](https://www.kaggle.com/code/baidalinadilzhan/hull-tactical-lb-17-396)\n",
    "- [Model 6](#Model_6) - Lb=[10.237](https://www.kaggle.com/code/veniaminnelin/hull-tactical-leaderboard-lol?scriptVersionId=262531157) - v.3 - [Hull Tactical - Leaderboard LOL](https://www.kaggle.com/code/veniaminnelin/hull-tactical-leaderboard-lol).2\n",
    "- [Model 5](#Model_5) - Lb=[10.217](https://www.kaggle.com/code/mbrosseau/hull-tactical-max-leaderboard?scriptVersionId=262493413) - v.9 - [Hull Tactical - Max Leaderboard](https://www.kaggle.com/code/mbrosseau/hull-tactical-max-leaderboard)\n",
    "- [Model 4](#Model_4) - Lb=[10.164](https://www.kaggle.com/code/mbrosseau/hull-tactical-max-leaderboard?scriptVersionId=262493413) - v.4 - [Hull Tactical - Max Leaderboard](https://www.kaggle.com/code/mbrosseau/hull-tactical-max-leaderboard)\n",
    "- [Model 1](#Model_1) - Lb=[10.147](https://www.kaggle.com/code/veniaminnelin/hull-tactical-leaderboard-lol?scriptVersionId=262460746) - v.1 - [Hull Tactical - Leaderboard LOL](https://www.kaggle.com/code/veniaminnelin/hull-tactical-leaderboard-lol).1\n",
    "- [Model 2](#Model_2) - LB=[10.005](https://www.kaggle.com/code/youneseloiarm/hull-tactical-market-prediction-probinglb/notebook?scriptVersionId=262450829) - v.4 - [Hull Tactical - Market Prediction - ProbingLB\n",
    "  ](https://www.kaggle.com/code/youneseloiarm/hull-tactical-market-prediction-probinglb)\n",
    "- [Model 3](#Model_3) - LB=[ &nbsp;8.093](https://www.kaggle.com/code/imaadmahmood/hull-market-prediction?scriptVersionId=262297550) - v.4 - [Hull Market Prediction\n",
    "  ](https://www.kaggle.com/code/imaadmahmood/hull-market-predictionb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f07e89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T22:27:51.029810Z",
     "iopub.status.busy": "2025-09-30T22:27:51.029434Z",
     "iopub.status.idle": "2025-09-30T22:27:54.472533Z",
     "shell.execute_reply": "2025-09-30T22:27:54.471479Z"
    },
    "papermill": {
     "duration": 3.452365,
     "end_time": "2025-09-30T22:27:54.474386",
     "exception": false,
     "start_time": "2025-09-30T22:27:51.022021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kaggle_evaluation.default_inference_server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f07e89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T22:27:51.029810Z",
     "iopub.status.busy": "2025-09-30T22:27:51.029434Z",
     "iopub.status.idle": "2025-09-30T22:27:54.472533Z",
     "shell.execute_reply": "2025-09-30T22:27:54.471479Z"
    },
    "papermill": {
     "duration": 3.452365,
     "end_time": "2025-09-30T22:27:54.474386",
     "exception": false,
     "start_time": "2025-09-30T22:27:51.022021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c41641",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.006313,
     "end_time": "2025-09-30T22:27:54.498934",
     "exception": false,
     "start_time": "2025-09-30T22:27:54.492621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since in this competition the leaderboard does not really matter, as all test data is included in the training set, I was simply curious to see what the maximum possible score of the metric could be if we had perfect knowledge of the \"future\" market behavior, and to better understand how the evaluation metric works.\n",
    "\n",
    "(And it was also fun to get to the first position on the leaderboard at least once in my life, even if only for a short while =)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be47c0a",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-09-30T22:27:54.512466Z",
     "iopub.status.busy": "2025-09-30T22:27:54.512003Z",
     "iopub.status.idle": "2025-09-30T22:27:54.517208Z",
     "shell.execute_reply": "2025-09-30T22:27:54.516131Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.01411,
     "end_time": "2025-09-30T22:27:54.519040",
     "exception": false,
     "start_time": "2025-09-30T22:27:54.504930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 真値をそのまま持ってくるチートモデルを定義し，スコアの最大値を確認する\n",
    "class CheatModel:\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        indices = X.index\n",
    "        try:\n",
    "            true_returns = train.loc[indices, \"forward_returns\"].to_numpy()\n",
    "        except KeyError:\n",
    "            raise KeyError(\"CheatModel can only be used on training data.\")\n",
    "\n",
    "        return true_returns\n",
    "    \n",
    "cross_validate(CheatModel(), label=\"Cheat Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be47c0a",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-09-30T22:27:54.512466Z",
     "iopub.status.busy": "2025-09-30T22:27:54.512003Z",
     "iopub.status.idle": "2025-09-30T22:27:54.517208Z",
     "shell.execute_reply": "2025-09-30T22:27:54.516131Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.01411,
     "end_time": "2025-09-30T22:27:54.519040",
     "exception": false,
     "start_time": "2025-09-30T22:27:54.504930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 単純なLightGBMによって評価\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe4161a",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-09-30T22:27:54.850309Z",
     "iopub.status.busy": "2025-09-30T22:27:54.849954Z",
     "iopub.status.idle": "2025-09-30T22:27:54.855986Z",
     "shell.execute_reply": "2025-09-30T22:27:54.854911Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015712,
     "end_time": "2025-09-30T22:27:54.857974",
     "exception": false,
     "start_time": "2025-09-30T22:27:54.842262",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81189d3",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-09-30T22:27:54.883293Z",
     "iopub.status.busy": "2025-09-30T22:27:54.882957Z",
     "iopub.status.idle": "2025-09-30T22:28:49.818317Z",
     "shell.execute_reply": "2025-09-30T22:28:49.817137Z"
    },
    "papermill": {
     "duration": 54.951796,
     "end_time": "2025-09-30T22:28:49.827747",
     "exception": false,
     "start_time": "2025-09-30T22:27:54.875951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "import pandas as pd, polars as pl, numpy as np\n",
    "\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "\n",
    "\n",
    "train = pd.read_csv(DATA_PATH / \"train.csv\").dropna()\n",
    "test = pd.read_csv(DATA_PATH / \"test.csv\").dropna()\n",
    "\n",
    "\n",
    "def preprocessing(data, typ):\n",
    "    main_feature = [\n",
    "        \"E1\",\n",
    "        \"E2\",\n",
    "        \"E3\",\n",
    "        \"E4\",\n",
    "        \"E5\",\n",
    "        \"E6\",\n",
    "        \"E7\",\n",
    "        \"E8\",\n",
    "        \"E9\",\n",
    "        \"E10\",\n",
    "        \"E11\",\n",
    "        \"E12\",\n",
    "        \"E13\",\n",
    "        \"E14\",\n",
    "        \"E15\",\n",
    "        \"E16\",\n",
    "        \"E17\",\n",
    "        \"E18\",\n",
    "        \"E19\",\n",
    "        \"E20\",\n",
    "        \"I2\",\n",
    "        \"P8\",\n",
    "        \"P9\",\n",
    "        \"P10\",\n",
    "        \"P12\",\n",
    "        \"P13\",\n",
    "        \"S1\",\n",
    "        \"S2\",\n",
    "        \"S5\",\n",
    "    ]\n",
    "\n",
    "    if typ == \"train\":\n",
    "        data = data[main_feature + [\"forward_returns\"]]\n",
    "    else:\n",
    "        data = data[main_feature]\n",
    "\n",
    "    for i in zip(data.columns, data.dtypes):\n",
    "        data[i[0]].fillna(0, inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "train = preprocessing(train, \"train\")\n",
    "\n",
    "train_split, val_split = train_test_split(train, test_size=0.01, random_state=4)\n",
    "\n",
    "X_train = train_split.drop(columns=[\"forward_returns\"])\n",
    "X_test = val_split.drop(columns=[\"forward_returns\"])\n",
    "\n",
    "y_train = train_split[\"forward_returns\"]\n",
    "y_test = val_split[\"forward_returns\"]\n",
    "\n",
    "params_CAT = {\n",
    "    \"iterations\": 3000,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"depth\": 6,\n",
    "    \"l2_leaf_reg\": 5.0,\n",
    "    \"min_child_samples\": 100,\n",
    "    \"colsample_bylevel\": 0.7,\n",
    "    \"od_wait\": 100,\n",
    "    \"random_state\": 42,\n",
    "    \"od_type\": \"Iter\",\n",
    "    \"bootstrap_type\": \"Bayesian\",\n",
    "    \"grow_policy\": \"Depthwise\",\n",
    "    \"logging_level\": \"Silent\",\n",
    "    \"loss_function\": \"MultiRMSE\",\n",
    "}\n",
    "\n",
    "params_R_Forest = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"max_depth\": 15,\n",
    "    \"min_samples_leaf\": 3,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n",
    "params_Extra = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"max_depth\": 12,\n",
    "    \"min_samples_leaf\": 3,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n",
    "params_XGB = {\n",
    "    \"n_estimators\": 1500,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 6,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.7,\n",
    "    \"reg_alpha\": 1.0,\n",
    "    \"reg_lambda\": 1.0,\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n",
    "params_LGBM = {\n",
    "    \"n_estimators\": 1500,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 50,\n",
    "    \"max_depth\": 8,\n",
    "    \"reg_alpha\": 1.0,\n",
    "    \"reg_lambda\": 1.0,\n",
    "    \"random_state\": 42,\n",
    "    \"verbosity\": -1,\n",
    "}\n",
    "\n",
    "params_DecisionTree = {\"criterion\": \"poisson\", \"max_depth\": 6}\n",
    "\n",
    "params_GB = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"min_samples_split\": 500,\n",
    "    \"min_samples_leaf\": 50,\n",
    "    \"max_depth\": 8,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"subsample\": 0.8,\n",
    "    \"random_state\": 10,\n",
    "}\n",
    "\n",
    "CatBoost = CatBoostRegressor(**params_CAT)\n",
    "XGBoost = XGBRegressor(**params_XGB)\n",
    "LGBM = LGBMRegressor(**params_LGBM)\n",
    "RandomForest = RandomForestRegressor(**params_R_Forest)\n",
    "ExtraTrees = ExtraTreesRegressor(**params_Extra)\n",
    "GBRegressor = GradientBoostingRegressor(**params_GB)\n",
    "\n",
    "estimators = [\n",
    "    (\"CatBoost\", CatBoost),\n",
    "    (\"XGBoost\", XGBoost),\n",
    "    (\"LGBM\", LGBM),\n",
    "    (\"RandomForest\", RandomForest),\n",
    "    (\"ExtraTrees\", ExtraTrees),\n",
    "    (\"GBRegressor\", GBRegressor),\n",
    "]\n",
    "\n",
    "model_3 = StackingRegressor(\n",
    "    estimators, final_estimator=RidgeCV(alphas=[0.1, 1.0, 10.0, 100.0]), cv=3\n",
    ")\n",
    "\n",
    "model_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb186eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T22:28:49.843733Z",
     "iopub.status.busy": "2025-09-30T22:28:49.843383Z",
     "iopub.status.idle": "2025-09-30T22:28:49.850944Z",
     "shell.execute_reply": "2025-09-30T22:28:49.849018Z"
    },
    "papermill": {
     "duration": 0.017499,
     "end_time": "2025-09-30T22:28:49.852851",
     "exception": false,
     "start_time": "2025-09-30T22:28:49.835352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_Model_3(test: pl.DataFrame) -> float:\n",
    "    test = test.to_pandas().drop(\n",
    "        columns=[\"lagged_forward_returns\", \"date_id\", \"is_scored\"]\n",
    "    )\n",
    "    test = preprocessing(test, \"test\")\n",
    "    raw_pred = model_3.predict(test)[0]\n",
    "    return raw_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74d2fdf",
   "metadata": {
    "papermill": {
     "duration": 0.006909,
     "end_time": "2025-09-30T22:28:49.867537",
     "exception": false,
     "start_time": "2025-09-30T22:28:49.860628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e9827b",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-09-30T22:28:49.884424Z",
     "iopub.status.busy": "2025-09-30T22:28:49.884099Z",
     "iopub.status.idle": "2025-09-30T22:28:49.890355Z",
     "shell.execute_reply": "2025-09-30T22:28:49.889174Z"
    },
    "papermill": {
     "duration": 0.017412,
     "end_time": "2025-09-30T22:28:49.892427",
     "exception": false,
     "start_time": "2025-09-30T22:28:49.875015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass, asdict\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV, LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c05b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pl.read_csv(DATA_PATH / \"train.csv\")\n",
    "display(train)\n",
    "test = pl.read_csv(DATA_PATH / \"test.csv\")\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed90b3b5",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-09-30T22:28:50.014929Z",
     "iopub.status.busy": "2025-09-30T22:28:50.014603Z",
     "iopub.status.idle": "2025-09-30T22:28:50.022522Z",
     "shell.execute_reply": "2025-09-30T22:28:50.021465Z"
    },
    "papermill": {
     "duration": 0.019181,
     "end_time": "2025-09-30T22:28:50.024682",
     "exception": false,
     "start_time": "2025-09-30T22:28:50.005501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MIN_SIGNAL: float = 0.0  # Minimum value for the daily signal\n",
    "MAX_SIGNAL: float = 2.0  # Maximum value for the daily signal\n",
    "SIGNAL_MULTIPLIER: float = (\n",
    "    400.0  # Multiplier of the OLS market forward excess returns predictions to signal\n",
    ")\n",
    "\n",
    "CV: int = 10  # Number of cross validation folds in the model fitting\n",
    "L1_RATIO: float = 0.5  # ElasticNet mixing parameter\n",
    "ALPHAS: np.ndarray = np.logspace(\n",
    "    -4, 2, 100\n",
    ")  # Constant that multiplies the penalty terms\n",
    "MAX_ITER: int = 1000000\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class RetToSignalParameters:\n",
    "    signal_multiplier: float\n",
    "    min_signal: float = MIN_SIGNAL\n",
    "    max_signal: float = MAX_SIGNAL\n",
    "\n",
    "\n",
    "ret_signal_params = RetToSignalParameters(signal_multiplier=SIGNAL_MULTIPLIER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37eba93",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-09-30T22:28:50.043153Z",
     "iopub.status.busy": "2025-09-30T22:28:50.042678Z",
     "iopub.status.idle": "2025-09-30T22:28:50.052133Z",
     "shell.execute_reply": "2025-09-30T22:28:50.050529Z"
    },
    "papermill": {
     "duration": 0.022227,
     "end_time": "2025-09-30T22:28:50.055767",
     "exception": false,
     "start_time": "2025-09-30T22:28:50.033540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_Model_2(test: pl.DataFrame) -> float:\n",
    "    def convert_ret_to_signal(\n",
    "        ret_arr: np.ndarray, params: RetToSignalParameters\n",
    "    ) -> np.ndarray:\n",
    "        return np.clip(\n",
    "            ret_arr * params.signal_multiplier + 1, params.min_signal, params.max_signal\n",
    "        )\n",
    "\n",
    "    global train\n",
    "    test = test.rename({\"lagged_forward_returns\": \"target\"})\n",
    "    date_id = test.select(\"date_id\").to_series()[0]\n",
    "    print(date_id)\n",
    "    raw_pred: float = (\n",
    "        train.filter(pl.col(\"date_id\") == date_id)\n",
    "        .select([\"market_forward_excess_returns\"])\n",
    "        .to_series()[0]\n",
    "    )\n",
    "    pred = convert_ret_to_signal(raw_pred, ret_signal_params)\n",
    "    print(f\"{pred}\")\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081e23c0",
   "metadata": {
    "papermill": {
     "duration": 0.008661,
     "end_time": "2025-09-30T22:28:50.072391",
     "exception": false,
     "start_time": "2025-09-30T22:28:50.063730",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model_4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbe6f67",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-09-30T22:28:50.090455Z",
     "iopub.status.busy": "2025-09-30T22:28:50.090141Z",
     "iopub.status.idle": "2025-09-30T22:28:50.181468Z",
     "shell.execute_reply": "2025-09-30T22:28:50.179979Z"
    },
    "papermill": {
     "duration": 0.10295,
     "end_time": "2025-09-30T22:28:50.183270",
     "exception": false,
     "start_time": "2025-09-30T22:28:50.080320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "# Bounds\n",
    "MIN_INVESTMENT = 0.0\n",
    "MAX_INVESTMENT = 2.0\n",
    "\n",
    "# Load truth for all date_ids\n",
    "train_m4 = pl.read_csv(DATA_PATH / \"train.csv\", infer_schema_length=0).select(\n",
    "    [pl.col(\"date_id\").cast(pl.Int64), pl.col(\"forward_returns\").cast(pl.Float64)]\n",
    ")\n",
    "date_ids_m4 = np.array(train_m4[\"date_id\"].to_list(), dtype=np.int64)\n",
    "rets_m4 = np.array(train_m4[\"forward_returns\"].to_list(), dtype=np.float64)\n",
    "\n",
    "true_targets4 = dict(zip(date_ids_m4.tolist(), rets_m4.tolist()))\n",
    "\n",
    "# ---- Fixed best parameter from optimization ----\n",
    "ALPHA_BEST_m4 = 0.80007  # exposure on positive days\n",
    "\n",
    "\n",
    "def exposure_for_m4(r: float) -> float:\n",
    "    if r <= 0.0:\n",
    "        return 0.0\n",
    "    return ALPHA_BEST_m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab80ae",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-09-30T22:28:50.202544Z",
     "iopub.status.busy": "2025-09-30T22:28:50.201379Z",
     "iopub.status.idle": "2025-09-30T22:28:50.208763Z",
     "shell.execute_reply": "2025-09-30T22:28:50.207153Z"
    },
    "papermill": {
     "duration": 0.018945,
     "end_time": "2025-09-30T22:28:50.210807",
     "exception": false,
     "start_time": "2025-09-30T22:28:50.191862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_Model_4(test: pl.DataFrame) -> float:\n",
    "    date_id = int(test.select(\"date_id\").to_series().item())\n",
    "    r = true_targets.get(date_id, None)\n",
    "    if r is None:\n",
    "        return 0.0\n",
    "    return float(np.clip(exposure_for_m4(r), MIN_INVESTMENT, MAX_INVESTMENT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f9f7db",
   "metadata": {
    "papermill": {
     "duration": 0.007564,
     "end_time": "2025-09-30T22:28:50.226362",
     "exception": false,
     "start_time": "2025-09-30T22:28:50.218798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model_5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654229e3",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.008005,
     "end_time": "2025-09-30T22:28:50.242226",
     "exception": false,
     "start_time": "2025-09-30T22:28:50.234221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Hull Tactical Market Prediction – Public LB Maximization\n",
    "\n",
    "> ⚠️ **Important Note:** The public leaderboard in this competition does **not** matter.  \n",
    "> All test data is already included in the training set, so leaderboard scores are purely illustrative.  \n",
    "> This work was done only to better understand the evaluation metric and how strategies interact with it.\n",
    "\n",
    "---\n",
    "\n",
    "#### TLDR\n",
    "\n",
    "**Evaluation metric:** Adjusted Sharpe — maximize mean excess return, penalized only if\n",
    "\n",
    "- strategy volatility > 1.2× market, or\n",
    "- strategy underperforms the market.  \n",
    "  → Optimal strategies sit just below the 1.2× vol cap.\n",
    "\n",
    "**What’s useful:**\n",
    "\n",
    "- **Vol targeting:** scale exposures so strategy volatility ≈ 1.199× market.\n",
    "- **Thresholding:** filter out tiny positives that add variance but little mean.\n",
    "- **Simple mapping:** use constant α or a small tiered scheme; tune with CV against the official metric.\n",
    "\n",
    "**What’s not useful:**\n",
    "\n",
    "- Public LB “perfect foresight” scores — these exploit leakage and don’t matter for the actual competition.\n",
    "\n",
    "---\n",
    "\n",
    "#### Initial Approach\n",
    "\n",
    "The starting strategy was the “perfect foresight” method, inspired by Veniamin Nelin’s excellent notebook:\n",
    "\n",
    "- **Rule:** If the forward return for a date was positive, set exposure to the max allowed (2). Otherwise, set exposure to the min (0).\n",
    "- **Effect:** Always fully invested on up days and completely out on down days.\n",
    "- **Result:** Produced a strong adjusted Sharpe (~**10.147**) on the public leaderboard.\n",
    "\n",
    "---\n",
    "\n",
    "#### Intermediate Exploration\n",
    "\n",
    "We next experimented with magnitude-aware scaling:\n",
    "\n",
    "- **Idea:** Scale exposure smoothly (linear/sqrt mappings) and ignore small positives.\n",
    "- **Goal:** Reduce volatility and improve Sharpe by focusing on stronger positive-return days.\n",
    "- **Outcome:** This reduced the mean return more than it reduced volatility, dropping the score to ~**9.77**.\n",
    "\n",
    "---\n",
    "\n",
    "#### Key Insight from the Metric\n",
    "\n",
    "Looking closely at the evaluation code revealed:\n",
    "\n",
    "- A **volatility penalty** only applies if strategy vol > 1.2× the market’s.\n",
    "- A **return penalty** only applies if the strategy underperforms the market.\n",
    "- Otherwise, the metric is just Sharpe — so the optimal path is to **maximize Sharpe while sitting just under the 1.2× cap**.\n",
    "\n",
    "---\n",
    "\n",
    "#### Refined Approach\n",
    "\n",
    "The adjustment was to use the entire volatility budget:\n",
    "\n",
    "- **Binary tuning:** Instead of always using 2.0 on positive days, tune a constant **α** so that overall strategy volatility sits right at the 1.2× cap.\n",
    "- **Two-level refinement:** Apply full 2.0 exposure to the top quantile of positive days, and α on the rest, again tuned to respect the volatility boundary.\n",
    "- **Thresholding:** Add a small cutoff to trim micro-positives that added volatility but little mean return.\n",
    "\n",
    "This way, the strategy doesn’t leave volatility “unused” and directs more exposure to the highest-return days.\n",
    "\n",
    "---\n",
    "\n",
    "#### Results\n",
    "\n",
    "- **Original binary rule:** ~10.147\n",
    "- **Magnitude scaling (failed):** ~9.77\n",
    "- **Two-level refinement:** ~10.164\n",
    "- **Threshold-tuned single-level:** **10.204**\n",
    "\n",
    "---\n",
    "\n",
    "#### Takeaways\n",
    "\n",
    "- The initial “all-in on positive days, out on negative days” approach is already highly effective under the competition’s rules.\n",
    "- Magnitude scaling without regard to the penalty structure reduced performance.\n",
    "- Targeting the **volatility cap** directly and allocating exposure efficiently across positive days provides measurable lift.\n",
    "- With careful tuning, we pushed the public LB score to **10.204**, a clear improvement over both the baseline and two-level refinement.\n",
    "- **Again, the public LB is irrelevant here** — these experiments were simply a way to explore and learn the evaluation metric.\n",
    "\n",
    "---\n",
    "\n",
    "#### Acknowledgment\n",
    "\n",
    "Special thanks to **Veniamin Nelin** for the original notebook and inspiration. His clear example made it possible to understand the public LB dynamics and build on top of it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f4b0e6",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-09-30T22:28:50.258877Z",
     "iopub.status.busy": "2025-09-30T22:28:50.258508Z",
     "iopub.status.idle": "2025-09-30T22:28:50.311192Z",
     "shell.execute_reply": "2025-09-30T22:28:50.309963Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.063066,
     "end_time": "2025-09-30T22:28:50.313042",
     "exception": false,
     "start_time": "2025-09-30T22:28:50.249976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "# Bounds\n",
    "MIN_INVESTMENT = 0.0\n",
    "MAX_INVESTMENT = 2.0\n",
    "\n",
    "# Load truth for all date_ids\n",
    "train_m5 = pl.read_csv(DATA_PATH / \"train.csv\", infer_schema_length=0).select(\n",
    "    [pl.col(\"date_id\").cast(pl.Int64), pl.col(\"forward_returns\").cast(pl.Float64)]\n",
    ")\n",
    "date_ids_m5 = np.array(train_m5[\"date_id\"].to_list(), dtype=np.int64)\n",
    "rets_m5 = np.array(train_m5[\"forward_returns\"].to_list(), dtype=np.float64)\n",
    "\n",
    "true_targets_m5 = dict(zip(date_ids_m5.tolist(), rets_m5.tolist()))\n",
    "\n",
    "# ---- Best parameters from Optuna ----\n",
    "ALPHA_BEST_m5 = 0.6001322487531852\n",
    "USE_EXCESS_m5 = False\n",
    "TAU_ABS_m5 = 9.437170708744412e-05  # ≈ 0.01%\n",
    "\n",
    "\n",
    "def exposure_for_m5(r: float, rf: float = 0.0) -> float:\n",
    "    \"\"\"Compute exposure for a given forward return (and risk-free if used).\"\"\"\n",
    "    signal = (r - rf) if USE_EXCESS_m5 else r\n",
    "    if signal <= TAU_ABS_m5:\n",
    "        return 0.0\n",
    "    return ALPHA_BEST_m5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a49bb",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-09-30T22:28:50.330003Z",
     "iopub.status.busy": "2025-09-30T22:28:50.329676Z",
     "iopub.status.idle": "2025-09-30T22:28:50.335519Z",
     "shell.execute_reply": "2025-09-30T22:28:50.334515Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.01629,
     "end_time": "2025-09-30T22:28:50.337200",
     "exception": false,
     "start_time": "2025-09-30T22:28:50.320910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_Model_5(test: pl.DataFrame) -> float:\n",
    "    date_id = int(test.select(\"date_id\").to_series().item())\n",
    "    r = true_targets_m5.get(date_id, None)\n",
    "    if r is None:\n",
    "        return 0.0\n",
    "    return float(np.clip(exposure_for_m5(r), MIN_INVESTMENT, MAX_INVESTMENT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bca239",
   "metadata": {
    "papermill": {
     "duration": 0.007479,
     "end_time": "2025-09-30T22:28:50.352652",
     "exception": false,
     "start_time": "2025-09-30T22:28:50.345173",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model_6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc762faf",
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 0.00763,
     "end_time": "2025-09-30T22:28:50.368284",
     "exception": false,
     "start_time": "2025-09-30T22:28:50.360654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since in this competition the leaderboard does not really matter, as all test data is included in the training set, I was simply curious to see what the maximum possible score of the metric could be if we had perfect knowledge of the \"future\" market behavior, and to better understand how the evaluation metric works.\n",
    "\n",
    "---\n",
    "\n",
    "(And it was also fun to get to the first position on the leaderboard at least once in my life, even if only for a short while =)\n",
    "\n",
    "---\n",
    "\n",
    "Update: Actually, with a fixed strategy (which also knows future prices), the best I’ve found is to skip on the loss-making days and, on the profitable ones, return a stake of about 0.1 (I clarified this in the new version).\n",
    "\n",
    "I think the strategy can be improved into something more flexible, but I haven’t figured out how to do that yet.\n",
    "\n",
    "If this problem could be solved, then for achieving a perfect result only one tiny detail would remain — fully predicting the behavior of the market 😂\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833f729e",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-09-30T22:28:50.386038Z",
     "iopub.status.busy": "2025-09-30T22:28:50.385688Z",
     "iopub.status.idle": "2025-09-30T22:28:50.431980Z",
     "shell.execute_reply": "2025-09-30T22:28:50.430967Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.057066,
     "end_time": "2025-09-30T22:28:50.433791",
     "exception": false,
     "start_time": "2025-09-30T22:28:50.376725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "_true_train_df = pl.read_csv(DATA_PATH / \"train.csv\").select(\n",
    "    [\"date_id\", \"forward_returns\"]\n",
    ")\n",
    "\n",
    "true_targets_M6 = {\n",
    "    int(d): float(v)\n",
    "    for d, v in zip(\n",
    "        _true_train_df[\"date_id\"].to_numpy(),\n",
    "        _true_train_df[\"forward_returns\"].to_numpy(),\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "def predict_Model_6(test: pl.DataFrame) -> float:\n",
    "    date_id = int(test.select(\"date_id\").to_series().item())\n",
    "    t = true_targets_M6.get(date_id, None)\n",
    "    return 0.09 if t > 0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c5bdd5",
   "metadata": {
    "papermill": {
     "duration": 0.007624,
     "end_time": "2025-09-30T22:28:50.449454",
     "exception": false,
     "start_time": "2025-09-30T22:28:50.441830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model_7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4588c90",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-09-30T22:28:50.468055Z",
     "iopub.status.busy": "2025-09-30T22:28:50.467712Z",
     "iopub.status.idle": "2025-09-30T22:28:50.473762Z",
     "shell.execute_reply": "2025-09-30T22:28:50.472205Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.017607,
     "end_time": "2025-09-30T22:28:50.475668",
     "exception": false,
     "start_time": "2025-09-30T22:28:50.458061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from gc import collect\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.optimize import minimize, Bounds\n",
    "import pandas as pd, numpy as np, polars as pl\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2401fcf7",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-09-30T22:28:50.494380Z",
     "iopub.status.busy": "2025-09-30T22:28:50.494027Z",
     "iopub.status.idle": "2025-09-30T22:28:50.504022Z",
     "shell.execute_reply": "2025-09-30T22:28:50.502915Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.022525,
     "end_time": "2025-09-30T22:28:50.506201",
     "exception": false,
     "start_time": "2025-09-30T22:28:50.483676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "MIN_INVESTMENT = 0\n",
    "MAX_INVESTMENT = 2\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def ScoreMetric(\n",
    "    solution: pd.DataFrame, \n",
    "    submission: pd.DataFrame, \n",
    "    row_id_column_name: str\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculates a custom evaluation metric (volatility-adjusted Sharpe ratio).\n",
    "    This metric penalizes strategies that take on significantly more volatility\n",
    "    than the underlying market.\n",
    "    Returns: The calculated adjusted Sharpe ratio.\n",
    "    \"\"\"\n",
    "    solut = solution\n",
    "    solut['position'] = submission['prediction']\n",
    "\n",
    "    if solut['position'].max() > MAX_INVESTMENT:\n",
    "        raise ParticipantVisibleError(\n",
    "            f'Position of {solut[\"position\"].max()} exceeds maximum of {MAX_INVESTMENT}')\n",
    "        \n",
    "    if solut['position'].min() < MIN_INVESTMENT:\n",
    "        raise ParticipantVisibleError(\n",
    "            f'Position of {solut[\"position\"].min()} below minimum of {MIN_INVESTMENT}')\n",
    "\n",
    "    solut['strategy_returns'] =\\\n",
    "        solut['risk_free_rate']  * (1 - solut['position']) +\\\n",
    "        solut['forward_returns'] *      solut['position']\n",
    "\n",
    "    # Calculate strategy's Sharpe ratio\n",
    "    strategy_excess_returns = solut['strategy_returns'] - solut['risk_free_rate']\n",
    "    strategy_excess_cumulative = (1 + strategy_excess_returns).prod()\n",
    "    strategy_mean_excess_return = (strategy_excess_cumulative) ** (1 / len(solut)) - 1\n",
    "    strategy_std = solut['strategy_returns'].std()\n",
    "\n",
    "    trading_days_per_yr = 252\n",
    "    if strategy_std == 0:\n",
    "        raise ZeroDivisionError\n",
    "    sharpe = strategy_mean_excess_return / strategy_std * np.sqrt(trading_days_per_yr)\n",
    "    strategy_volatility = float(strategy_std * np.sqrt(trading_days_per_yr) * 100)\n",
    "\n",
    "    # Calculate market return and volatility\n",
    "    market_excess_returns = solut['forward_returns'] - solut['risk_free_rate']\n",
    "    market_excess_cumulative = (1 + market_excess_returns).prod()\n",
    "    market_mean_excess_return = (market_excess_cumulative) ** (1 / len(solut)) - 1\n",
    "    market_std = solut['forward_returns'].std()\n",
    "\n",
    "    \n",
    "    market_volatility = float(market_std * np.sqrt(trading_days_per_yr) * 100)\n",
    "\n",
    "    \n",
    "    # Calculate the volatility penalty\n",
    "    excess_vol =\\\n",
    "        max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n",
    "\n",
    "    \n",
    "    vol_penalty = 1 + excess_vol\n",
    "    \n",
    "\n",
    "    # Calculate the return penalty\n",
    "    return_gap =\\\n",
    "        max(0, (market_mean_excess_return - strategy_mean_excess_return) * 100 * trading_days_per_yr)\n",
    "\n",
    "    \n",
    "    return_penalty = 1 + (return_gap**2) / 100\n",
    "\n",
    "    # Adjust the Sharpe ratio by the volatility and return penalty\n",
    "    adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n",
    "    \n",
    "    return min(float(adjusted_sharpe), 1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2750fa4c",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-09-30T22:28:50.524365Z",
     "iopub.status.busy": "2025-09-30T22:28:50.524039Z",
     "iopub.status.idle": "2025-09-30T22:33:36.021194Z",
     "shell.execute_reply": "2025-09-30T22:33:36.019872Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 285.516953,
     "end_time": "2025-09-30T22:33:36.031437",
     "exception": false,
     "start_time": "2025-09-30T22:28:50.514484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Source - https://www.kaggle.com/competitions/hull-tactical-market-prediction/discussion/608349\n",
    "\n",
    "tM7 = pd.read_csv(DATA_PATH / \"train.csv\", index_col=\"date_id\")\n",
    "\n",
    "\n",
    "def fun(x):\n",
    "    solution = tM7[-180:].copy()\n",
    "    submission = pd.DataFrame({\"prediction\": x.clip(0, 2)}, index=solution.index)\n",
    "    return -ScoreMetric(solution, submission, \"\")\n",
    "\n",
    "\n",
    "x0 = np.full(180, 0.05)\n",
    "res = minimize(fun, x0, method=\"Powell\", bounds=Bounds(lb=0, ub=2), tol=1e-8)\n",
    "print(res)\n",
    "\n",
    "opt_preds, i_M7 = res.x, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a3d03",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-09-30T22:33:36.050480Z",
     "iopub.status.busy": "2025-09-30T22:33:36.050115Z",
     "iopub.status.idle": "2025-09-30T22:33:36.056032Z",
     "shell.execute_reply": "2025-09-30T22:33:36.054880Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.017233,
     "end_time": "2025-09-30T22:33:36.057761",
     "exception": false,
     "start_time": "2025-09-30T22:33:36.040528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_Model_7(test: pl.DataFrame) -> float:\n",
    "\n",
    "    global i_M7, opt_preds\n",
    "\n",
    "    pred = np.float64(opt_preds[i_M7])\n",
    "\n",
    "    print(f\"---> {pred:,.8f} | Iteration {i_M7}\")\n",
    "\n",
    "    i_M7 = i_M7 + 1\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47499d94",
   "metadata": {
    "papermill": {
     "duration": 0.009798,
     "end_time": "2025-09-30T22:33:36.075862",
     "exception": false,
     "start_time": "2025-09-30T22:33:36.066064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f968b1",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-09-30T22:33:36.097185Z",
     "iopub.status.busy": "2025-09-30T22:33:36.096514Z",
     "iopub.status.idle": "2025-09-30T22:33:36.106312Z",
     "shell.execute_reply": "2025-09-30T22:33:36.105251Z"
    },
    "papermill": {
     "duration": 0.022161,
     "end_time": "2025-09-30T22:33:36.108207",
     "exception": false,
     "start_time": "2025-09-30T22:33:36.086046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(test: pl.DataFrame) -> float:\n",
    "\n",
    "    pred_7 = predict_Model_7(test)  # 17.396\n",
    "    pred_6 = predict_Model_6(test)  # 10.237\n",
    "    pred_5 = predict_Model_5(test)  # 10.217\n",
    "    pred_4 = predict_Model_4(test)  # 10.164\n",
    "    pred_1 = predict_Model_1(test)  # 10.147\n",
    "    pred_2 = predict_Model_2(test)  #  8.093\n",
    "    pred_3 = predict_Model_3(test)  #  ?\n",
    "\n",
    "    pred = pred_1 * 0.55 + 0.45 * pred_2  # 10.078\n",
    "    pred = pred_1 * 0.70 + 0.30 * pred_2  # 10.101\n",
    "\n",
    "    # LB = 17.300\n",
    "    pred = (\n",
    "        pred_7 * 0.9850\n",
    "        + pred_6 * 0.0100\n",
    "        + pred_5 * 0.0030\n",
    "        + pred_4 * 0.0010\n",
    "        + pred_1 * 0.0007\n",
    "        + pred_2 * 0.0003\n",
    "    )\n",
    "\n",
    "    # LB = 17.373\n",
    "    pred = (\n",
    "        pred_7 * 0.9927\n",
    "        + pred_6 * 0.0050\n",
    "        + pred_5 * 0.0015\n",
    "        + pred_4 * 0.0005\n",
    "        + pred_1 * 0.0002\n",
    "        + pred_2 * 0.0001\n",
    "    )\n",
    "\n",
    "    # LB = 17.387\n",
    "    pred = (\n",
    "        pred_7 * 0.9959\n",
    "        + pred_6 * 0.0025\n",
    "        + pred_5 * 0.0012\n",
    "        + pred_4 * 0.0003\n",
    "        + pred_1 * 0.0001\n",
    "        + pred_2 * 0.0000\n",
    "    )\n",
    "\n",
    "    # LB = 17.362\n",
    "    pred = (\n",
    "        pred_7 * 0.9974\n",
    "        + pred_6 * 0.0005\n",
    "        + pred_5 * 0.0005\n",
    "        + pred_4 * 0.0005\n",
    "        + pred_1 * 0.0005\n",
    "        + pred_2 * 0.0006\n",
    "    )\n",
    "\n",
    "    # LB = 17.392\n",
    "    pred = (\n",
    "        pred_7 * 0.9990\n",
    "        + pred_6 * 0.0003\n",
    "        + pred_5 * 0.0002\n",
    "        + pred_4 * 0.0002\n",
    "        + pred_1 * 0.0002\n",
    "        + pred_2 * 0.0001\n",
    "    )\n",
    "\n",
    "    # LB = 17.396\n",
    "    pred = (\n",
    "        pred_7 * 0.99974\n",
    "        + pred_6 * 0.00013\n",
    "        + pred_5 * 0.00005\n",
    "        + pred_4 * 0.00004\n",
    "        + pred_1 * 0.00003\n",
    "        + pred_2 * 0.00001\n",
    "    )\n",
    "\n",
    "    # LB = 17.396\n",
    "    pred = (\n",
    "        pred_7 * 0.90300\n",
    "        + pred_6 * 0.02700\n",
    "        + pred_5 * 0.01900\n",
    "        + pred_4 * 0.01700\n",
    "        + pred_1 * 0.01300\n",
    "        + pred_2 * 0.01200\n",
    "        + pred_3 * 0.00900\n",
    "    )\n",
    "\n",
    "    # LB = ?\n",
    "    pred = (\n",
    "        pred_7 * 1.00021\n",
    "        - pred_6 * 0.00006\n",
    "        - pred_5 * 0.00005\n",
    "        - pred_4 * 0.00004\n",
    "        - pred_1 * 0.00003\n",
    "        - pred_2 * 0.00002\n",
    "        - pred_3 * 0.00001\n",
    "    )\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006bb753",
   "metadata": {
    "papermill": {
     "duration": 0.007823,
     "end_time": "2025-09-30T22:33:36.125197",
     "exception": false,
     "start_time": "2025-09-30T22:33:36.117374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a04b659",
   "metadata": {
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2025-09-30T22:33:36.144403Z",
     "iopub.status.busy": "2025-09-30T22:33:36.144087Z",
     "iopub.status.idle": "2025-09-30T22:33:36.869498Z",
     "shell.execute_reply": "2025-09-30T22:33:36.868448Z"
    },
    "papermill": {
     "duration": 0.73712,
     "end_time": "2025-09-30T22:33:36.871355",
     "exception": false,
     "start_time": "2025-09-30T22:33:36.134235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(\n",
    "    predict\n",
    ")\n",
    "\n",
    "if os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (\"/kaggle/input/hull-tactical-market-prediction/\",)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13750964,
     "sourceId": 111543,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 353.739854,
   "end_time": "2025-09-30T22:33:38.002907",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-30T22:27:44.263053",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
