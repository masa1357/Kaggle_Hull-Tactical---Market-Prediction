{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4da04843",
   "metadata": {},
   "source": [
    "# Hull Tactical Market Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2358dfe",
   "metadata": {},
   "source": [
    "### Import Libralies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33e2c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "from colorama import Fore, Style\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "# Models\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Submission\n",
    "import polars as pl\n",
    "import kaggle_evaluation.default_inference_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e4c475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "427f4438",
   "metadata": {},
   "outputs": [],
   "source": [
    "INNER_VAL_LEN = 180\n",
    "TRADING_DAYS_PER_YR = 252"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad54b45d",
   "metadata": {},
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b41dbf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ RETURNS TO SIGNAL CONFIGS ============\n",
    "MIN_SIGNAL: float = 0.0                         # Minimum value for the daily signal\n",
    "MAX_SIGNAL: float = 2.0                         # Maximum value for the daily signal\n",
    "SIGNAL_MULTIPLIER: float = 7.5                 # Multiplier of the OLS market forward excess returns predictions to signal\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class RetToSignalParameters:\n",
    "    signal_multiplier: float\n",
    "    min_signal : float = MIN_SIGNAL\n",
    "    max_signal : float = MAX_SIGNAL\n",
    "\n",
    "ret_signal_params = RetToSignalParameters(\n",
    "    signal_multiplier= SIGNAL_MULTIPLIER\n",
    ")\n",
    "\n",
    "def convert_ret_to_signal(\n",
    "    ret_arr: np.ndarray,\n",
    "    params: RetToSignalParameters,\n",
    "    signal_multiplier=None\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts raw model predictions (expected returns) into a trading signal.\n",
    "\n",
    "    Args:\n",
    "        ret_arr (np.ndarray): The array of predicted returns.\n",
    "        params (RetToSignalParameters): Parameters for scaling and clipping the signal.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The resulting trading signal, clipped between min and max values.\n",
    "    \"\"\"\n",
    "\n",
    "    # 予測値を基準に，投資戦略シグナルに変換\n",
    "    # ret * signal_multiplier + 1 を min_signal ~ max_signal の範囲にクリップ\n",
    "    if signal_multiplier is None:\n",
    "        multi = params.signal_multiplier\n",
    "    else:\n",
    "        multi = signal_multiplier\n",
    "\n",
    "    ret = np.clip(\n",
    "        ret_arr * multi + 1,\n",
    "        params.min_signal,\n",
    "        params.max_signal\n",
    "    )\n",
    "\n",
    "    if ret.size < 20:\n",
    "        print(f\"Strategy:\")\n",
    "        for i, value in enumerate(ret): print(f'  {i}: {value:.4f}')\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a444b812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy:\n",
      "  0: 2.0000\n",
      "  1: 1.7500\n",
      "  2: 2.0000\n",
      "  3: 0.0000\n",
      "  4: 2.0000\n"
     ]
    }
   ],
   "source": [
    "# convert_ret_to_signalの動作確認\n",
    "# 20個の乱数(0~1)\n",
    "hoge = convert_ret_to_signal(np.array([5, 0.1, 0.3, -0.2, 1.3]), ret_signal_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfc2f554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ LOAD DATA ============\n",
    "# プラットフォームがkaggleかローカルかで分岐\n",
    "if os.getenv('KAGGLE_KERNEL_RUN_TYPE') is not None:\n",
    "    # Kaggle上\n",
    "    DATA_PATH: Path = Path('/kaggle/input/hull-tactical-market-prediction/')\n",
    "else:\n",
    "    BASE_PATH = Path.cwd()\n",
    "    DATA_PATH: Path = BASE_PATH / 'data'\n",
    "\n",
    "\n",
    "train = pd.read_csv(DATA_PATH / \"train.csv\")\n",
    "test = pd.read_csv(DATA_PATH / \"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ef6c12",
   "metadata": {},
   "source": [
    "### Scoreing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "862dff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticipantVisibleError(Exception):\n",
    "    # Custom error to show messages to participants\n",
    "    pass\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, intermediate_res:list = []) -> float:\n",
    "    \"\"\"\n",
    "    Calculates a custom evaluation metric (volatility-adjusted Sharpe ratio).\n",
    "\n",
    "    This metric penalizes strategies that take on significantly more volatility\n",
    "    than the underlying market.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated adjusted Sharpe ratio.\n",
    "    \"\"\"\n",
    "    solution = solution.copy().reset_index(drop=True)\n",
    "    submission = submission.copy().reset_index(drop=True)\n",
    "    solution['position'] = submission['prediction']\n",
    "\n",
    "    # ありえない値を除外する (0 <= position <= 2)\n",
    "        # 0 means that we don't invest in S & P at all but get only the risk-free rate.\n",
    "        # 1 means that we invest all our money in S & P.\n",
    "        # 2 means that we invest twice our capital in S & P while taking a credit at the risk-free rate.\n",
    "        # -> つまり，普通に預金するか，S&Pに投資するか，S&Pに2倍レバレッジで投資するか（借金）の割合\n",
    "    if solution['position'].max() > MAX_SIGNAL:\n",
    "        raise ParticipantVisibleError(f'Position of {solution[\"position\"].max()} exceeds maximum of {MAX_SIGNAL}')\n",
    "    if solution['position'].min() < MIN_SIGNAL:\n",
    "        raise ParticipantVisibleError(f'Position of {solution[\"position\"].min()} below minimum of {MIN_SIGNAL}')\n",
    "\n",
    "    # Calculate strategy returns\n",
    "    # フェデラルファンド金利(利息) * (1-予測値) + 予測値 * S&P500の翌日のリターン = 戦略のリターン(割合)\n",
    "    solution['strategy_returns'] = solution['risk_free_rate'] * (1 - solution['position']) + solution['position'] * solution['forward_returns']\n",
    "\n",
    "    # Calculate strategy's Sharpe ratio\n",
    "    # リターンとその標準偏差を用いてシャープレシオ（リスクあたりの効率）を計算\n",
    "    strategy_excess_returns = solution['strategy_returns'] - solution['risk_free_rate'] # 超過リターン -> 今回の戦略で得た割合から，リスクフリー時の割合を引いた分\n",
    "    strategy_excess_cumulative = (1 + strategy_excess_returns).prod() # 累積超過リターン -> 全期間の超過リターンをかけ合わせた分(1+で倍率に変換)\n",
    "    strategy_mean_excess_return = (strategy_excess_cumulative) ** (1 / len(solution)) - 1 # 平均超過リターン -> 複利は幾何平均で求める． また，倍率から割合に戻してる\n",
    "    strategy_std = solution['strategy_returns'].std() # リターンの標準偏差\n",
    "\n",
    "    trading_days_per_yr = 252 # 1年あたりの取引日数(固定値)\n",
    "    if strategy_std == 0:\n",
    "        raise ZeroDivisionError\n",
    "    sharpe = strategy_mean_excess_return / strategy_std * np.sqrt(trading_days_per_yr) # 年率換算したシャープレシオ. sqrt(252)をかけることで年率換算している（統計的な性質らしい）\n",
    "    strategy_volatility = float(strategy_std * np.sqrt(trading_days_per_yr) * 100)  # 年率換算したボラティリティ(価格変動率)\n",
    "\n",
    "    # Calculate market return and volatility\n",
    "    # S&P500に投資し続けた場合のリターンとボラティリティを計算\n",
    "    market_excess_returns = solution['forward_returns'] - solution['risk_free_rate'] # S&P500が利息を上回る割合\n",
    "    market_excess_cumulative = (1 + market_excess_returns).prod() # ↑の累積\n",
    "    market_mean_excess_return = (market_excess_cumulative) ** (1 / len(solution)) - 1 # train: 0.0003066067595838273 幾何平均，割合化\n",
    "    market_std = solution['forward_returns'].std() # S&P500のリターンの標準偏差\n",
    "\n",
    "    market_volatility = float(market_std * np.sqrt(trading_days_per_yr) * 100) # train: 16.748459963166347 %\n",
    "\n",
    "    # Calculate the volatility penalty\n",
    "    # ボラティリティペナルティを計算\n",
    "    # -> 市場のボラティリティの1.2倍を超える場合のペナルティ\n",
    "    excess_vol = max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n",
    "    vol_penalty = 1 + excess_vol\n",
    "\n",
    "    # Calculate the return penalty\n",
    "    # リターンペナルティを計算\n",
    "    # -> 市場のリターンを下回る場合のペナルティ\n",
    "    return_gap = max(\n",
    "        0,\n",
    "        (market_mean_excess_return - strategy_mean_excess_return) * 100 * trading_days_per_yr,\n",
    "    )\n",
    "    return_penalty = 1 + (return_gap**2) / 100\n",
    "\n",
    "    # Adjust the Sharpe ratio by the volatility and return penalty\n",
    "    # ペナルティ値の反映\n",
    "    adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n",
    "\n",
    "    # print(\"strategy_excess_returns NaN数:\", solution['strategy_returns'].isna().sum())\n",
    "    # print(\"strategy_std:\", strategy_std)\n",
    "    # print(\"strategy_excess_cumulative:\", strategy_excess_cumulative)\n",
    "    # print(\"market_excess_cumulative:\", market_excess_cumulative)\n",
    "    # print(\"adjusted_sharpe:\", adjusted_sharpe)\n",
    "    try:\n",
    "        intermediate_res.append((strategy_mean_excess_return, strategy_std, sharpe, vol_penalty, return_penalty)) # 各値を記録(debug)\n",
    "        return min(float(adjusted_sharpe), 1_000_000), intermediate_res # float変換，上限100万\n",
    "    except NameError:\n",
    "        return min(float(adjusted_sharpe), 1_000_000) # float変換，上限100万"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836dbfa5",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e17aa132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== ユーティリティ ======\n",
    "def _annualize(sigma_daily: np.ndarray) -> np.ndarray:\n",
    "    return sigma_daily * np.sqrt(252.0)\n",
    "\n",
    "def _rolling_vol_no_leak(fr: pd.Series, window_size: int) -> np.ndarray:\n",
    "    # center=False で未来不参照。序盤は expanding で埋める（過去のみ）\n",
    "    roll = fr.rolling(window=window_size, min_periods=window_size, center=False).std()\n",
    "    expd = fr.expanding(min_periods=2).std()\n",
    "    vol = roll.combine_first(expd).bfill(limit=0)\n",
    "    return vol.to_numpy()\n",
    "\n",
    "def _ewma_vol_series(fr: pd.Series, lam: float = 0.94, min_periods: int = 2) -> np.ndarray:\n",
    "    # adjust=False で逐次（未来を見ない）\n",
    "    var = (fr**2).ewm(alpha=1 - lam, adjust=False, min_periods=min_periods).mean()\n",
    "    return np.sqrt(var).to_numpy()\n",
    "\n",
    "def _make_sigma_for_period(fr_all: np.ndarray, start: int, end: int,\n",
    "                           mode=\"ewma\", lam=0.94, window=30) -> np.ndarray:\n",
    "    \"\"\"[start, end) 用 σ_t を直前の過去を使って作る（リークなし）。\"\"\"\n",
    "    warm = max(window, 20)\n",
    "    prefix_start = max(0, start - warm)\n",
    "    fr_prefix = fr_all[prefix_start:start]\n",
    "    fr_period  = fr_all[start:end]\n",
    "    fr_concat  = np.concatenate([fr_prefix, fr_period])\n",
    "    s = pd.Series(fr_concat)\n",
    "    if mode == \"rolling\":\n",
    "        sigma_all = _rolling_vol_no_leak(s, window_size=window)\n",
    "    elif mode == \"ewma\":\n",
    "        sigma_all = _ewma_vol_series(s, lam=lam, min_periods=max(2, window//4))\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'rolling' or 'ewma'\")\n",
    "    return sigma_all[-(end - start):]\n",
    "\n",
    "# ====== Phase1: 静的校正（z化）＋ soft-clip ======\n",
    "def compute_z_calibration(y_pred_inner: np.ndarray, std_scale: float = 2.0) -> tuple[float, float]:\n",
    "    \"\"\"z 正規化に使う (b, T)。b: 中央値, T: std_scale×標準偏差（ゼロ除算ガード）\"\"\"\n",
    "    y = np.asarray(y_pred_inner).reshape(-1)\n",
    "    b = float(np.median(y))\n",
    "    s = float(np.std(y, ddof=1))\n",
    "    T = max(s * std_scale, 1e-8)\n",
    "    return b, T\n",
    "\n",
    "def choose_m_soft_by_clip(z_inner: np.ndarray,\n",
    "                          T_soft: float = 1.0,\n",
    "                          target_clip: float = 0.22,\n",
    "                          m_bounds: tuple[float, float] = (0.5, 5.0)) -> float:\n",
    "    \"\"\"\n",
    "    inner の z 分布から m を自動選定。\n",
    "    1 + m*tanh(z/T_soft) の 0/2 クリップ率が target_clip に近い m を選ぶ。\n",
    "    \"\"\"\n",
    "    z = np.asarray(z_inner).reshape(-1)\n",
    "\n",
    "    def clip_rate_for(m: float) -> float:\n",
    "        # 端貼り付き条件: m * tanh(|z|/T_soft) >= 1\n",
    "        if m <= 1.0:\n",
    "            return 0.0\n",
    "        thr = T_soft * np.arctanh(1.0 / m)\n",
    "        return float(np.mean(np.abs(z) >= thr))\n",
    "\n",
    "    lo, hi = m_bounds\n",
    "    grid = np.linspace(lo, hi, 20)\n",
    "    vals = np.array([clip_rate_for(m) for m in grid])\n",
    "    m0 = float(grid[np.argmin(np.abs(vals - target_clip))])\n",
    "\n",
    "    m_lo, m_hi = max(lo, m0 - 0.5), min(hi, m0 + 0.5)\n",
    "    for _ in range(12):  # 小さな二分探索\n",
    "        m_mid = 0.5 * (m_lo + m_hi)\n",
    "        cr = clip_rate_for(m_mid)\n",
    "        if cr > target_clip:\n",
    "            m_lo = m_mid\n",
    "        else:\n",
    "            m_hi = m_mid\n",
    "    return float(np.clip(0.5 * (m_lo + m_hi), *m_bounds))\n",
    "\n",
    "def soft_clip_from_z(z: np.ndarray, m: float, T_soft: float,\n",
    "                     min_signal: float, max_signal: float) -> np.ndarray:\n",
    "    \"\"\"p = clip( 1 + m * tanh(z / T_soft), [min_signal, max_signal] )\"\"\"\n",
    "    raw = 1.0 + m * np.tanh(z / T_soft)\n",
    "    return np.clip(raw, min_signal, max_signal)\n",
    "\n",
    "# ====== Phase2: 信頼度連動レバ（|z|） ======\n",
    "def conf_m_from_z_abs(z: np.ndarray, m_lo: float = 1.0, m_hi: float = 3.0, Tm: float = 1.2) -> np.ndarray:\n",
    "    \"\"\"|z| が小さいとき m→m_lo, 大きいと m→m_hi\"\"\"\n",
    "    return m_lo + (m_hi - m_lo) * np.tanh(np.abs(z) / Tm)\n",
    "\n",
    "# ====== Phase4: ボラ・ターゲティング ======\n",
    "def vol_target_scaler(sigma_daily: np.ndarray, gamma: float = 1.10, lev_cap: float = 2.0) -> np.ndarray:\n",
    "    \"\"\"ℓ_t = min(lev_cap, σ* / (σ_t^ann + eps)), σ* = gamma * median(σ^ann)\"\"\"\n",
    "    sigma_ann = _annualize(sigma_daily)\n",
    "    sigma_ref = np.median(sigma_ann)\n",
    "    sigma_star = gamma * sigma_ref\n",
    "    return np.minimum(lev_cap, sigma_star / (sigma_ann + 1e-6))\n",
    "\n",
    "# ====== 推論パイプ（z → soft-clip → confidence → vol target） ======\n",
    "def make_allocation_from_predictions(\n",
    "    y_pred: np.ndarray,\n",
    "    *,\n",
    "    b_z: float,\n",
    "    T_z: float,\n",
    "    T_soft: float,\n",
    "    m_soft: float,\n",
    "    conf_params: tuple[float, float, float],  # (m_lo, m_hi, Tm)\n",
    "    sigma_daily: np.ndarray | None,\n",
    "    gamma: float,\n",
    "    lev_cap: float,\n",
    "    min_signal: float,\n",
    "    max_signal: float\n",
    ") -> np.ndarray:\n",
    "    \"\"\"1本のパイプで allocation を作る（リークしない前提の σ を渡すこと）。\"\"\"\n",
    "    # z 化\n",
    "    z = (y_pred - b_z) / T_z\n",
    "    # 基本 soft-clip（中心1.0）\n",
    "    p_soft = soft_clip_from_z(z, m=m_soft, T_soft=T_soft,\n",
    "                              min_signal=min_signal, max_signal=max_signal)\n",
    "    # 信頼度連動レバ（弱めから開始）\n",
    "    m_lo, m_hi, Tm = conf_params\n",
    "    m_conf = conf_m_from_z_abs(z, m_lo=m_lo, m_hi=m_hi, Tm=Tm)\n",
    "    p_conf = np.clip(1.0 + (m_conf * np.tanh(z / T_soft)), min_signal, max_signal)\n",
    "\n",
    "    # 2段構えにしたい場合は p_soft と p_conf を混合しても良いが、まずは p_conf を採用\n",
    "    p = p_conf\n",
    "\n",
    "    # ボラ・ターゲティング（σが渡されない場合はスキップ）\n",
    "    if sigma_daily is not None:\n",
    "        ell_t = vol_target_scaler(sigma_daily, gamma=gamma, lev_cap=lev_cap)\n",
    "        p = np.clip((p - 1.0) * ell_t + 1.0, min_signal, max_signal)\n",
    "\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86800ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_indices(start: int, end: int, n_slices: int) -> list[tuple[int,int]]:\n",
    "    length = end - start\n",
    "    base = length // n_slices\n",
    "    rem  = length % n_slices\n",
    "    spans = []\n",
    "    cur = start\n",
    "    for i in range(n_slices):\n",
    "        w = base + (1 if i < rem else 0)\n",
    "        spans.append((cur, cur + w))\n",
    "        cur += w\n",
    "    return spans\n",
    "\n",
    "def select_hparams_pessimistic(\n",
    "    *,\n",
    "    # calib の絶対インデックス\n",
    "    calib_abs_start: int,\n",
    "    calib_abs_end: int,\n",
    "    # calib 期間の予測\n",
    "    y_pred_calib: np.ndarray,\n",
    "    # calib 期間のソリューション DF（forward_returns, risk_free_rate）\n",
    "    sol_calib: pd.DataFrame,\n",
    "    # 全系列（リークなしσ算出に使う。必須）\n",
    "    full_forward_returns: np.ndarray,   # ← 追加（y_all を渡す）\n",
    "    # z 校正パラメータ\n",
    "    b_z: float,\n",
    "    T_z: float,\n",
    "    # σ推定\n",
    "    vol_mode: str = \"ewma\",\n",
    "    lambda_ewma: float = 0.94,\n",
    "    window_size: int = 30,\n",
    "    # サブ窓分割\n",
    "    n_slices: int = 5,\n",
    "    # 目的関数の重み\n",
    "    L_var: float = 0.20,\n",
    "    L_vol: float = 10.0,\n",
    "    L_clip: float = 0.02,\n",
    "    # グリッド\n",
    "    T_soft_grid: np.ndarray = np.array([0.9, 1.0, 1.1, 1.2]),\n",
    "    target_clip_grid: np.ndarray = np.array([0.18, 0.20, 0.22, 0.24, 0.26]),\n",
    "    m_hi_grid: np.ndarray = np.array([2.0, 2.5, 3.0]),\n",
    "    Tm_grid: np.ndarray = np.array([1.0, 1.2, 1.4, 1.6]),\n",
    "    gamma_grid: np.ndarray = np.array([1.05, 1.08, 1.10]),\n",
    "    # クリップ範囲\n",
    "    min_signal: float = 0.0,\n",
    "    max_signal: float = 2.0,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    calib を複数サブ窓に分割し、悲観的（下振れに強い）目的でハイパラ選定。\n",
    "    必ず full_forward_returns（= y_all）を渡すこと。\n",
    "    \"\"\"\n",
    "    y_pred_calib = np.asarray(y_pred_calib).reshape(-1)\n",
    "    if len(y_pred_calib) != len(sol_calib):\n",
    "        raise ValueError(\"len(y_pred_calib) must equal len(sol_calib)\")\n",
    "\n",
    "    # サブ窓（絶対インデックス）\n",
    "    spans_abs = _split_indices(calib_abs_start, calib_abs_end, n_slices)\n",
    "\n",
    "    # z（calib 全体の b,T で固定）\n",
    "    z_all = (y_pred_calib - b_z) / T_z\n",
    "\n",
    "    best, best_eff = None, -np.inf\n",
    "\n",
    "    for T_soft in T_soft_grid:\n",
    "        for target_clip in target_clip_grid:\n",
    "            M_SOFT = choose_m_soft_by_clip(z_all, T_soft=T_soft, target_clip=target_clip)\n",
    "\n",
    "            for m_hi in m_hi_grid:\n",
    "                m_lo = 1.0\n",
    "                for Tm in Tm_grid:\n",
    "                    for gamma in gamma_grid:\n",
    "\n",
    "                        scores, vols, clips = [], [], []\n",
    "\n",
    "                        for (abs_s, abs_e) in spans_abs:\n",
    "                            # 相対インデックス（calib内のスライス）\n",
    "                            rel_s = abs_s - calib_abs_start\n",
    "                            rel_e = abs_e - calib_abs_start\n",
    "                            if rel_e - rel_s < max(20, window_size):  # 短すぎる窓はスキップ\n",
    "                                continue\n",
    "\n",
    "                            z_seg   = z_all[rel_s:rel_e]\n",
    "                            sol_seg = sol_calib.iloc[rel_s:rel_e].reset_index(drop=True)\n",
    "\n",
    "                            # 信頼度連動\n",
    "                            m_conf = conf_m_from_z_abs(z_seg, m_lo=m_lo, m_hi=m_hi, Tm=Tm)\n",
    "                            p_soft = 1.0 + m_conf * np.tanh(z_seg / T_soft)\n",
    "                            p_soft = np.clip(p_soft, min_signal, max_signal)\n",
    "\n",
    "                            # σ：全系列 y_all と絶対インデックスで作る（リークなし）\n",
    "                            sigma_daily = _make_sigma_for_period(\n",
    "                                fr_all=full_forward_returns,\n",
    "                                start=abs_s, end=abs_e,\n",
    "                                mode=vol_mode, lam=lambda_ewma, window=window_size\n",
    "                            )\n",
    "                            # 長さ整合チェック\n",
    "                            if len(sigma_daily) != len(p_soft):\n",
    "                                # 両方の長さに合わせて切る（保険）\n",
    "                                L = min(len(sigma_daily), len(p_soft))\n",
    "                                if L <= 0:\n",
    "                                    continue\n",
    "                                sigma_daily = sigma_daily[:L]\n",
    "                                p_soft = p_soft[:L]\n",
    "                                sol_seg = sol_seg.iloc[:L].reset_index(drop=True)\n",
    "\n",
    "                            ell_t = vol_target_scaler(sigma_daily, gamma=gamma, lev_cap=2.0)\n",
    "                            p = np.clip((p_soft - 1.0) * ell_t + 1.0, min_signal, max_signal)\n",
    "\n",
    "                            sub = pd.DataFrame({\"prediction\": p}).reset_index(drop=True)\n",
    "                            sc, inter = score(sol_seg.copy(), sub, \"\", [])\n",
    "                            scores.append(sc)\n",
    "\n",
    "                            # 罰則量\n",
    "                            vol_pen = inter[-1][3] if inter else 1.0\n",
    "                            vols.append(max(0.0, vol_pen - 1.0))\n",
    "                            clips.append(float(np.mean(p >= max_signal)))\n",
    "\n",
    "                        if not scores:\n",
    "                            continue\n",
    "\n",
    "                        scores = np.array(scores, dtype=float)\n",
    "                        vols   = np.array(vols, dtype=float)\n",
    "                        clips  = np.array(clips, dtype=float)\n",
    "\n",
    "                        eff = np.median(scores) \\\n",
    "                              - L_var * np.std(scores) \\\n",
    "                              - L_vol * np.mean(vols**2) \\\n",
    "                              - L_clip * np.mean(clips)\n",
    "\n",
    "                        if eff > best_eff:\n",
    "                            best_eff = eff\n",
    "                            best = dict(\n",
    "                                T_soft=float(T_soft),\n",
    "                                target_clip=float(target_clip),\n",
    "                                m_lo=float(m_lo),\n",
    "                                m_hi=float(m_hi),\n",
    "                                Tm=float(Tm),\n",
    "                                gamma=float(gamma),\n",
    "                                score_eff=float(eff),\n",
    "                                score_median=float(np.median(scores)),\n",
    "                                score_std=float(np.std(scores)),\n",
    "                            )\n",
    "\n",
    "    return best or {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d1585ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list_dict = {}\n",
    "\n",
    "def cross_validate(\n",
    "    allocation_model,\n",
    "    label: str = \"\",\n",
    "    min_train_size: int = 3000,\n",
    "    eval_size: int = 180,            # 旧: test_size\n",
    "    *,\n",
    "    calib_len: int = 720,            # 旧: INNER_VAL_LEN\n",
    "    vol_mode: str = \"ewma\",\n",
    "    lambda_ewma: float = 0.94,\n",
    "    window_size: int = 30,\n",
    "    std_scale: float = 2.0,\n",
    "    T_soft_init: float = 1.0,\n",
    "    target_clip: float = 0.22,\n",
    "    conf_params: tuple = (1.0, 3.0, 1.2),  # (m_lo, m_hi, Tm)\n",
    "    gamma: float = 1.10,\n",
    "    lev_cap: float = 2.0\n",
    "):\n",
    "    \"\"\"\n",
    "    時系列CV（calib→eval→holdout）\n",
    "      - calib: 直前区間。z校正(b,T)とm_soft決定に使用（リークなし）\n",
    "      - eval : 各fold評価区間（旧test）\n",
    "      - holdout: 最後180（LB相当、固定）。各fold学習モデルで一貫パイプ評価\n",
    "    \"\"\"\n",
    "    n = len(train)\n",
    "    oof = np.full(n, np.nan, dtype=float)\n",
    "    eval_scores, holdout_scores, intermediate_res = [], [], []\n",
    "\n",
    "    # 特徴列\n",
    "    drop_cols = [\"date_id\", \"forward_returns\", \"risk_free_rate\", \"market_forward_excess_returns\"]\n",
    "    feature_cols = [c for c in train.columns if c not in drop_cols]\n",
    "    X_all = train[feature_cols]\n",
    "    y_all = train[\"forward_returns\"].to_numpy()\n",
    "    rfr_all = train[\"risk_free_rate\"].to_numpy()\n",
    "\n",
    "    # holdout（最後180固定）\n",
    "    holdout_start = max(0, n - 180)\n",
    "    X_holdout = X_all.iloc[holdout_start:]\n",
    "    sol_holdout = pd.DataFrame({\n",
    "        \"forward_returns\": y_all[holdout_start:],\n",
    "        \"risk_free_rate\":  rfr_all[holdout_start:],\n",
    "    }).reset_index(drop=True)\n",
    "\n",
    "    for fold, eval_start in enumerate(range(n - eval_size, min_train_size, -eval_size)):\n",
    "        print(Fore.CYAN + f\"=== Fold {fold} Eval start at {eval_start} ===\" + Style.RESET_ALL)\n",
    "        eval_end = eval_start + eval_size\n",
    "\n",
    "        # ---- split ----\n",
    "        X_train = X_all.iloc[:eval_start]\n",
    "        X_eval  = X_all.iloc[eval_start:eval_end]\n",
    "        y_eval  = y_all[eval_start:eval_end]   # デバッグ用\n",
    "        sol_eval = pd.DataFrame({\n",
    "            \"forward_returns\": y_all[eval_start:eval_end],\n",
    "            \"risk_free_rate\":  rfr_all[eval_start:eval_end],\n",
    "        }).reset_index(drop=True)\n",
    "\n",
    "        calib_start = max(0, eval_start - calib_len)\n",
    "        X_calib = X_all.iloc[calib_start:eval_start]\n",
    "        y_calib = y_all[calib_start:eval_start]\n",
    "        sol_calib = pd.DataFrame({\n",
    "            \"forward_returns\": y_all[calib_start:eval_start],\n",
    "            \"risk_free_rate\":  rfr_all[calib_start:eval_start],\n",
    "        }).reset_index(drop=True)\n",
    "\n",
    "        # ---- fit ----\n",
    "        allocation_model.fit(X_train, y_all[:eval_start])\n",
    "\n",
    "        # ---- calib: z校正 & m_soft 決定 ----\n",
    "        y_pred_calib = allocation_model.predict(X_calib)\n",
    "        b_z, T_z = compute_z_calibration(y_pred_calib, std_scale=std_scale)\n",
    "        z_calib = (y_pred_calib - b_z) / T_z\n",
    "        # T_SOFT = T_soft_init\n",
    "        # M_SOFT = choose_m_soft_by_clip(z_calib, T_soft=T_SOFT, target_clip=target_clip)\n",
    "\n",
    "        # ---- 悲観的ハイパラ選定（calib を複数サブ窓で評価）----\n",
    "        best = select_hparams_pessimistic(\n",
    "            calib_abs_start=calib_start,\n",
    "            calib_abs_end=eval_start,\n",
    "            y_pred_calib=y_pred_calib,\n",
    "            sol_calib=sol_calib,\n",
    "            full_forward_returns=y_all,   # ★ ここを必ず渡す\n",
    "            b_z=b_z, T_z=T_z,\n",
    "            vol_mode=vol_mode, lambda_ewma=lambda_ewma, window_size=window_size,\n",
    "            n_slices=5,\n",
    "            L_var=0.20, L_vol=10.0, L_clip=0.02,\n",
    "            T_soft_grid=np.array([0.9, 1.0, 1.1, 1.2]),\n",
    "            target_clip_grid=np.array([0.18, 0.20, 0.22, 0.24, 0.26]),\n",
    "            m_hi_grid=np.array([2.0, 2.5, 3.0]),\n",
    "            Tm_grid=np.array([1.0, 1.2, 1.4, 1.6]),\n",
    "            gamma_grid=np.array([1.05, 1.08, 1.10]),\n",
    "            min_signal=ret_signal_params.min_signal,\n",
    "            max_signal=ret_signal_params.max_signal,\n",
    "        )\n",
    "\n",
    "        # fallback（念のため）\n",
    "        if not best:\n",
    "            T_SOFT = T_soft_init\n",
    "            M_SOFT = choose_m_soft_by_clip(z_calib, T_soft=T_SOFT, target_clip=target_clip)\n",
    "            m_lo, m_hi, Tm = conf_params\n",
    "            GAMMA = gamma\n",
    "        else:\n",
    "            T_SOFT = best['T_soft']\n",
    "            # calib 全体の z で target_clip を満たす M_SOFT を再計算\n",
    "            M_SOFT = choose_m_soft_by_clip(z_calib, T_soft=T_SOFT, target_clip=best['target_clip'])\n",
    "            m_lo, m_hi, Tm = 1.0, best['m_hi'], best['Tm']\n",
    "            GAMMA = best['gamma']\n",
    "\n",
    "        print(f\"[calib/pessimistic] T_SOFT={T_SOFT:.2f}, M_SOFT={M_SOFT:.3f}, \"\n",
    "          f\"m_lo={m_lo:.1f}, m_hi={m_hi:.1f}, Tm={Tm:.2f}, gamma={GAMMA:.2f}\")\n",
    "\n",
    "\n",
    "        # ---- eval: 予測 → 配分 ----\n",
    "        y_pred_eval = allocation_model.predict(X_eval)\n",
    "        sigma_eval_daily = _make_sigma_for_period(y_all, eval_start, eval_end,\n",
    "                                                mode=vol_mode, lam=lambda_ewma, window=window_size)\n",
    "        alloc_eval = make_allocation_from_predictions(\n",
    "            y_pred_eval,\n",
    "            b_z=b_z, T_z=T_z,\n",
    "            T_soft=T_SOFT, m_soft=M_SOFT,\n",
    "            conf_params=(m_lo, m_hi, Tm),\n",
    "            sigma_daily=sigma_eval_daily,\n",
    "            gamma=GAMMA, lev_cap=lev_cap,\n",
    "            min_signal=ret_signal_params.min_signal,\n",
    "            max_signal=ret_signal_params.max_signal,\n",
    "        )\n",
    "\n",
    "        sub_eval = pd.DataFrame({\"prediction\": alloc_eval}).reset_index(drop=True)\n",
    "        eval_score, intermediate_res = score(sol_eval, sub_eval, \"\", intermediate_res)\n",
    "\n",
    "        # ---- holdout（最後180）：同一パイプで評価 ----\n",
    "        y_pred_holdout = allocation_model.predict(X_holdout)\n",
    "        sigma_holdout_daily = _make_sigma_for_period(\n",
    "            y_all, holdout_start, n, mode=vol_mode, lam=lambda_ewma, window=window_size\n",
    "        )\n",
    "\n",
    "        alloc_holdout = make_allocation_from_predictions(\n",
    "            y_pred_holdout,\n",
    "            b_z=b_z, T_z=T_z,\n",
    "            T_soft=T_SOFT, m_soft=M_SOFT,\n",
    "            conf_params=(m_lo, m_hi, Tm),\n",
    "            sigma_daily=sigma_holdout_daily,\n",
    "            gamma=GAMMA, lev_cap=lev_cap,\n",
    "            min_signal=ret_signal_params.min_signal,\n",
    "            max_signal=ret_signal_params.max_signal,\n",
    "        )\n",
    "        sub_holdout = pd.DataFrame({\"prediction\": alloc_holdout}).reset_index(drop=True)\n",
    "        holdout_score, inter2 = score(sol_holdout, sub_holdout, \"\", intermediate_res)\n",
    "\n",
    "        # ---- ログ ----\n",
    "        clip0 = np.mean(alloc_eval <= ret_signal_params.min_signal) * 100\n",
    "        clip2 = np.mean(alloc_eval >= ret_signal_params.max_signal) * 100\n",
    "        if inter2:\n",
    "            _, _, sharpe, vol_pen, ret_pen = inter2[-1]\n",
    "            print(f\"[holdout] sharpe={sharpe:.3f} vol_pen={vol_pen:.2f} ret_pen={ret_pen:.2f}\")\n",
    "            lo = np.mean(alloc_holdout <= ret_signal_params.min_signal)\n",
    "            hi = np.mean(alloc_holdout >= ret_signal_params.max_signal)\n",
    "            print(f\"[holdout] clip@0={lo:.2%}, clip@2={hi:.2%}\")\n",
    "        print(f\"[calib]  M_SOFT={M_SOFT:.3f}, T_SOFT={T_SOFT:.2f}, target clip≈{int(target_clip*100)}%\")\n",
    "        print(f\"[eval ]  clip@0={clip0:.2f}% clip@2={clip2:.2f}%\")\n",
    "\n",
    "        display(HTML(\n",
    "            f\"<p style='color: orange'>\"\n",
    "            f\"train(:{eval_start:4}) eval({eval_start:4}:{eval_end:4})<br>\"\n",
    "            f\"eval_score: {eval_score:6.3f}<br>\"\n",
    "            f\"holdout(last180) score: {holdout_score:.6f}<br>\"\n",
    "            f\"z-calib: b={b_z:.3e}, T={T_z:.3e}, M_SOFT={M_SOFT:.3f}, T_SOFT={T_SOFT:.2f}\"\n",
    "            f\"</p>\"\n",
    "        ))\n",
    "\n",
    "        oof[eval_start:eval_end] = alloc_eval\n",
    "        eval_scores.append(eval_score)\n",
    "        holdout_scores.append(holdout_score)\n",
    "\n",
    "    # ===== 集計表示 =====\n",
    "    submit_model = allocation_model\n",
    "    display(HTML('<h2 style=\"text-align:center;color:orange\">======== Result ========</h2>'))\n",
    "    avg_eval = float(np.nanmean(eval_scores)) if len(eval_scores) else np.nan\n",
    "    print(f\"{label} Average Eval Score: {avg_eval:.6f}\")\n",
    "\n",
    "    # OOF 全体スコア\n",
    "    mask = np.isfinite(oof)\n",
    "    if np.any(mask):\n",
    "        solution_all = pd.DataFrame({\n",
    "            \"forward_returns\": y_all[mask],\n",
    "            \"risk_free_rate\":  rfr_all[mask],\n",
    "        }).reset_index(drop=True)\n",
    "        submission_all = pd.DataFrame({'prediction': oof[mask]}).reset_index(drop=True)\n",
    "        overall_score, inter_all = score(solution_all, submission_all, '', [])\n",
    "        vol_penalty = inter_all[-1][3] if inter_all else np.nan\n",
    "        return_penalty = inter_all[-1][4] if inter_all else np.nan\n",
    "        print(f\"{label} Overall OOF Score: {overall_score:.6f} vol_penalty={vol_penalty:.2f} return_penalty={return_penalty:.2f}\")\n",
    "    else:\n",
    "        print(f\"{label} Overall OOF Score: NaN (no valid OOF)\")\n",
    "\n",
    "    # ====== 追加: 各foldの holdout スコアのばらつき可視化 ======\n",
    "    if holdout_scores:\n",
    "        holdout_scores = np.array(holdout_scores, dtype=float)\n",
    "        mu, sd = float(np.mean(holdout_scores)), float(np.std(holdout_scores))\n",
    "        print(Fore.YELLOW + f\"[holdout] mean={mu:.3f}, std={sd:.3f}\" + Style.RESET_ALL)\n",
    "\n",
    "        plt.figure(figsize=(6.5, 2.6))\n",
    "        plt.plot(holdout_scores, marker='o', linewidth=1)\n",
    "        plt.axhline(mu, linestyle='--')\n",
    "        plt.title(f\"Holdout (last180) scores per fold — mean={mu:.3f}, std={sd:.3f}\")\n",
    "        plt.xlabel(\"Fold index\")\n",
    "        plt.ylabel(\"Score\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    score_list_dict[label] = eval_scores\n",
    "    if eval_scores:\n",
    "        print(f\"{label} First Eval Fold Score: {eval_scores[0]:.6f}\")\n",
    "    if holdout_scores.size:\n",
    "        print(Fore.YELLOW + f\"{label} Holdout Score (avg over folds using each model): {holdout_scores.mean():.3f}\" + Style.RESET_ALL)\n",
    "\n",
    "    # ヒスト（OOF）\n",
    "    if np.any(mask):\n",
    "        vals = oof[mask]\n",
    "        vmin, vmax = float(np.min(vals)), float(np.max(vals))\n",
    "        if vmin == vmax: vmax = vmin + 1e-6\n",
    "        bins = np.linspace(vmin, vmax, 50)\n",
    "        plt.figure(figsize=(6, 2))\n",
    "        plt.hist(vals, bins=bins, density=False, color='c', edgecolor='k', linewidth=0.5)\n",
    "        plt.title(f'Allocation histogram of {label}')\n",
    "        plt.gca().get_yaxis().set_visible(False)\n",
    "        plt.xlim(vmin, vmax)\n",
    "        plt.show()\n",
    "        print(f\"Range of predictions: [{vmin:.6f}, {vmax:.6f}]\")\n",
    "\n",
    "    return submit_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3ca9afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 0 Eval start at 8810 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21575\n",
      "[LightGBM] [Info] Number of data points in the train set: 8810, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000468\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=1.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.05\n",
      "[holdout] sharpe=0.405 vol_pen=1.05 ret_pen=1.00\n",
      "[holdout] clip@0=0.00%, clip@2=0.00%\n",
      "[calib]  M_SOFT=1.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=0.00% clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:8810) eval(8810:8990)<br>eval_score:  0.385<br>holdout(last180) score: 0.384554<br>z-calib: b=5.080e-04, T=1.742e-02, M_SOFT=1.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 1 Eval start at 8630 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21573\n",
      "[LightGBM] [Info] Number of data points in the train set: 8630, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000460\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=1.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.109 vol_pen=1.00 ret_pen=1.33\n",
      "[holdout] clip@0=0.00%, clip@2=0.00%\n",
      "[calib]  M_SOFT=1.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=0.00% clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:8630) eval(8630:8810)<br>eval_score:  1.121<br>holdout(last180) score: 0.082134<br>z-calib: b=4.762e-04, T=1.770e-02, M_SOFT=1.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 2 Eval start at 8450 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21575\n",
      "[LightGBM] [Info] Number of data points in the train set: 8450, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000453\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=2.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.314 vol_pen=1.00 ret_pen=1.02\n",
      "[holdout] clip@0=0.00%, clip@2=0.00%\n",
      "[calib]  M_SOFT=2.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=0.00% clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:8450) eval(8450:8630)<br>eval_score:  1.277<br>holdout(last180) score: 0.307119<br>z-calib: b=4.583e-04, T=1.898e-02, M_SOFT=2.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 3 Eval start at 8270 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21574\n",
      "[LightGBM] [Info] Number of data points in the train set: 8270, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000440\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=1.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.548 vol_pen=1.00 ret_pen=1.00\n",
      "[holdout] clip@0=0.00%, clip@2=0.00%\n",
      "[calib]  M_SOFT=1.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=0.00% clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:8270) eval(8270:8450)<br>eval_score:  1.386<br>holdout(last180) score: 0.548453<br>z-calib: b=9.222e-04, T=2.368e-02, M_SOFT=1.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 4 Eval start at 8090 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21569\n",
      "[LightGBM] [Info] Number of data points in the train set: 8090, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000468\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=2.421, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.283 vol_pen=1.00 ret_pen=1.06\n",
      "[holdout] clip@0=0.00%, clip@2=0.00%\n",
      "[calib]  M_SOFT=2.421, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=0.56% clip@2=7.22%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:8090) eval(8090:8270)<br>eval_score: -0.531<br>holdout(last180) score: 0.268188<br>z-calib: b=1.212e-03, T=2.029e-02, M_SOFT=2.421, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 5 Eval start at 7910 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21568\n",
      "[LightGBM] [Info] Number of data points in the train set: 7910, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000465\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=2.421, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.411 vol_pen=1.00 ret_pen=1.00\n",
      "[holdout] clip@0=0.00%, clip@2=0.00%\n",
      "[calib]  M_SOFT=2.421, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=0.00% clip@2=0.56%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:7910) eval(7910:8090)<br>eval_score:  1.573<br>holdout(last180) score: 0.411313<br>z-calib: b=1.087e-03, T=2.132e-02, M_SOFT=2.421, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 6 Eval start at 7730 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21566\n",
      "[LightGBM] [Info] Number of data points in the train set: 7730, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000448\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=1.421, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.381 vol_pen=1.00 ret_pen=1.00\n",
      "[holdout] clip@0=0.00%, clip@2=0.00%\n",
      "[calib]  M_SOFT=1.421, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=9.44% clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:7730) eval(7730:7910)<br>eval_score:  0.718<br>holdout(last180) score: 0.379618<br>z-calib: b=1.073e-03, T=2.122e-02, M_SOFT=1.421, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 7 Eval start at 7550 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21508\n",
      "[LightGBM] [Info] Number of data points in the train set: 7550, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000434\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=1.421, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.411 vol_pen=1.00 ret_pen=1.00\n",
      "[holdout] clip@0=1.67%, clip@2=0.56%\n",
      "[calib]  M_SOFT=1.421, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=8.33% clip@2=2.78%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:7550) eval(7550:7730)<br>eval_score:  0.511<br>holdout(last180) score: 0.411283<br>z-calib: b=6.820e-04, T=1.398e-02, M_SOFT=1.421, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 8 Eval start at 7370 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21444\n",
      "[LightGBM] [Info] Number of data points in the train set: 7370, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000428\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=2.658, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.274 vol_pen=1.02 ret_pen=1.05\n",
      "[holdout] clip@0=1.11%, clip@2=0.00%\n",
      "[calib]  M_SOFT=2.658, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=2.78% clip@2=3.89%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:7370) eval(7370:7550)<br>eval_score:  1.217<br>holdout(last180) score: 0.255813<br>z-calib: b=6.448e-04, T=1.334e-02, M_SOFT=2.658, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 9 Eval start at 7190 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21383\n",
      "[LightGBM] [Info] Number of data points in the train set: 7190, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000433\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=1.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.119 vol_pen=1.16 ret_pen=1.27\n",
      "[holdout] clip@0=2.22%, clip@2=1.67%\n",
      "[calib]  M_SOFT=1.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=2.22% clip@2=2.78%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:7190) eval(7190:7370)<br>eval_score:  0.379<br>holdout(last180) score: 0.081551<br>z-calib: b=5.740e-04, T=1.315e-02, M_SOFT=1.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 10 Eval start at 7010 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21328\n",
      "[LightGBM] [Info] Number of data points in the train set: 7010, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000428\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=1.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.302 vol_pen=1.08 ret_pen=1.02\n",
      "[holdout] clip@0=2.22%, clip@2=0.56%\n",
      "[calib]  M_SOFT=1.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=5.00% clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:7010) eval(7010:7190)<br>eval_score:  0.810<br>holdout(last180) score: 0.274481<br>z-calib: b=4.002e-04, T=1.364e-02, M_SOFT=1.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 11 Eval start at 6830 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21313\n",
      "[LightGBM] [Info] Number of data points in the train set: 6830, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score 0.000421\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=1.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.05\n",
      "[holdout] sharpe=0.206 vol_pen=1.14 ret_pen=1.10\n",
      "[holdout] clip@0=0.00%, clip@2=0.56%\n",
      "[calib]  M_SOFT=1.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=10.56% clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:6830) eval(6830:7010)<br>eval_score:  2.047<br>holdout(last180) score: 0.163981<br>z-calib: b=4.353e-04, T=1.442e-02, M_SOFT=1.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 12 Eval start at 6650 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001990 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21261\n",
      "[LightGBM] [Info] Number of data points in the train set: 6650, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score 0.000413\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=2.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.212 vol_pen=1.15 ret_pen=1.09\n",
      "[holdout] clip@0=2.78%, clip@2=0.56%\n",
      "[calib]  M_SOFT=2.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=13.33% clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:6650) eval(6650:6830)<br>eval_score:  1.803<br>holdout(last180) score: 0.169361<br>z-calib: b=5.253e-04, T=1.443e-02, M_SOFT=2.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 13 Eval start at 6470 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21194\n",
      "[LightGBM] [Info] Number of data points in the train set: 6470, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score 0.000413\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=1.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.094 vol_pen=1.05 ret_pen=1.35\n",
      "[holdout] clip@0=6.67%, clip@2=0.56%\n",
      "[calib]  M_SOFT=1.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=6.67% clip@2=1.11%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:6470) eval(6470:6650)<br>eval_score:  1.939<br>holdout(last180) score: 0.065815<br>z-calib: b=7.800e-04, T=1.327e-02, M_SOFT=1.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 14 Eval start at 6290 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21072\n",
      "[LightGBM] [Info] Number of data points in the train set: 6290, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score 0.000422\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=2.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.410 vol_pen=1.17 ret_pen=1.00\n",
      "[holdout] clip@0=1.11%, clip@2=1.67%\n",
      "[calib]  M_SOFT=2.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=4.44% clip@2=0.56%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:6290) eval(6290:6470)<br>eval_score:  0.458<br>holdout(last180) score: 0.350821<br>z-calib: b=7.628e-04, T=1.223e-02, M_SOFT=2.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 15 Eval start at 6110 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20660\n",
      "[LightGBM] [Info] Number of data points in the train set: 6110, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score 0.000424\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=2.421, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.180 vol_pen=1.07 ret_pen=1.16\n",
      "[holdout] clip@0=1.11%, clip@2=0.56%\n",
      "[calib]  M_SOFT=2.421, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=7.22% clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:6110) eval(6110:6290)<br>eval_score:  1.832<br>holdout(last180) score: 0.144924<br>z-calib: b=7.117e-04, T=1.777e-02, M_SOFT=2.421, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 16 Eval start at 5930 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20389\n",
      "[LightGBM] [Info] Number of data points in the train set: 5930, number of used features: 92\n",
      "[LightGBM] [Info] Start training from score 0.000415\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=1.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.08\n",
      "[holdout] sharpe=0.409 vol_pen=1.00 ret_pen=1.00\n",
      "[holdout] clip@0=7.22%, clip@2=0.00%\n",
      "[calib]  M_SOFT=1.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=7.22% clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:5930) eval(5930:6110)<br>eval_score:  1.858<br>holdout(last180) score: 0.408263<br>z-calib: b=8.788e-04, T=1.795e-02, M_SOFT=1.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 17 Eval start at 5750 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5750, number of used features: 91\n",
      "[LightGBM] [Info] Start training from score 0.000396\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=1.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.357 vol_pen=1.00 ret_pen=1.01\n",
      "[holdout] clip@0=0.56%, clip@2=0.00%\n",
      "[calib]  M_SOFT=1.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=0.56% clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:5750) eval(5750:5930)<br>eval_score:  0.951<br>holdout(last180) score: 0.353448<br>z-calib: b=6.882e-04, T=2.002e-02, M_SOFT=1.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 18 Eval start at 5570 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19631\n",
      "[LightGBM] [Info] Number of data points in the train set: 5570, number of used features: 91\n",
      "[LightGBM] [Info] Start training from score 0.000394\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=1.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.589 vol_pen=1.00 ret_pen=1.00\n",
      "[holdout] clip@0=0.00%, clip@2=0.00%\n",
      "[calib]  M_SOFT=1.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=0.00% clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:5570) eval(5570:5750)<br>eval_score:  0.822<br>holdout(last180) score: 0.589291<br>z-calib: b=1.208e-03, T=2.208e-02, M_SOFT=1.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 19 Eval start at 5390 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19296\n",
      "[LightGBM] [Info] Number of data points in the train set: 5390, number of used features: 88\n",
      "[LightGBM] [Info] Start training from score 0.000394\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=2.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.266 vol_pen=1.00 ret_pen=1.10\n",
      "[holdout] clip@0=0.00%, clip@2=0.00%\n",
      "[calib]  M_SOFT=2.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=0.00% clip@2=0.56%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:5390) eval(5390:5570)<br>eval_score:  0.403<br>holdout(last180) score: 0.242727<br>z-calib: b=1.110e-03, T=2.830e-02, M_SOFT=2.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 20 Eval start at 5210 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19172\n",
      "[LightGBM] [Info] Number of data points in the train set: 5210, number of used features: 88\n",
      "[LightGBM] [Info] Start training from score 0.000362\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=2.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.165 vol_pen=1.00 ret_pen=1.25\n",
      "[holdout] clip@0=2.22%, clip@2=0.00%\n",
      "[calib]  M_SOFT=2.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=0.56% clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:5210) eval(5210:5390)<br>eval_score:  2.356<br>holdout(last180) score: 0.132104<br>z-calib: b=5.279e-04, T=3.002e-02, M_SOFT=2.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 21 Eval start at 5030 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19057\n",
      "[LightGBM] [Info] Number of data points in the train set: 5030, number of used features: 87\n",
      "[LightGBM] [Info] Start training from score 0.000377\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=2.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.312 vol_pen=1.00 ret_pen=1.05\n",
      "[holdout] clip@0=0.00%, clip@2=0.00%\n",
      "[calib]  M_SOFT=2.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=0.56% clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:5030) eval(5030:5210)<br>eval_score: -0.154<br>holdout(last180) score: 0.297215<br>z-calib: b=6.021e-04, T=2.937e-02, M_SOFT=2.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 22 Eval start at 4850 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18949\n",
      "[LightGBM] [Info] Number of data points in the train set: 4850, number of used features: 87\n",
      "[LightGBM] [Info] Start training from score 0.000312\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=1.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.173 vol_pen=1.00 ret_pen=1.24\n",
      "[holdout] clip@0=9.44%, clip@2=0.00%\n",
      "[calib]  M_SOFT=1.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=10.56% clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:4850) eval(4850:5030)<br>eval_score:  0.453<br>holdout(last180) score: 0.140212<br>z-calib: b=4.766e-04, T=2.747e-02, M_SOFT=1.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 23 Eval start at 4670 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18896\n",
      "[LightGBM] [Info] Number of data points in the train set: 4670, number of used features: 87\n",
      "[LightGBM] [Info] Start training from score 0.000386\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=1.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.116 vol_pen=1.00 ret_pen=1.36\n",
      "[holdout] clip@0=23.89%, clip@2=0.00%\n",
      "[calib]  M_SOFT=1.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=13.33% clip@2=17.78%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:4670) eval(4670:4850)<br>eval_score: -0.613<br>holdout(last180) score: 0.085156<br>z-calib: b=6.132e-04, T=1.693e-02, M_SOFT=1.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 24 Eval start at 4490 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18469\n",
      "[LightGBM] [Info] Number of data points in the train set: 4490, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.000442\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=2.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=-0.260 vol_pen=1.00 ret_pen=2.68\n",
      "[holdout] clip@0=19.44%, clip@2=1.11%\n",
      "[calib]  M_SOFT=2.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=4.44% clip@2=16.11%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:4490) eval(4490:4670)<br>eval_score: -0.577<br>holdout(last180) score: -0.097057<br>z-calib: b=7.626e-04, T=1.315e-02, M_SOFT=2.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 25 Eval start at 4310 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18318\n",
      "[LightGBM] [Info] Number of data points in the train set: 4310, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.000444\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=2.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.150 vol_pen=1.00 ret_pen=1.24\n",
      "[holdout] clip@0=14.44%, clip@2=1.67%\n",
      "[calib]  M_SOFT=2.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=2.78% clip@2=3.33%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:4310) eval(4310:4490)<br>eval_score:  0.521<br>holdout(last180) score: 0.120407<br>z-calib: b=8.186e-04, T=1.189e-02, M_SOFT=2.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 26 Eval start at 4130 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18264\n",
      "[LightGBM] [Info] Number of data points in the train set: 4130, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.000425\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=0.947, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=-0.189 vol_pen=1.00 ret_pen=2.35\n",
      "[holdout] clip@0=12.22%, clip@2=0.56%\n",
      "[calib]  M_SOFT=0.947, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=2.78% clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:4130) eval(4130:4310)<br>eval_score:  1.954<br>holdout(last180) score: -0.080306<br>z-calib: b=9.583e-04, T=1.258e-02, M_SOFT=0.947, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 27 Eval start at 3950 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17761\n",
      "[LightGBM] [Info] Number of data points in the train set: 3950, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.000430\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=2.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.361 vol_pen=1.00 ret_pen=1.02\n",
      "[holdout] clip@0=9.44%, clip@2=0.56%\n",
      "[calib]  M_SOFT=2.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=0.56% clip@2=0.56%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:3950) eval(3950:4130)<br>eval_score:  1.187<br>holdout(last180) score: 0.353544<br>z-calib: b=8.972e-04, T=1.663e-02, M_SOFT=2.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 28 Eval start at 3770 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17476\n",
      "[LightGBM] [Info] Number of data points in the train set: 3770, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.000444\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=2.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.289 vol_pen=1.00 ret_pen=1.07\n",
      "[holdout] clip@0=3.89%, clip@2=0.00%\n",
      "[calib]  M_SOFT=2.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=0.00% clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:3770) eval(3770:3950)<br>eval_score:  0.012<br>holdout(last180) score: 0.271045<br>z-calib: b=7.062e-04, T=2.266e-02, M_SOFT=2.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 29 Eval start at 3590 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17231\n",
      "[LightGBM] [Info] Number of data points in the train set: 3590, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.000440\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=2.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.284 vol_pen=1.00 ret_pen=1.07\n",
      "[holdout] clip@0=3.33%, clip@2=0.00%\n",
      "[calib]  M_SOFT=2.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=0.00% clip@2=0.56%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:3590) eval(3590:3770)<br>eval_score:  0.937<br>holdout(last180) score: 0.264620<br>z-calib: b=4.174e-04, T=2.463e-02, M_SOFT=2.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 30 Eval start at 3410 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17027\n",
      "[LightGBM] [Info] Number of data points in the train set: 3410, number of used features: 85\n",
      "[LightGBM] [Info] Start training from score 0.000425\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=2.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.738 vol_pen=1.00 ret_pen=1.00\n",
      "[holdout] clip@0=1.67%, clip@2=0.56%\n",
      "[calib]  M_SOFT=2.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=0.00% clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:3410) eval(3410:3590)<br>eval_score:  1.474<br>holdout(last180) score: 0.738478<br>z-calib: b=-2.457e-04, T=2.793e-02, M_SOFT=2.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 31 Eval start at 3230 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001087 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16840\n",
      "[LightGBM] [Info] Number of data points in the train set: 3230, number of used features: 83\n",
      "[LightGBM] [Info] Start training from score 0.000411\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=2.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.456 vol_pen=1.00 ret_pen=1.00\n",
      "[holdout] clip@0=3.89%, clip@2=0.00%\n",
      "[calib]  M_SOFT=2.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=1.67% clip@2=1.11%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:3230) eval(3230:3410)<br>eval_score:  0.716<br>holdout(last180) score: 0.455894<br>z-calib: b=-4.804e-04, T=2.847e-02, M_SOFT=2.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 32 Eval start at 3050 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16764\n",
      "[LightGBM] [Info] Number of data points in the train set: 3050, number of used features: 83\n",
      "[LightGBM] [Info] Start training from score 0.000508\n",
      "[calib/pessimistic] T_SOFT=0.90, M_SOFT=2.184, m_lo=1.0, m_hi=3.0, Tm=1.00, gamma=1.10\n",
      "[holdout] sharpe=0.212 vol_pen=1.00 ret_pen=1.13\n",
      "[holdout] clip@0=1.11%, clip@2=0.00%\n",
      "[calib]  M_SOFT=2.184, T_SOFT=0.90, target clip≈22%\n",
      "[eval ]  clip@0=1.67% clip@2=5.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:3050) eval(3050:3230)<br>eval_score: -0.658<br>holdout(last180) score: 0.187431<br>z-calib: b=-2.662e-05, T=2.575e-02, M_SOFT=2.184, T_SOFT=0.90</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2 style=\"text-align:center;color:orange\">======== Result ========</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Model Average Eval Score: 0.865714\n",
      "LightGBM Model Overall OOF Score: 0.466791 vol_penalty=1.04 return_penalty=1.00\n",
      "\u001b[33m[holdout] mean=0.266, std=0.178\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 650x260 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Model First Eval Fold Score: 0.384554\n",
      "\u001b[33mLightGBM Model Holdout Score (avg over folds using each model): 0.266\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of predictions: [0.000000, 2.000000]\n"
     ]
    }
   ],
   "source": [
    "# 単純なLightGBMモデルで試す\n",
    "\n",
    "allocation_model = lgb.LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "submit_model = cross_validate(allocation_model, label=\"LightGBM Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427c0cc0",
   "metadata": {},
   "source": [
    "### Submission\n",
    "- time-series streaming形式\n",
    "- Kaggle サーバーから1batchずつ送られるデータからsubmission.parquetを返す\n",
    "- 返り値検証があるため，指定された形式で返す\n",
    "- 指定形式\n",
    "  - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "218685fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test: pl.DataFrame) -> float:\n",
    "    \"\"\"Replace this function with your inference code.\"\"\"\n",
    "    test_pd = test.to_pandas()\n",
    "    # display(test_pd.info())\n",
    "    if len(test_pd.columns) > 94:\n",
    "        test_pd = test_pd.drop(\n",
    "            [\"date_id\", \"is_scored\", \"lagged_forward_returns\", \"lagged_risk_free_rate\", \"lagged_market_forward_excess_returns\"],\n",
    "            axis = 1)\n",
    "\n",
    "    preds = submit_model.predict(test_pd)\n",
    "    raw_pred: float = float(preds[0])\n",
    "    print(f\"predict:{raw_pred}\")\n",
    "\n",
    "    # --- 出力（float or ndarray）---\n",
    "    # KaggleのAPI仕様上、float単体かSeries/DataFrameで返す必要あり float(preds[0]) if len(preds) == 1 else preds　\n",
    "    return convert_ret_to_signal(raw_pred, ret_signal_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b05b6a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "GatewayRuntimeError",
     "evalue": "(<GatewayRuntimeErrorType.GATEWAY_RAISED_EXCEPTION: 5>, 'Traceback (most recent call last):\\n  File \"/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/base_gateway.py\", line 134, in run\\n    predictions, row_ids = self.get_all_predictions()\\n  File \"/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/base_gateway.py\", line 109, in get_all_predictions\\n    for data_batch, row_ids in self.generate_data_batches():\\n  File \"/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/default_gateway.py\", line 29, in generate_data_batches\\n    test = pl.read_csv(self.competition_data_dir / \\'test.csv\\')\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/_utils/deprecation.py\", line 128, in wrapper\\n    return function(*args, **kwargs)\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/_utils/deprecation.py\", line 128, in wrapper\\n    return function(*args, **kwargs)\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/_utils/deprecation.py\", line 128, in wrapper\\n    return function(*args, **kwargs)\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/io/csv/functions.py\", line 549, in read_csv\\n    df = _read_csv_impl(\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/io/csv/functions.py\", line 697, in _read_csv_impl\\n    pydf = PyDataFrame.read_csv(\\nFileNotFoundError: No such file or directory (os error 2): /kaggle/input/hull-tactical-market-prediction/test.csv\\n')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGatewayRuntimeError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     inference_server\u001b[38;5;241m.\u001b[39mserve()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     \u001b[43minference_server\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_local_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/hull-tactical-market-prediction/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/templates.py:110\u001b[0m, in \u001b[0;36mInferenceServer.run_local_gateway\u001b[0;34m(self, data_paths, file_share_dir, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver\u001b[38;5;241m.\u001b[39mstop(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/templates.py:108\u001b[0m, in \u001b[0;36mInferenceServer.run_local_gateway\u001b[0;34m(self, data_paths, file_share_dir, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_gateway_for_test(data_paths, file_share_dir, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/base_gateway.py:153\u001b[0m, in \u001b[0;36mBaseGateway.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_result(error)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# For local testing\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[0;31mGatewayRuntimeError\u001b[0m: (<GatewayRuntimeErrorType.GATEWAY_RAISED_EXCEPTION: 5>, 'Traceback (most recent call last):\\n  File \"/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/base_gateway.py\", line 134, in run\\n    predictions, row_ids = self.get_all_predictions()\\n  File \"/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/base_gateway.py\", line 109, in get_all_predictions\\n    for data_batch, row_ids in self.generate_data_batches():\\n  File \"/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/default_gateway.py\", line 29, in generate_data_batches\\n    test = pl.read_csv(self.competition_data_dir / \\'test.csv\\')\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/_utils/deprecation.py\", line 128, in wrapper\\n    return function(*args, **kwargs)\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/_utils/deprecation.py\", line 128, in wrapper\\n    return function(*args, **kwargs)\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/_utils/deprecation.py\", line 128, in wrapper\\n    return function(*args, **kwargs)\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/io/csv/functions.py\", line 549, in read_csv\\n    df = _read_csv_impl(\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/io/csv/functions.py\", line 697, in _read_csv_impl\\n    pydf = PyDataFrame.read_csv(\\nFileNotFoundError: No such file or directory (os error 2): /kaggle/input/hull-tactical-market-prediction/test.csv\\n')"
     ]
    }
   ],
   "source": [
    "# サーバー上でpredict(test_batch)を動かす\n",
    "inference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(('/kaggle/input/hull-tactical-market-prediction/',))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
