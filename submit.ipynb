{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4da04843",
   "metadata": {},
   "source": [
    "# Hull Tactical Market Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2358dfe",
   "metadata": {},
   "source": [
    "### Import Libralies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "33e2c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "from colorama import Fore, Style\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "# Models\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Submission\n",
    "import polars as pl\n",
    "import kaggle_evaluation.default_inference_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7e4c475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "427f4438",
   "metadata": {},
   "outputs": [],
   "source": [
    "INNER_VAL_LEN = 180\n",
    "TRADING_DAYS_PER_YR = 252"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad54b45d",
   "metadata": {},
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b41dbf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ RETURNS TO SIGNAL CONFIGS ============\n",
    "MIN_SIGNAL: float = 0.0                         # Minimum value for the daily signal \n",
    "MAX_SIGNAL: float = 2.0                         # Maximum value for the daily signal \n",
    "SIGNAL_MULTIPLIER: float = 7.5                 # Multiplier of the OLS market forward excess returns predictions to signal \n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class RetToSignalParameters:\n",
    "    signal_multiplier: float \n",
    "    min_signal : float = MIN_SIGNAL\n",
    "    max_signal : float = MAX_SIGNAL\n",
    "\n",
    "ret_signal_params = RetToSignalParameters(\n",
    "    signal_multiplier= SIGNAL_MULTIPLIER\n",
    ")\n",
    "\n",
    "def convert_ret_to_signal(\n",
    "    ret_arr: np.ndarray,\n",
    "    params: RetToSignalParameters,\n",
    "    signal_multiplier=None\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts raw model predictions (expected returns) into a trading signal.\n",
    "\n",
    "    Args:\n",
    "        ret_arr (np.ndarray): The array of predicted returns.\n",
    "        params (RetToSignalParameters): Parameters for scaling and clipping the signal.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The resulting trading signal, clipped between min and max values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 予測値を基準に，投資戦略シグナルに変換\n",
    "    # ret * signal_multiplier + 1 を min_signal ~ max_signal の範囲にクリップ\n",
    "    if signal_multiplier is None:\n",
    "        multi = params.signal_multiplier    \n",
    "    else:\n",
    "        multi = signal_multiplier\n",
    "    \n",
    "    ret = np.clip(\n",
    "        ret_arr * multi + 1,\n",
    "        params.min_signal, \n",
    "        params.max_signal\n",
    "    )\n",
    "\n",
    "    if ret.size < 20:\n",
    "        print(f\"Strategy:\")\n",
    "        for i, value in enumerate(ret): print(f'  {i}: {value:.4f}')\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a444b812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy:\n",
      "  0: 2.0000\n",
      "  1: 1.7500\n",
      "  2: 2.0000\n",
      "  3: 0.0000\n",
      "  4: 2.0000\n"
     ]
    }
   ],
   "source": [
    "# convert_ret_to_signalの動作確認\n",
    "# 20個の乱数(0~1)\n",
    "hoge = convert_ret_to_signal(np.array([5, 0.1, 0.3, -0.2, 1.3]), ret_signal_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "dfc2f554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ LOAD DATA ============\n",
    "# プラットフォームがkaggleかローカルかで分岐\n",
    "if os.getenv('KAGGLE_KERNEL_RUN_TYPE') is not None:\n",
    "    # Kaggle上\n",
    "    DATA_PATH: Path = Path('/kaggle/input/hull-tactical-market-prediction/')\n",
    "else:\n",
    "    BASE_PATH = Path.cwd()\n",
    "    DATA_PATH: Path = BASE_PATH / 'data'\n",
    "\n",
    "\n",
    "train = pd.read_csv(DATA_PATH / \"train.csv\")\n",
    "test = pd.read_csv(DATA_PATH / \"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ef6c12",
   "metadata": {},
   "source": [
    "### Scoreing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "862dff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticipantVisibleError(Exception):\n",
    "    # Custom error to show messages to participants\n",
    "    pass\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, intermediate_res:list = []) -> float:\n",
    "    \"\"\"\n",
    "    Calculates a custom evaluation metric (volatility-adjusted Sharpe ratio).\n",
    "\n",
    "    This metric penalizes strategies that take on significantly more volatility\n",
    "    than the underlying market.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated adjusted Sharpe ratio.\n",
    "    \"\"\"\n",
    "    solution = solution.copy().reset_index(drop=True)\n",
    "    submission = submission.copy().reset_index(drop=True)\n",
    "    solution['position'] = submission['prediction']\n",
    "\n",
    "    # ありえない値を除外する (0 <= position <= 2)\n",
    "        # 0 means that we don't invest in S & P at all but get only the risk-free rate.\n",
    "        # 1 means that we invest all our money in S & P.\n",
    "        # 2 means that we invest twice our capital in S & P while taking a credit at the risk-free rate.\n",
    "        # -> つまり，普通に預金するか，S&Pに投資するか，S&Pに2倍レバレッジで投資するか（借金）の割合\n",
    "    if solution['position'].max() > MAX_SIGNAL:\n",
    "        raise ParticipantVisibleError(f'Position of {solution[\"position\"].max()} exceeds maximum of {MAX_SIGNAL}')\n",
    "    if solution['position'].min() < MIN_SIGNAL:\n",
    "        raise ParticipantVisibleError(f'Position of {solution[\"position\"].min()} below minimum of {MIN_SIGNAL}')\n",
    "\n",
    "    # Calculate strategy returns\n",
    "    # フェデラルファンド金利(利息) * (1-予測値) + 予測値 * S&P500の翌日のリターン = 戦略のリターン(割合)\n",
    "    solution['strategy_returns'] = solution['risk_free_rate'] * (1 - solution['position']) + solution['position'] * solution['forward_returns']\n",
    "\n",
    "    # Calculate strategy's Sharpe ratio\n",
    "    # リターンとその標準偏差を用いてシャープレシオ（リスクあたりの効率）を計算\n",
    "    strategy_excess_returns = solution['strategy_returns'] - solution['risk_free_rate'] # 超過リターン -> 今回の戦略で得た割合から，リスクフリー時の割合を引いた分\n",
    "    strategy_excess_cumulative = (1 + strategy_excess_returns).prod() # 累積超過リターン -> 全期間の超過リターンをかけ合わせた分(1+で倍率に変換)\n",
    "    strategy_mean_excess_return = (strategy_excess_cumulative) ** (1 / len(solution)) - 1 # 平均超過リターン -> 複利は幾何平均で求める． また，倍率から割合に戻してる\n",
    "    strategy_std = solution['strategy_returns'].std() # リターンの標準偏差\n",
    "\n",
    "    trading_days_per_yr = 252 # 1年あたりの取引日数(固定値)\n",
    "    if strategy_std == 0:\n",
    "        raise ZeroDivisionError\n",
    "    sharpe = strategy_mean_excess_return / strategy_std * np.sqrt(trading_days_per_yr) # 年率換算したシャープレシオ. sqrt(252)をかけることで年率換算している（統計的な性質らしい）\n",
    "    strategy_volatility = float(strategy_std * np.sqrt(trading_days_per_yr) * 100)  # 年率換算したボラティリティ(価格変動率)\n",
    "\n",
    "    # Calculate market return and volatility\n",
    "    # S&P500に投資し続けた場合のリターンとボラティリティを計算\n",
    "    market_excess_returns = solution['forward_returns'] - solution['risk_free_rate'] # S&P500が利息を上回る割合\n",
    "    market_excess_cumulative = (1 + market_excess_returns).prod() # ↑の累積\n",
    "    market_mean_excess_return = (market_excess_cumulative) ** (1 / len(solution)) - 1 # train: 0.0003066067595838273 幾何平均，割合化\n",
    "    market_std = solution['forward_returns'].std() # S&P500のリターンの標準偏差\n",
    "    \n",
    "    market_volatility = float(market_std * np.sqrt(trading_days_per_yr) * 100) # train: 16.748459963166347 %\n",
    "    \n",
    "    # Calculate the volatility penalty\n",
    "    # ボラティリティペナルティを計算\n",
    "    # -> 市場のボラティリティの1.2倍を超える場合のペナルティ\n",
    "    excess_vol = max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n",
    "    vol_penalty = 1 + excess_vol\n",
    "\n",
    "    # Calculate the return penalty\n",
    "    # リターンペナルティを計算\n",
    "    # -> 市場のリターンを下回る場合のペナルティ\n",
    "    return_gap = max(\n",
    "        0,\n",
    "        (market_mean_excess_return - strategy_mean_excess_return) * 100 * trading_days_per_yr,\n",
    "    )\n",
    "    return_penalty = 1 + (return_gap**2) / 100\n",
    "\n",
    "    # Adjust the Sharpe ratio by the volatility and return penalty\n",
    "    # ペナルティ値の反映\n",
    "    adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n",
    "\n",
    "    # print(\"strategy_excess_returns NaN数:\", solution['strategy_returns'].isna().sum())\n",
    "    # print(\"strategy_std:\", strategy_std)\n",
    "    # print(\"strategy_excess_cumulative:\", strategy_excess_cumulative)\n",
    "    # print(\"market_excess_cumulative:\", market_excess_cumulative)\n",
    "    # print(\"adjusted_sharpe:\", adjusted_sharpe)\n",
    "    try:\n",
    "        intermediate_res.append((strategy_mean_excess_return, strategy_std, sharpe, vol_penalty, return_penalty)) # 各値を記録(debug)\n",
    "        return min(float(adjusted_sharpe), 1_000_000), intermediate_res # float変換，上限100万\n",
    "    except NameError:\n",
    "        return min(float(adjusted_sharpe), 1_000_000) # float変換，上限100万"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836dbfa5",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "dc41edeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _annualize(sigma_daily): return sigma_daily * np.sqrt(252.0)\n",
    "\n",
    "def _vol_target_scaler(sigma_daily: np.ndarray, gamma=1.10, lev_cap=2.0) -> np.ndarray:\n",
    "    sigma_ann = _annualize(sigma_daily)\n",
    "    sigma_ref = np.median(sigma_ann)  # 参照（fold内で一定）\n",
    "    sigma_star = gamma * sigma_ref\n",
    "    return np.minimum(lev_cap, sigma_star / (sigma_ann + 1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "80c432d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_m_from_z(z, m_lo=1.0, m_hi=3.0, Tm=1.2):\n",
    "    return m_lo + (m_hi - m_lo) * np.tanh(np.abs(z) / Tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "65d568a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conf_m_from_z_abs(z: np.ndarray, m_lo=1.0, m_hi=3.0, Tm=1.2) -> np.ndarray:\n",
    "    # |z|が小さいと m→m_lo、大きいと m→m_hi\n",
    "    return m_lo + (m_hi - m_lo) * np.tanh(np.abs(z) / Tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9f0274f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _choose_m_soft_from_inner(z_inner: np.ndarray,\n",
    "                              T_soft: float = 0.9,\n",
    "                              target_clip: float = 0.22,\n",
    "                              m_bounds: tuple[float, float] = (0.5, 5.0)) -> float:\n",
    "    \"\"\"\n",
    "    inner の z 分布から m を自動選定。\n",
    "    1 + m*tanh(z/T_soft) が 0/2 に clip される割合が target_clip に近くなる m を選ぶ。\n",
    "    \"\"\"\n",
    "    z = np.asarray(z_inner).reshape(-1)\n",
    "    # 端に貼り付く条件: m * tanh(|z|/T_soft) >= 1\n",
    "    # ↔ tanh(|z|/T_soft) >= 1/m ↔ |z| >= T_soft * atanh(1/m)\n",
    "    def clip_rate_for(m: float) -> float:\n",
    "        thr = T_soft * np.arctanh(1.0 / max(m, 1.0 + 1e-9)) if m > 1.0 else np.inf\n",
    "        if not np.isfinite(thr):  # m<=1 → ほぼ貼り付きゼロ\n",
    "            return 0.0\n",
    "        return float(np.mean(np.abs(z) >= thr))\n",
    "\n",
    "    lo, hi = m_bounds\n",
    "    # 粗探索 + 二分探索で target_clip に近づける\n",
    "    grid = np.linspace(lo, hi, 20)\n",
    "    vals = np.array([clip_rate_for(m) for m in grid])\n",
    "    m0 = float(grid[np.argmin(np.abs(vals - target_clip))])\n",
    "\n",
    "    # 近傍を二分探索\n",
    "    m_lo, m_hi = max(lo, m0 - 0.5), min(hi, m0 + 0.5)\n",
    "    for _ in range(12):\n",
    "        m_mid = 0.5 * (m_lo + m_hi)\n",
    "        cr = clip_rate_for(m_mid)\n",
    "        if cr > target_clip:\n",
    "            m_lo = m_mid\n",
    "        else:\n",
    "            m_hi = m_mid\n",
    "    return float(np.clip(0.5 * (m_lo + m_hi), *m_bounds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f19f11e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_static_calibration(y_pred_inner: np.ndarray, std_scale: float = 2.0) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    inner の予測から z 正規化に使う (b, T) を決定。\n",
    "    b: 中央値、 T: std_scale * 標準偏差（極小分散の安全弁付き）\n",
    "    \"\"\"\n",
    "    y = np.asarray(y_pred_inner).reshape(-1)\n",
    "    b = float(np.median(y))\n",
    "    s = float(np.std(y, ddof=1))\n",
    "    T = max(s * std_scale, 1e-8)  # ほぼ一定やゼロ分散の安全弁\n",
    "    return b, T\n",
    "\n",
    "def soft_convert_ret_to_signal_from_z(\n",
    "    z: np.ndarray,\n",
    "    params: RetToSignalParameters,\n",
    "    *,\n",
    "    m: float = 5.0,\n",
    "    T_soft: float = 0.7\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    z を soft-clip で [0,2] に変換（中心1.0、振幅は m と T_soft で調整）\n",
    "    p = clip( 1 + m * tanh(z / T_soft), min, max )\n",
    "    \"\"\"\n",
    "    raw = 1.0 + m * np.tanh(z / T_soft)\n",
    "    return np.clip(raw, params.min_signal, params.max_signal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d54d97c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rolling_vol_no_leak(fr: pd.Series, window_size: int) -> np.ndarray:\n",
    "    # 過去のみ参照（center=False）。窓不足の序盤は expanding std で埋める（未来は使わない）\n",
    "    roll = fr.rolling(window=window_size, min_periods=window_size, center=False).std()\n",
    "    # 序盤: 窓不足部分（NaN）を expanding std で補う（過去のみ）\n",
    "    expd = fr.expanding(min_periods=2).std()  # 1点ではstdはNaNのまま\n",
    "    vol = roll.combine_first(expd).bfill(limit=0)  # bfill(limit=0) 実質何もしない（安全のため残す）\n",
    "    return vol.to_numpy()\n",
    "\n",
    "def _ewma_vol_series(fr: pd.Series, lam: float = 0.94, min_periods: int = 2) -> np.ndarray:\n",
    "    # EWMA分散 → 平方根でボラ。adjust=False で再帰形（オンライン更新と等価）\n",
    "    var = (fr**2).ewm(alpha=1 - lam, adjust=False, min_periods=min_periods).mean()\n",
    "    return np.sqrt(var).to_numpy()\n",
    "\n",
    "def calculate_volatility_scaling_factor(\n",
    "    y_pred: np.ndarray,\n",
    "    solution: pd.DataFrame,\n",
    "    window_size: int = 30,\n",
    "    *,\n",
    "    vol_mode: str = \"ewma\",         # \"rolling\" or \"ewma\"\n",
    "    lambda_ewma: float = 0.94,\n",
    "    k_grid: np.ndarray | None = None,\n",
    "    alpha_grid: np.ndarray | None = None,\n",
    "    eps: float = 1e-6,\n",
    "    lambda_reg: float = 0.0\n",
    ") -> tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    ボラ依存スケーリング:\n",
    "        m_t = k / (sigma_t + eps)^alpha\n",
    "    を inner データ上で score() 最大化となる (k, alpha) を探索。\n",
    "\n",
    "    Args:\n",
    "        y_pred: inner 区間のモデル予測（len == len(solution)）\n",
    "        solution: 'forward_returns', 'risk_free_rate' を持つ DataFrame（inner 区間）\n",
    "        window_size: rolling 用の窓\n",
    "        vol_mode: \"rolling\" or \"ewma\"\n",
    "        lambda_ewma: EWMA の λ\n",
    "        k_grid, alpha_grid: 探索グリッド（未指定なら内部既定）\n",
    "        eps: ゼロ除算回避\n",
    "        lambda_reg: L2 正則化強度\n",
    "\n",
    "    Returns:\n",
    "        best_k (float)     :  最適化された k の値\n",
    "        best_alpha (float) :  最適化された α の値\n",
    "        best_score (float) :  最適化されたときの報酬値\n",
    "    \"\"\"\n",
    "    # 入力検証\n",
    "    y_pred = np.asarray(y_pred).reshape(-1)\n",
    "    if not {\"forward_returns\", \"risk_free_rate\"}.issubset(solution.columns):\n",
    "        raise ValueError(\"solution must have columns: forward_returns, risk_free_rate\")\n",
    "    if len(y_pred) != len(solution):\n",
    "        raise ValueError(f\"Length mismatch: y_pred={len(y_pred)} vs solution={len(solution)}\")\n",
    "\n",
    "    fr = solution[\"forward_returns\"]\n",
    "\n",
    "    # ボラ計算\n",
    "    if vol_mode == \"rolling\":\n",
    "        market_vol = _rolling_vol_no_leak(fr, window_size=window_size)\n",
    "    elif vol_mode == \"ewma\":\n",
    "        market_vol = _ewma_vol_series(fr, lam=lambda_ewma, min_periods=max(2, int(window_size // 4)))\n",
    "    else:\n",
    "        raise ValueError(\"vol_mode must be 'rolling' or 'ewma'\")\n",
    "\n",
    "    # グリッド定義\n",
    "    if k_grid is None:\n",
    "        k_grid = np.logspace(-4, np.log10(1.0), 20)  # kの探索範囲:10^-4 ~ 1.0までを20ステップ\n",
    "    if alpha_grid is None:\n",
    "        alpha_grid = np.linspace(0, 1.0, 5)  # αの探索範囲とステップ\n",
    "\n",
    "\n",
    "    best_score = -np.inf\n",
    "    best_k = None\n",
    "    best_alpha = None\n",
    "\n",
    "    for k in k_grid:\n",
    "        for alpha in alpha_grid:\n",
    "            m_t = k / np.power(market_vol + eps, alpha)\n",
    "            # 戦略(0-2)に変換：convert_ret_to_signal がベクトルmultiplier非対応なら、先に y_pred*m_t を計算して渡す\n",
    "            alloc = convert_ret_to_signal(y_pred, ret_signal_params, signal_multiplier=m_t)\n",
    "            sub = pd.DataFrame({\"prediction\": alloc}).reset_index(drop=True)\n",
    "            s, _ = score(solution, sub, \"\", [])\n",
    "            if lambda_reg > 0:\n",
    "                s -= lambda_reg * (k**2 + alpha**2)\n",
    "            if s > best_score:\n",
    "                best_score, best_k, best_alpha = s, float(k), float(alpha)\n",
    "                # print(f\"New best score: {best_score:.6f} (k={best_k:.6f}, alpha={best_alpha:.6f})\")\n",
    "\n",
    "    return float(best_k), float(best_alpha), float(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9cb9f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_sigma_for_period(fr_all: np.ndarray, start: int, end: int,\n",
    "                           mode=\"ewma\", lam=0.94, window=30) -> np.ndarray:\n",
    "    \"\"\" [start, end) 用の σ_t を、直前の過去だけを使って作る（リークなし）。 \"\"\"\n",
    "    warm = max(window, 20)\n",
    "    prefix_start = max(0, start - warm)\n",
    "    fr_prefix = fr_all[prefix_start:start]\n",
    "    fr_period  = fr_all[start:end]\n",
    "    fr_concat  = np.concatenate([fr_prefix, fr_period])\n",
    "    s = pd.Series(fr_concat)\n",
    "    if mode == \"rolling\":\n",
    "        sigma_all = _rolling_vol_no_leak(s, window_size=window)\n",
    "    elif mode == \"ewma\":\n",
    "        sigma_all = _ewma_vol_series(s, lam=lam, min_periods=max(2, window//4))\n",
    "    else:\n",
    "        raise ValueError(\"vol_mode must be 'rolling' or 'ewma'\")\n",
    "    return sigma_all[-(end - start):]  # 期間ぶんだけ取り出す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4d1585ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list_dict = {}\n",
    "def cross_validate(allocation_model, label=\"\", min_train_size=3000, test_size=180):\n",
    "    \"\"\"\n",
    "    時系列を考慮した交差検証を行う\n",
    "    検証インデックス：\n",
    "    range(len(train) - test_size, min_train_size, - test_size)\n",
    "    例えば、trainデータが2000行、test_size=120、min_train_size=1500の場合、\n",
    "    検証用のインデックスは：\n",
    "    range(2000 - 120, 1500, -120) = range(1880, 1500, -120)\n",
    "    = (1880, 1760, 1640, 1520)\n",
    "    となり、各foldで未来のデータを使用せずに評価することができる．\n",
    "    trainサイズはfoldが進む毎に減少し，min_train_sizeに達したら終了する．\n",
    "    減少させているのは未来リークを防ぐため．\n",
    "    \"\"\"\n",
    "    n = len(train)\n",
    "    oof = np.full(n, np.nan, dtype=float)\n",
    "    score_list = []\n",
    "    intermediate_res = []\n",
    "    val_list = []\n",
    "\n",
    "    # ===== 前処理（1回だけ） =====\n",
    "    # 学習に使わない列を除いた特徴量列を一度だけ確定\n",
    "    drop_cols = [\"date_id\", \"forward_returns\", \"risk_free_rate\", \"market_forward_excess_returns\"]\n",
    "    feature_cols = [c for c in train.columns if c not in drop_cols]\n",
    "\n",
    "    # 必要列を配列/ビューで保持（コピー最小化）\n",
    "    X_all = train[feature_cols]                  # DataFrame（ループ内は iloc でビュー切り）\n",
    "    y_all = train[\"forward_returns\"].to_numpy()  # 1D ndarray\n",
    "    rfr_all = train[\"risk_free_rate\"].to_numpy() # 1D ndarray\n",
    "\n",
    "    # バリデーション（固定で最後180）を一度だけ切り出し\n",
    "    val_idx_start = max(0, n - 180)\n",
    "    X_val = X_all.iloc[val_idx_start:]\n",
    "    y_val = y_all[val_idx_start:]\n",
    "    v_sol = pd.DataFrame(\n",
    "        {\n",
    "            \"forward_returns\": y_all[val_idx_start:],\n",
    "            \"risk_free_rate\":  rfr_all[val_idx_start:],\n",
    "        }\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    for fold, test_start in enumerate(\n",
    "        range(n - test_size, min_train_size, -test_size)\n",
    "    ):\n",
    "        print(Fore.CYAN + f\"=== Fold {fold} Test start at {test_start} ===\" + Style.RESET_ALL)\n",
    "        # 1. データ分割（中間DataFrameを作らず直接切る）\n",
    "        test_end = test_start + test_size\n",
    "\n",
    "        X_train = X_all.iloc[:test_start]\n",
    "        y_train = y_all[:test_start]\n",
    "\n",
    "        X_test = X_all.iloc[test_start:test_end]\n",
    "        y_test = y_all[test_start:test_end]  # 使わないが念のため残す（デバッグ等）\n",
    "        \n",
    "        # 評価用（score用のソリューション; 必要最小限のDF生成）\n",
    "        solution = pd.DataFrame(\n",
    "            {\n",
    "                \"forward_returns\": y_all[test_start:test_end],\n",
    "                \"risk_free_rate\":  rfr_all[test_start:test_end],\n",
    "            }\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "        # 1.5. SIGNALE_MULTIPLIER の最適化\n",
    "        # --- inner validation を train_fold の末尾から作る ---\n",
    "        inner_start = max(0, test_start - INNER_VAL_LEN)\n",
    "        X_inner = X_all.iloc[inner_start:test_start]\n",
    "        y_inner = y_all[inner_start:test_start]\n",
    "        sol_inner = pd.DataFrame({\n",
    "            \"forward_returns\": y_all[inner_start:test_start],\n",
    "            \"risk_free_rate\":  rfr_all[inner_start:test_start],\n",
    "        }).reset_index(drop=True)\n",
    "\n",
    "        # 2. モデル学習\n",
    "        allocation_model.fit(X_train, y_train)\n",
    "\n",
    "        # 2.5. inner validation で (k, alpha) を決定\n",
    "        y_pred_inner = allocation_model.predict(X_inner)\n",
    "        # best_k, best_alpha, best_score = calculate_volatility_scaling_factor(y_pred_inner, sol_inner)\n",
    "        b_z, T_z = _compute_static_calibration(y_pred_inner, std_scale=2.0)\n",
    "\n",
    "        # inner を z に変換\n",
    "        z_inner = (y_pred_inner - b_z) / T_z\n",
    "\n",
    "        M_SOFT   = 5.0   # レバ強度\n",
    "        T_SOFT   = 1.0   # tanh の温度（貼り付き率が高ければ↑、低ければ↓）\n",
    "\n",
    "        # ===== テスト区間の m_t を “再計算” して適用（リークなし） =====\n",
    "        # vol の作り方は calculate_volatility_scaling_factor と同じモード/パラメータに揃える\n",
    "        VOL_MODE = \"ewma\"       # or \"rolling\"\n",
    "        LAMBDA_EWMA = 0.94\n",
    "        WINDOW_SIZE = 30\n",
    "        EPS = 1e-6\n",
    "\n",
    "        # inner の z 分布から m を自動決定（目標貼り付き率 22% 程度）\n",
    "        M_SOFT = _choose_m_soft_from_inner(z_inner, T_soft=T_SOFT, target_clip=0.22)\n",
    "\n",
    "\n",
    "        # 3. 予測\n",
    "        y_pred = allocation_model.predict(X_test)\n",
    "        # z 正規化（inner で決めた b_z, T_z を固定して使う）\n",
    "        z_test = (y_pred - b_z) / T_z\n",
    "\n",
    "        # テスト用 σ_t と m_t（ベクトル）を作成\n",
    "        # sigma_test = _make_sigma_for_period(y_all, test_start, test_end,\n",
    "        #                                     mode=VOL_MODE, lam=LAMBDA_EWMA, window=WINDOW_SIZE)\n",
    "        # m_t_test = best_k / np.power(sigma_test + EPS, best_alpha)\n",
    "        # allocation_list = np.clip(y_pred, 0, 2)  # 投資比率は0から2の間にクリップ\n",
    "        # allocation_list = convert_ret_to_signal(y_pred, ret_signal_params, signal_multiplier=m_t_test)\n",
    "        # m_conf = _conf_m_from_z_abs(z_test, m_lo=1.0, m_hi=3.0, Tm=1.2)  # まずは控えめ\n",
    "        m_conf = conf_m_from_z(z_test, m_lo=1.0, m_hi=3.0, Tm=1.2)\n",
    "        p_soft = 1.0 + (m_conf * np.tanh(z_test / T_SOFT))\n",
    "        allocation_list = np.clip(p_soft, ret_signal_params.min_signal, ret_signal_params.max_signal)\n",
    "        # phase 4: ボラターゲット調整\n",
    "        sigma_test_daily = _make_sigma_for_period(y_all, test_start, test_end, mode=VOL_MODE, lam=LAMBDA_EWMA, window=WINDOW_SIZE)\n",
    "        ell_t = _vol_target_scaler(sigma_test_daily, gamma=1.10, lev_cap=2.0)\n",
    "        p_final = np.clip((allocation_list - 1.0) * ell_t + 1.0, 0.0, 2.0)\n",
    "        allocation_list = p_final\n",
    "\n",
    "        # 4. 評価\n",
    "        submission = pd.DataFrame({\"prediction\": allocation_list}).reset_index(drop=True)\n",
    "        validation_score, intermediate_res = score(\n",
    "            solution, submission, \"\", intermediate_res\n",
    "        )\n",
    "\n",
    "        pred_val = allocation_model.predict(X_val)\n",
    "        z_val = (pred_val - b_z) / T_z\n",
    "\n",
    "        # m_conf = _conf_m_from_z_abs(z_test, m_lo=1.0, m_hi=3.0, Tm=1.2)  # まずは控えめ\n",
    "        m_conf = conf_m_from_z(z_test, m_lo=1.0, m_hi=3.0, Tm=1.2)\n",
    "        p_soft = 1.0 + (m_conf * np.tanh(z_test / T_SOFT))\n",
    "        val_allocation_list = np.clip(p_soft, ret_signal_params.min_signal, ret_signal_params.max_signal)\n",
    "\n",
    "        # phase 4: ボラターゲット調整\n",
    "        sigma_val_daily = _make_sigma_for_period(y_all, val_idx_start, n, mode=VOL_MODE, lam=LAMBDA_EWMA, window=WINDOW_SIZE)\n",
    "        ell_t_val = _vol_target_scaler(sigma_val_daily, gamma=1.10, lev_cap=2.0)\n",
    "        p_final_val = np.clip((val_allocation_list - 1.0) * ell_t_val + 1.0, 0.0, 2.0)\n",
    "        val_allocation_list = p_final_val\n",
    "\n",
    "        clip0 = np.mean(allocation_list <= ret_signal_params.min_signal) * 100\n",
    "        clip2 = np.mean(allocation_list >= ret_signal_params.max_signal) * 100\n",
    "        print(f\"[inner] M_SOFT={M_SOFT:.3f}, T_SOFT={T_SOFT:.2f}, target clip≈22%\")\n",
    "        print(f\"[test ] clip@0={clip0:.2f}% clip@2={clip2:.2f}%\")\n",
    "\n",
    "\n",
    "        # val_start = val_idx_start\n",
    "        # val_end   = n\n",
    "        # sigma_val = _make_sigma_for_period(y_all, val_start, val_end,\n",
    "        #                                 mode=VOL_MODE, lam=LAMBDA_EWMA, window=WINDOW_SIZE)\n",
    "        # m_t_val = best_k / np.power(sigma_val + EPS, best_alpha)\n",
    "\n",
    "        # val_allocation_list = convert_ret_to_signal(pred_val, ret_signal_params, signal_multiplier=m_t_val)\n",
    "        val_submission = pd.DataFrame({\"prediction\": val_allocation_list}).reset_index(drop=True)\n",
    "        val_score, inter = score(\n",
    "            v_sol, val_submission, \"\", intermediate_res\n",
    "        )\n",
    "        if inter:\n",
    "            strat_mu, strat_std, sharpe, vol_pen, ret_pen = inter[-1]\n",
    "            print(f\"[last180] sharpe={sharpe:.3f} vol_pen={vol_pen:.2f} ret_pen={ret_pen:.2f}\")\n",
    "        lo = np.mean(val_allocation_list <= 0.0)\n",
    "        hi = np.mean(val_allocation_list >= 2.0)\n",
    "        print(f\"[last180] clip@0={lo:.2%}, clip@2={hi:.2%}\")\n",
    "        \n",
    "        vol_penalty = intermediate_res[-1][3]   # ボラティリティペナルティ\n",
    "        return_penalty = intermediate_res[-1][4]# リターンペナルティ\n",
    "        \n",
    "        clip0 = np.mean(allocation_list <= ret_signal_params.min_signal) * 100\n",
    "        clip2 = np.mean(allocation_list >= ret_signal_params.max_signal) * 100\n",
    "        display(HTML(\n",
    "            f\"<p style='color: orange'>\"\n",
    "            f\"train(:{test_start:4}) test({test_start:4}:{test_end:4})<br>\"\n",
    "            f\"val_score: {validation_score:6.3f} {vol_penalty=:.2f} {return_penalty=:.2f}<br>\"\n",
    "            f\"score(submission): {val_score:.6f}<br>\"\n",
    "            f\"z-calib: b={b_z:.3e}, T={T_z:.3e}, M_SOFT={M_SOFT}, T_SOFT={T_SOFT}<br>\"\n",
    "            f\"clip@test: {clip0:.2f}% / {clip2:.2f}%\"\n",
    "            f\"</p>\"\n",
    "        ))\n",
    "        \n",
    "        oof[test_start:test_end] = allocation_list\n",
    "        score_list.append(validation_score)\n",
    "        val_list.append(val_score)\n",
    "\n",
    "        # 最初のfold modelを保存しておく\n",
    "        # if fold == 0:\n",
    "        #     submit_model = allocation_model\n",
    "        # else :\n",
    "        #     break\n",
    "\n",
    "    # ===== 集計表示 =====\n",
    "    submit_model = allocation_model\n",
    "    display(HTML('<h2 style=\"text-align:center;color:orange\">======== Result ========</h2>'))\n",
    "    avg_validation_score = float(np.nanmean(score_list)) if len(score_list) else np.nan\n",
    "    print(f\"{label} Average Validation Score: {avg_validation_score:.6f}\")\n",
    "    \n",
    "    # 全体スコア（インデックス揃え）\n",
    "    mask = np.isfinite(oof)\n",
    "    if np.any(mask):\n",
    "        solution_all = pd.DataFrame(\n",
    "            {\n",
    "                \"forward_returns\": y_all[mask],\n",
    "                \"risk_free_rate\":  rfr_all[mask],\n",
    "            }\n",
    "        ).reset_index(drop=True)\n",
    "        submission_all = pd.DataFrame({'prediction': oof[mask]}).reset_index(drop=True)\n",
    "        overall_score, intermediate_res = score(solution_all, submission_all, '', intermediate_res)\n",
    "        vol_penalty = intermediate_res[-1][3] if intermediate_res else np.nan\n",
    "        return_penalty = intermediate_res[-1][4] if intermediate_res else np.nan\n",
    "        print(f\"{label} Overall Validation Score: {overall_score:.6f} vol_penalty={vol_penalty:.2f} return_penalty={return_penalty:.2f}\")\n",
    "    else:\n",
    "        print(f\"{label} Overall Validation Score: NaN (no valid OOF)\")\n",
    "\n",
    "\n",
    "\n",
    "    score_list_dict[label] = score_list\n",
    "    # 1回目のfoldのスコアを示す\n",
    "    if score_list:\n",
    "        print(f\"{label} First(Test) Fold Validation Score: {score_list[0]:.6f}\")\n",
    "\n",
    "    if val_list:\n",
    "        print(Fore.YELLOW + f\"All(Test) Fold Validation Score : {(sum(val_list) / len(val_list)):6.3f}\" + Style.RESET_ALL)\n",
    "        \n",
    "\n",
    "    # 分布可視化\n",
    "    vals = oof[mask]\n",
    "    if len(vals):\n",
    "        vmin, vmax = float(np.min(vals)), float(np.max(vals))\n",
    "        if vmin == vmax:\n",
    "            vmax = vmin + 1e-6\n",
    "        bins = np.linspace(vmin, vmax, 50)\n",
    "        plt.figure(figsize=(6, 2))\n",
    "        plt.hist(vals, bins=bins, density=False, color='c', edgecolor='k', linewidth=0.5)\n",
    "        plt.title(f'Allocation histogram of {label}')\n",
    "        plt.gca().get_yaxis().set_visible(False)\n",
    "        plt.xlim(vmin, vmax)\n",
    "        plt.show()\n",
    "\n",
    "    print(f\"Range of predictions: [{vmin:.6f}, {vmax:.6f}]\")\n",
    "    \n",
    "    # SIGNAL_MULTIPLIER の算出（元ロジック踏襲）\n",
    "    # ※ oofの分布に依存するため、maskチェックを入れる\n",
    "    if np.any(mask):\n",
    "        span = min(MAX_SIGNAL - 1.0, 1.0 - MIN_SIGNAL)  # 0-2なら span=1.0\n",
    "        q = np.percentile(np.abs(oof[mask]), 99)        # 上位1%に合わせる\n",
    "        SIGNAL_MULTIPLIER = (0.95 * span) / max(q, 1e-12)\n",
    "        print(f\"multi::{SIGNAL_MULTIPLIER}\")\n",
    "    else:\n",
    "        print(\"multi::NaN (no valid OOF)\")\n",
    "    \n",
    "\n",
    "    return submit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a3ca9afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 0 Test start at 8810 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21575\n",
      "[LightGBM] [Info] Number of data points in the train set: 8810, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000468\n",
      "[inner] M_SOFT=1.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=0.00% clip@2=0.56%\n",
      "[last180] sharpe=0.431 vol_pen=1.09 ret_pen=1.00\n",
      "[last180] clip@0=0.00%, clip@2=0.56%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:8810) test(8810:8990)<br>val_score:  0.394 vol_penalty=1.09 return_penalty=1.00<br>score(submission): 0.393542<br>z-calib: b=1.083e-03, T=1.071e-02, M_SOFT=1.4211747018914473, T_SOFT=1.0<br>clip@test: 0.00% / 0.56%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 1 Test start at 8630 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21573\n",
      "[LightGBM] [Info] Number of data points in the train set: 8630, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000460\n",
      "[inner] M_SOFT=2.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=0.00% clip@2=1.11%\n",
      "[last180] sharpe=0.732 vol_pen=1.00 ret_pen=1.00\n",
      "[last180] clip@0=0.00%, clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:8630) test(8630:8810)<br>val_score:  1.161 vol_penalty=1.00 return_penalty=1.00<br>score(submission): 0.731819<br>z-calib: b=8.143e-04, T=1.021e-02, M_SOFT=2.4209305612664473, T_SOFT=1.0<br>clip@test: 0.00% / 1.11%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 2 Test start at 8450 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21575\n",
      "[LightGBM] [Info] Number of data points in the train set: 8450, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000453\n",
      "[inner] M_SOFT=2.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=0.00% clip@2=0.00%\n",
      "[last180] sharpe=0.192 vol_pen=1.00 ret_pen=1.19\n",
      "[last180] clip@0=0.56%, clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:8450) test(8450:8630)<br>val_score:  1.277 vol_penalty=1.00 return_penalty=1.19<br>score(submission): 0.162217<br>z-calib: b=4.493e-04, T=1.593e-02, M_SOFT=2.4209305612664473, T_SOFT=1.0<br>clip@test: 0.00% / 0.00%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 3 Test start at 8270 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21574\n",
      "[LightGBM] [Info] Number of data points in the train set: 8270, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000440\n",
      "[inner] M_SOFT=2.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=0.00% clip@2=0.00%\n",
      "[last180] sharpe=0.501 vol_pen=1.00 ret_pen=1.00\n",
      "[last180] clip@0=0.00%, clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:8270) test(8270:8450)<br>val_score:  1.388 vol_penalty=1.00 return_penalty=1.00<br>score(submission): 0.500906<br>z-calib: b=-1.793e-03, T=2.767e-02, M_SOFT=2.4209305612664473, T_SOFT=1.0<br>clip@test: 0.00% / 0.00%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 4 Test start at 8090 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21569\n",
      "[LightGBM] [Info] Number of data points in the train set: 8090, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000468\n",
      "[inner] M_SOFT=1.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=2.22% clip@2=13.89%\n",
      "[last180] sharpe=-0.030 vol_pen=1.20 ret_pen=1.76\n",
      "[last180] clip@0=2.78%, clip@2=13.89%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:8090) test(8090:8270)<br>val_score: -0.425 vol_penalty=1.20 return_penalty=1.76<br>score(submission): -0.014075<br>z-calib: b=1.035e-03, T=1.344e-02, M_SOFT=1.4211747018914473, T_SOFT=1.0<br>clip@test: 2.22% / 13.89%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 5 Test start at 7910 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21568\n",
      "[LightGBM] [Info] Number of data points in the train set: 7910, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000465\n",
      "[inner] M_SOFT=2.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=0.56% clip@2=0.56%\n",
      "[last180] sharpe=1.049 vol_pen=1.00 ret_pen=1.00\n",
      "[last180] clip@0=2.22%, clip@2=2.22%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:7910) test(7910:8090)<br>val_score:  1.648 vol_penalty=1.00 return_penalty=1.00<br>score(submission): 1.048953<br>z-calib: b=1.187e-03, T=1.647e-02, M_SOFT=2.4209305612664473, T_SOFT=1.0<br>clip@test: 0.56% / 0.56%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 6 Test start at 7730 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21566\n",
      "[LightGBM] [Info] Number of data points in the train set: 7730, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000448\n",
      "[inner] M_SOFT=2.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=0.56% clip@2=0.00%\n",
      "[last180] sharpe=0.488 vol_pen=1.00 ret_pen=1.01\n",
      "[last180] clip@0=0.56%, clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:7730) test(7730:7910)<br>val_score:  1.234 vol_penalty=1.00 return_penalty=1.01<br>score(submission): 0.481495<br>z-calib: b=2.587e-03, T=3.248e-02, M_SOFT=2.4209305612664473, T_SOFT=1.0<br>clip@test: 0.56% / 0.00%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 7 Test start at 7550 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21508\n",
      "[LightGBM] [Info] Number of data points in the train set: 7550, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000434\n",
      "[inner] M_SOFT=2.658, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=6.67% clip@2=2.22%\n",
      "[last180] sharpe=-0.272 vol_pen=1.19 ret_pen=3.11\n",
      "[last180] clip@0=3.33%, clip@2=2.22%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:7550) test(7550:7730)<br>val_score:  0.506 vol_penalty=1.19 return_penalty=3.11<br>score(submission): -0.073306<br>z-calib: b=8.357e-04, T=1.303e-02, M_SOFT=2.6577726665296053, T_SOFT=1.0<br>clip@test: 6.67% / 2.22%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 8 Test start at 7370 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21444\n",
      "[LightGBM] [Info] Number of data points in the train set: 7370, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000428\n",
      "[inner] M_SOFT=2.895, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=0.00% clip@2=1.11%\n",
      "[last180] sharpe=0.646 vol_pen=1.00 ret_pen=1.00\n",
      "[last180] clip@0=0.00%, clip@2=1.67%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:7370) test(7370:7550)<br>val_score:  1.188 vol_penalty=1.00 return_penalty=1.00<br>score(submission): 0.645925<br>z-calib: b=5.347e-04, T=1.835e-02, M_SOFT=2.894614771792763, T_SOFT=1.0<br>clip@test: 0.00% / 1.11%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 9 Test start at 7190 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21383\n",
      "[LightGBM] [Info] Number of data points in the train set: 7190, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000433\n",
      "[inner] M_SOFT=2.895, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=1.11% clip@2=1.11%\n",
      "[last180] sharpe=0.482 vol_pen=1.10 ret_pen=1.00\n",
      "[last180] clip@0=0.00%, clip@2=3.89%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:7190) test(7190:7370)<br>val_score:  0.244 vol_penalty=1.10 return_penalty=1.00<br>score(submission): 0.439233<br>z-calib: b=8.867e-04, T=1.578e-02, M_SOFT=2.894614771792763, T_SOFT=1.0<br>clip@test: 1.11% / 1.11%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 10 Test start at 7010 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21328\n",
      "[LightGBM] [Info] Number of data points in the train set: 7010, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000428\n",
      "[inner] M_SOFT=2.658, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=17.78% clip@2=1.67%\n",
      "[last180] sharpe=-0.187 vol_pen=1.00 ret_pen=2.39\n",
      "[last180] clip@0=16.67%, clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:7010) test(7010:7190)<br>val_score:  0.447 vol_penalty=1.00 return_penalty=2.39<br>score(submission): -0.078468<br>z-calib: b=5.039e-04, T=6.596e-03, M_SOFT=2.6577726665296053, T_SOFT=1.0<br>clip@test: 17.78% / 1.67%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 11 Test start at 6830 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21313\n",
      "[LightGBM] [Info] Number of data points in the train set: 6830, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score 0.000421\n",
      "[inner] M_SOFT=2.895, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=12.22% clip@2=0.00%\n",
      "[last180] sharpe=-0.486 vol_pen=1.00 ret_pen=3.53\n",
      "[last180] clip@0=18.89%, clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:6830) test(6830:7010)<br>val_score:  1.764 vol_penalty=1.00 return_penalty=3.53<br>score(submission): -0.137786<br>z-calib: b=6.169e-04, T=1.070e-02, M_SOFT=2.894614771792763, T_SOFT=1.0<br>clip@test: 12.22% / 0.00%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 12 Test start at 6650 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21261\n",
      "[LightGBM] [Info] Number of data points in the train set: 6650, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score 0.000413\n",
      "[inner] M_SOFT=1.184, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=6.11% clip@2=0.00%\n",
      "[last180] sharpe=0.426 vol_pen=1.00 ret_pen=1.02\n",
      "[last180] clip@0=5.56%, clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:6650) test(6650:6830)<br>val_score:  1.841 vol_penalty=1.00 return_penalty=1.02<br>score(submission): 0.418416<br>z-calib: b=1.568e-04, T=1.764e-02, M_SOFT=1.1843325966282894, T_SOFT=1.0<br>clip@test: 6.11% / 0.00%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 13 Test start at 6470 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21194\n",
      "[LightGBM] [Info] Number of data points in the train set: 6470, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score 0.000413\n",
      "[inner] M_SOFT=2.658, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=1.67% clip@2=0.00%\n",
      "[last180] sharpe=0.175 vol_pen=1.00 ret_pen=1.27\n",
      "[last180] clip@0=0.00%, clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:6470) test(6470:6650)<br>val_score:  1.355 vol_penalty=1.00 return_penalty=1.27<br>score(submission): 0.138013<br>z-calib: b=-6.219e-06, T=1.728e-02, M_SOFT=2.6577726665296053, T_SOFT=1.0<br>clip@test: 1.67% / 0.00%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 14 Test start at 6290 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21072\n",
      "[LightGBM] [Info] Number of data points in the train set: 6290, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score 0.000422\n",
      "[inner] M_SOFT=2.658, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=3.33% clip@2=0.00%\n",
      "[last180] sharpe=0.499 vol_pen=1.00 ret_pen=1.00\n",
      "[last180] clip@0=4.44%, clip@2=5.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:6290) test(6290:6470)<br>val_score:  0.432 vol_penalty=1.00 return_penalty=1.00<br>score(submission): 0.498781<br>z-calib: b=7.812e-04, T=1.149e-02, M_SOFT=2.6577726665296053, T_SOFT=1.0<br>clip@test: 3.33% / 0.00%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 15 Test start at 6110 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20660\n",
      "[LightGBM] [Info] Number of data points in the train set: 6110, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score 0.000424\n",
      "[inner] M_SOFT=1.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=17.78% clip@2=0.00%\n",
      "[last180] sharpe=0.613 vol_pen=1.00 ret_pen=1.01\n",
      "[last180] clip@0=17.78%, clip@2=0.56%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:6110) test(6110:6290)<br>val_score:  2.101 vol_penalty=1.00 return_penalty=1.01<br>score(submission): 0.608462<br>z-calib: b=6.949e-04, T=1.101e-02, M_SOFT=1.4211747018914473, T_SOFT=1.0<br>clip@test: 17.78% / 0.00%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 16 Test start at 5930 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20389\n",
      "[LightGBM] [Info] Number of data points in the train set: 5930, number of used features: 92\n",
      "[LightGBM] [Info] Start training from score 0.000415\n",
      "[inner] M_SOFT=1.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=11.67% clip@2=0.56%\n",
      "[last180] sharpe=0.166 vol_pen=1.00 ret_pen=1.31\n",
      "[last180] clip@0=23.33%, clip@2=0.56%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:5930) test(5930:6110)<br>val_score:  1.697 vol_penalty=1.00 return_penalty=1.31<br>score(submission): 0.127024<br>z-calib: b=1.536e-03, T=1.345e-02, M_SOFT=1.4211747018914473, T_SOFT=1.0<br>clip@test: 11.67% / 0.56%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 17 Test start at 5750 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5750, number of used features: 91\n",
      "[LightGBM] [Info] Start training from score 0.000396\n",
      "[inner] M_SOFT=2.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=2.22% clip@2=0.56%\n",
      "[last180] sharpe=0.159 vol_pen=1.00 ret_pen=1.31\n",
      "[last180] clip@0=3.33%, clip@2=1.11%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:5750) test(5750:5930)<br>val_score:  0.820 vol_penalty=1.00 return_penalty=1.31<br>score(submission): 0.121523<br>z-calib: b=1.261e-04, T=1.393e-02, M_SOFT=2.4209305612664473, T_SOFT=1.0<br>clip@test: 2.22% / 0.56%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 18 Test start at 5570 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19631\n",
      "[LightGBM] [Info] Number of data points in the train set: 5570, number of used features: 91\n",
      "[LightGBM] [Info] Start training from score 0.000394\n",
      "[inner] M_SOFT=2.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=0.00% clip@2=0.00%\n",
      "[last180] sharpe=0.053 vol_pen=1.00 ret_pen=1.49\n",
      "[last180] clip@0=0.00%, clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:5570) test(5570:5750)<br>val_score:  0.832 vol_penalty=1.00 return_penalty=1.49<br>score(submission): 0.035735<br>z-calib: b=6.307e-04, T=2.845e-02, M_SOFT=2.4209305612664473, T_SOFT=1.0<br>clip@test: 0.00% / 0.00%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 19 Test start at 5390 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19296\n",
      "[LightGBM] [Info] Number of data points in the train set: 5390, number of used features: 88\n",
      "[LightGBM] [Info] Start training from score 0.000394\n",
      "[inner] M_SOFT=2.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=9.44% clip@2=1.67%\n",
      "[last180] sharpe=0.898 vol_pen=1.00 ret_pen=1.00\n",
      "[last180] clip@0=6.67%, clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:5390) test(5390:5570)<br>val_score:  0.530 vol_penalty=1.00 return_penalty=1.00<br>score(submission): 0.898226<br>z-calib: b=1.426e-03, T=1.218e-02, M_SOFT=2.4209305612664473, T_SOFT=1.0<br>clip@test: 9.44% / 1.67%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 20 Test start at 5210 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19172\n",
      "[LightGBM] [Info] Number of data points in the train set: 5210, number of used features: 88\n",
      "[LightGBM] [Info] Start training from score 0.000362\n",
      "[inner] M_SOFT=1.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=1.11% clip@2=0.00%\n",
      "[last180] sharpe=0.468 vol_pen=1.00 ret_pen=1.02\n",
      "[last180] clip@0=1.67%, clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:5210) test(5210:5390)<br>val_score:  2.090 vol_penalty=1.00 return_penalty=1.02<br>score(submission): 0.458812<br>z-calib: b=7.857e-04, T=2.207e-02, M_SOFT=1.4211747018914473, T_SOFT=1.0<br>clip@test: 1.11% / 0.00%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 21 Test start at 5030 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19057\n",
      "[LightGBM] [Info] Number of data points in the train set: 5030, number of used features: 87\n",
      "[LightGBM] [Info] Start training from score 0.000377\n",
      "[inner] M_SOFT=2.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=0.56% clip@2=0.00%\n",
      "[last180] sharpe=0.591 vol_pen=1.00 ret_pen=1.00\n",
      "[last180] clip@0=0.00%, clip@2=2.78%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:5030) test(5030:5210)<br>val_score: -0.190 vol_penalty=1.00 return_penalty=1.00<br>score(submission): 0.591355<br>z-calib: b=2.612e-03, T=2.344e-02, M_SOFT=2.4209305612664473, T_SOFT=1.0<br>clip@test: 0.56% / 0.00%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 22 Test start at 4850 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18949\n",
      "[LightGBM] [Info] Number of data points in the train set: 4850, number of used features: 87\n",
      "[LightGBM] [Info] Start training from score 0.000312\n",
      "[inner] M_SOFT=2.184, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=0.00% clip@2=0.00%\n",
      "[last180] sharpe=0.556 vol_pen=1.00 ret_pen=1.00\n",
      "[last180] clip@0=0.00%, clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:4850) test(4850:5030)<br>val_score:  1.827 vol_penalty=1.00 return_penalty=1.00<br>score(submission): 0.556343<br>z-calib: b=-4.668e-04, T=4.508e-02, M_SOFT=2.1840884560032894, T_SOFT=1.0<br>clip@test: 0.00% / 0.00%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 23 Test start at 4670 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18896\n",
      "[LightGBM] [Info] Number of data points in the train set: 4670, number of used features: 87\n",
      "[LightGBM] [Info] Start training from score 0.000386\n",
      "[inner] M_SOFT=1.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=6.11% clip@2=13.33%\n",
      "[last180] sharpe=0.672 vol_pen=1.06 ret_pen=1.00\n",
      "[last180] clip@0=2.22%, clip@2=11.11%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:4670) test(4670:4850)<br>val_score: -0.662 vol_penalty=1.06 return_penalty=1.00<br>score(submission): 0.636425<br>z-calib: b=-4.671e-04, T=2.438e-02, M_SOFT=1.4211747018914473, T_SOFT=1.0<br>clip@test: 6.11% / 13.33%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 24 Test start at 4490 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18469\n",
      "[LightGBM] [Info] Number of data points in the train set: 4490, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.000442\n",
      "[inner] M_SOFT=1.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=2.22% clip@2=8.33%\n",
      "[last180] sharpe=0.857 vol_pen=1.00 ret_pen=1.00\n",
      "[last180] clip@0=3.89%, clip@2=3.89%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:4490) test(4490:4670)<br>val_score: -0.655 vol_penalty=1.00 return_penalty=1.00<br>score(submission): 0.856599<br>z-calib: b=8.973e-04, T=1.747e-02, M_SOFT=1.4211747018914473, T_SOFT=1.0<br>clip@test: 2.22% / 8.33%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 25 Test start at 4310 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18318\n",
      "[LightGBM] [Info] Number of data points in the train set: 4310, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.000444\n",
      "[inner] M_SOFT=1.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=1.67% clip@2=2.78%\n",
      "[last180] sharpe=0.439 vol_pen=1.00 ret_pen=1.00\n",
      "[last180] clip@0=3.33%, clip@2=6.67%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:4310) test(4310:4490)<br>val_score:  0.543 vol_penalty=1.00 return_penalty=1.00<br>score(submission): 0.438888<br>z-calib: b=9.581e-04, T=1.132e-02, M_SOFT=1.4211747018914473, T_SOFT=1.0<br>clip@test: 1.67% / 2.78%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 26 Test start at 4130 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18264\n",
      "[LightGBM] [Info] Number of data points in the train set: 4130, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.000425\n",
      "[inner] M_SOFT=2.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=1.67% clip@2=0.00%\n",
      "[last180] sharpe=0.132 vol_pen=1.00 ret_pen=1.28\n",
      "[last180] clip@0=2.78%, clip@2=1.11%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:4130) test(4130:4310)<br>val_score:  1.972 vol_penalty=1.00 return_penalty=1.28<br>score(submission): 0.103275<br>z-calib: b=7.277e-04, T=1.181e-02, M_SOFT=2.4209305612664473, T_SOFT=1.0<br>clip@test: 1.67% / 0.00%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 27 Test start at 3950 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17761\n",
      "[LightGBM] [Info] Number of data points in the train set: 3950, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.000430\n",
      "[inner] M_SOFT=2.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=2.22% clip@2=0.56%\n",
      "[last180] sharpe=0.460 vol_pen=1.00 ret_pen=1.01\n",
      "[last180] clip@0=5.56%, clip@2=0.56%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:3950) test(3950:4130)<br>val_score:  1.281 vol_penalty=1.00 return_penalty=1.01<br>score(submission): 0.456916<br>z-calib: b=6.257e-04, T=1.172e-02, M_SOFT=2.4209305612664473, T_SOFT=1.0<br>clip@test: 2.22% / 0.56%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 28 Test start at 3770 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17476\n",
      "[LightGBM] [Info] Number of data points in the train set: 3770, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.000444\n",
      "[inner] M_SOFT=1.184, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=1.11% clip@2=0.00%\n",
      "[last180] sharpe=0.739 vol_pen=1.00 ret_pen=1.00\n",
      "[last180] clip@0=1.11%, clip@2=0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:3770) test(3770:3950)<br>val_score:  0.043 vol_penalty=1.00 return_penalty=1.00<br>score(submission): 0.739343<br>z-calib: b=1.130e-03, T=1.344e-02, M_SOFT=1.1843325966282894, T_SOFT=1.0<br>clip@test: 1.11% / 0.00%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 29 Test start at 3590 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17231\n",
      "[LightGBM] [Info] Number of data points in the train set: 3590, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score 0.000440\n",
      "[inner] M_SOFT=1.184, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=3.33% clip@2=3.33%\n",
      "[last180] sharpe=0.548 vol_pen=1.00 ret_pen=1.00\n",
      "[last180] clip@0=7.22%, clip@2=1.67%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:3590) test(3590:3770)<br>val_score:  0.717 vol_penalty=1.00 return_penalty=1.00<br>score(submission): 0.548358<br>z-calib: b=9.818e-04, T=1.408e-02, M_SOFT=1.1843325966282894, T_SOFT=1.0<br>clip@test: 3.33% / 3.33%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 30 Test start at 3410 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17027\n",
      "[LightGBM] [Info] Number of data points in the train set: 3410, number of used features: 85\n",
      "[LightGBM] [Info] Start training from score 0.000425\n",
      "[inner] M_SOFT=2.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=0.56% clip@2=0.00%\n",
      "[last180] sharpe=0.984 vol_pen=1.00 ret_pen=1.00\n",
      "[last180] clip@0=0.00%, clip@2=0.56%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:3410) test(3410:3590)<br>val_score:  1.493 vol_penalty=1.00 return_penalty=1.00<br>score(submission): 0.984098<br>z-calib: b=5.989e-04, T=2.500e-02, M_SOFT=2.4209305612664473, T_SOFT=1.0<br>clip@test: 0.56% / 0.00%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 31 Test start at 3230 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16840\n",
      "[LightGBM] [Info] Number of data points in the train set: 3230, number of used features: 83\n",
      "[LightGBM] [Info] Start training from score 0.000411\n",
      "[inner] M_SOFT=2.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=0.00% clip@2=0.00%\n",
      "[last180] sharpe=0.680 vol_pen=1.00 ret_pen=1.00\n",
      "[last180] clip@0=0.56%, clip@2=0.56%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:3230) test(3230:3410)<br>val_score:  0.724 vol_penalty=1.00 return_penalty=1.00<br>score(submission): 0.680483<br>z-calib: b=-1.602e-03, T=3.319e-02, M_SOFT=2.4209305612664473, T_SOFT=1.0<br>clip@test: 0.00% / 0.00%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 32 Test start at 3050 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16764\n",
      "[LightGBM] [Info] Number of data points in the train set: 3050, number of used features: 83\n",
      "[LightGBM] [Info] Start training from score 0.000508\n",
      "[inner] M_SOFT=2.421, T_SOFT=1.00, target clip≈22%\n",
      "[test ] clip@0=1.11% clip@2=4.44%\n",
      "[last180] sharpe=1.084 vol_pen=1.00 ret_pen=1.00\n",
      "[last180] clip@0=0.56%, clip@2=17.22%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style='color: orange'>train(:3050) test(3050:3230)<br>val_score: -0.688 vol_penalty=1.00 return_penalty=1.00<br>score(submission): 1.084033<br>z-calib: b=-7.745e-05, T=2.348e-02, M_SOFT=2.4209305612664473, T_SOFT=1.0<br>clip@test: 1.11% / 4.44%</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2 style=\"text-align:center;color:orange\">======== Result ========</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Model Average Validation Score: 0.876673\n",
      "LightGBM Model Overall Validation Score: 0.463162 vol_penalty=1.04 return_penalty=1.00\n",
      "LightGBM Model First(Test) Fold Validation Score: 0.393542\n",
      "\u001b[33mAll(Test) Fold Validation Score :  0.457\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of predictions: [0.000000, 2.000000]\n",
      "multi::0.475\n"
     ]
    }
   ],
   "source": [
    "# 単純なLightGBMモデルで試す\n",
    "\n",
    "allocation_model = lgb.LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "submit_model = cross_validate(allocation_model, label=\"LightGBM Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427c0cc0",
   "metadata": {},
   "source": [
    "### Submission\n",
    "- time-series streaming形式\n",
    "- Kaggle サーバーから1batchずつ送られるデータからsubmission.parquetを返す\n",
    "- 返り値検証があるため，指定された形式で返す\n",
    "- 指定形式\n",
    "  - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "218685fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test: pl.DataFrame) -> float:\n",
    "    \"\"\"Replace this function with your inference code.\"\"\"\n",
    "    test_pd = test.to_pandas()\n",
    "    # display(test_pd.info())\n",
    "    if len(test_pd.columns) > 94:\n",
    "        test_pd = test_pd.drop(\n",
    "            [\"date_id\", \"is_scored\", \"lagged_forward_returns\", \"lagged_risk_free_rate\", \"lagged_market_forward_excess_returns\"], \n",
    "            axis = 1)\n",
    "    \n",
    "    preds = submit_model.predict(test_pd)\n",
    "    raw_pred: float = float(preds[0])\n",
    "    print(f\"predict:{raw_pred}\")\n",
    "    \n",
    "    # --- 出力（float or ndarray）---\n",
    "    # KaggleのAPI仕様上、float単体かSeries/DataFrameで返す必要あり float(preds[0]) if len(preds) == 1 else preds　\n",
    "    return convert_ret_to_signal(raw_pred, ret_signal_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4b05b6a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "GatewayRuntimeError",
     "evalue": "(<GatewayRuntimeErrorType.GATEWAY_RAISED_EXCEPTION: 5>, 'Traceback (most recent call last):\\n  File \"/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/base_gateway.py\", line 134, in run\\n    predictions, row_ids = self.get_all_predictions()\\n  File \"/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/base_gateway.py\", line 109, in get_all_predictions\\n    for data_batch, row_ids in self.generate_data_batches():\\n  File \"/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/default_gateway.py\", line 29, in generate_data_batches\\n    test = pl.read_csv(self.competition_data_dir / \\'test.csv\\')\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/_utils/deprecation.py\", line 128, in wrapper\\n    return function(*args, **kwargs)\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/_utils/deprecation.py\", line 128, in wrapper\\n    return function(*args, **kwargs)\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/_utils/deprecation.py\", line 128, in wrapper\\n    return function(*args, **kwargs)\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/io/csv/functions.py\", line 549, in read_csv\\n    df = _read_csv_impl(\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/io/csv/functions.py\", line 697, in _read_csv_impl\\n    pydf = PyDataFrame.read_csv(\\nFileNotFoundError: No such file or directory (os error 2): /kaggle/input/hull-tactical-market-prediction/test.csv\\n')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGatewayRuntimeError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[201], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     inference_server\u001b[38;5;241m.\u001b[39mserve()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     \u001b[43minference_server\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_local_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/hull-tactical-market-prediction/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/templates.py:110\u001b[0m, in \u001b[0;36mInferenceServer.run_local_gateway\u001b[0;34m(self, data_paths, file_share_dir, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver\u001b[38;5;241m.\u001b[39mstop(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/templates.py:108\u001b[0m, in \u001b[0;36mInferenceServer.run_local_gateway\u001b[0;34m(self, data_paths, file_share_dir, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_gateway_for_test(data_paths, file_share_dir, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/base_gateway.py:153\u001b[0m, in \u001b[0;36mBaseGateway.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_result(error)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# For local testing\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[0;31mGatewayRuntimeError\u001b[0m: (<GatewayRuntimeErrorType.GATEWAY_RAISED_EXCEPTION: 5>, 'Traceback (most recent call last):\\n  File \"/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/base_gateway.py\", line 134, in run\\n    predictions, row_ids = self.get_all_predictions()\\n  File \"/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/base_gateway.py\", line 109, in get_all_predictions\\n    for data_batch, row_ids in self.generate_data_batches():\\n  File \"/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/default_gateway.py\", line 29, in generate_data_batches\\n    test = pl.read_csv(self.competition_data_dir / \\'test.csv\\')\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/_utils/deprecation.py\", line 128, in wrapper\\n    return function(*args, **kwargs)\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/_utils/deprecation.py\", line 128, in wrapper\\n    return function(*args, **kwargs)\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/_utils/deprecation.py\", line 128, in wrapper\\n    return function(*args, **kwargs)\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/io/csv/functions.py\", line 549, in read_csv\\n    df = _read_csv_impl(\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/io/csv/functions.py\", line 697, in _read_csv_impl\\n    pydf = PyDataFrame.read_csv(\\nFileNotFoundError: No such file or directory (os error 2): /kaggle/input/hull-tactical-market-prediction/test.csv\\n')"
     ]
    }
   ],
   "source": [
    "# サーバー上でpredict(test_batch)を動かす\n",
    "inference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(('/kaggle/input/hull-tactical-market-prediction/',))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
