{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4da04843",
   "metadata": {},
   "source": [
    "# Hull Tactical Market Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2358dfe",
   "metadata": {},
   "source": [
    "### Import Libralies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "33e2c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "from colorama import Fore, Style\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "# Models\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Submission\n",
    "import polars as pl\n",
    "import kaggle_evaluation.default_inference_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e4c475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad54b45d",
   "metadata": {},
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b41dbf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ RETURNS TO SIGNAL CONFIGS ============\n",
    "MIN_SIGNAL: float = 0.0                         # Minimum value for the daily signal \n",
    "MAX_SIGNAL: float = 2.0                         # Maximum value for the daily signal \n",
    "SIGNAL_MULTIPLIER: float = 7.5                 # Multiplier of the OLS market forward excess returns predictions to signal \n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class RetToSignalParameters:\n",
    "    signal_multiplier: float \n",
    "    min_signal : float = MIN_SIGNAL\n",
    "    max_signal : float = MAX_SIGNAL\n",
    "\n",
    "ret_signal_params = RetToSignalParameters(\n",
    "    signal_multiplier= SIGNAL_MULTIPLIER\n",
    ")\n",
    "\n",
    "def convert_ret_to_signal(\n",
    "    ret_arr: np.ndarray,\n",
    "    params: RetToSignalParameters,\n",
    "    signal_multiplier=None\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts raw model predictions (expected returns) into a trading signal.\n",
    "\n",
    "    Args:\n",
    "        ret_arr (np.ndarray): The array of predicted returns.\n",
    "        params (RetToSignalParameters): Parameters for scaling and clipping the signal.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The resulting trading signal, clipped between min and max values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 予測値を基準に，投資戦略シグナルに変換\n",
    "    # ret * signal_multiplier + 1 を min_signal ~ max_signal の範囲にクリップ\n",
    "    if signal_multiplier is not None:\n",
    "        ret = np.clip(\n",
    "            ret_arr * signal_multiplier + 1, params.min_signal, params.max_signal\n",
    "        )\n",
    "    else:    \n",
    "        ret = np.clip(\n",
    "            ret_arr * params.signal_multiplier + 1, params.min_signal, params.max_signal\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        if ret.size < 20:\n",
    "            print(f\"submit::{ret}\")\n",
    "    except:\n",
    "        pass\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dfc2f554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ LOAD DATA ============\n",
    "# プラットフォームがkaggleかローカルかで分岐\n",
    "if os.getenv('KAGGLE_KERNEL_RUN_TYPE') is not None:\n",
    "    # Kaggle上\n",
    "    DATA_PATH: Path = Path('/kaggle/input/hull-tactical-market-prediction/')\n",
    "else:\n",
    "    BASE_PATH = Path.cwd()\n",
    "    DATA_PATH: Path = BASE_PATH / 'data'\n",
    "\n",
    "\n",
    "train = pd.read_csv(DATA_PATH / \"train.csv\")\n",
    "test = pd.read_csv(DATA_PATH / \"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ef6c12",
   "metadata": {},
   "source": [
    "### Scoreing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "862dff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticipantVisibleError(Exception):\n",
    "    # Custom error to show messages to participants\n",
    "    pass\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, intermediate_res:list = None) -> float:\n",
    "    \"\"\"\n",
    "    Calculates a custom evaluation metric (volatility-adjusted Sharpe ratio).\n",
    "\n",
    "    This metric penalizes strategies that take on significantly more volatility\n",
    "    than the underlying market.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated adjusted Sharpe ratio.\n",
    "    \"\"\"\n",
    "    solution = solution.copy().reset_index(drop=True)\n",
    "    submission = submission.copy().reset_index(drop=True)\n",
    "    solution['position'] = submission['prediction']\n",
    "\n",
    "    # ありえない値を除外する (0 <= position <= 2)\n",
    "        # 0 means that we don't invest in S & P at all but get only the risk-free rate.\n",
    "        # 1 means that we invest all our money in S & P.\n",
    "        # 2 means that we invest twice our capital in S & P while taking a credit at the risk-free rate.\n",
    "        # -> つまり，普通に預金するか，S&Pに投資するか，S&Pに2倍レバレッジで投資するか（借金）の割合\n",
    "    if solution['position'].max() > MAX_SIGNAL:\n",
    "        raise ParticipantVisibleError(f'Position of {solution[\"position\"].max()} exceeds maximum of {MAX_SIGNAL}')\n",
    "    if solution['position'].min() < MIN_SIGNAL:\n",
    "        raise ParticipantVisibleError(f'Position of {solution[\"position\"].min()} below minimum of {MIN_SIGNAL}')\n",
    "\n",
    "    # Calculate strategy returns\n",
    "    # フェデラルファンド金利(利息) * (1-予測値) + 予測値 * S&P500の翌日のリターン = 戦略のリターン(割合)\n",
    "    solution['strategy_returns'] = solution['risk_free_rate'] * (1 - solution['position']) + solution['position'] * solution['forward_returns']\n",
    "\n",
    "    # Calculate strategy's Sharpe ratio\n",
    "    # リターンとその標準偏差を用いてシャープレシオ（リスクあたりの効率）を計算\n",
    "    strategy_excess_returns = solution['strategy_returns'] - solution['risk_free_rate'] # 超過リターン -> 今回の戦略で得た割合から，リスクフリー時の割合を引いた分\n",
    "    strategy_excess_cumulative = (1 + strategy_excess_returns).prod() # 累積超過リターン -> 全期間の超過リターンをかけ合わせた分(1+で倍率に変換)\n",
    "    strategy_mean_excess_return = (strategy_excess_cumulative) ** (1 / len(solution)) - 1 # 平均超過リターン -> 複利は幾何平均で求める． また，倍率から割合に戻してる\n",
    "    strategy_std = solution['strategy_returns'].std() # リターンの標準偏差\n",
    "\n",
    "    trading_days_per_yr = 252 # 1年あたりの取引日数(固定値)\n",
    "    if strategy_std == 0:\n",
    "        raise ZeroDivisionError\n",
    "    sharpe = strategy_mean_excess_return / strategy_std * np.sqrt(trading_days_per_yr) # 年率換算したシャープレシオ. sqrt(252)をかけることで年率換算している（統計的な性質らしい）\n",
    "    strategy_volatility = float(strategy_std * np.sqrt(trading_days_per_yr) * 100)  # 年率換算したボラティリティ(価格変動率)\n",
    "\n",
    "    # Calculate market return and volatility\n",
    "    # S&P500に投資し続けた場合のリターンとボラティリティを計算\n",
    "    market_excess_returns = solution['forward_returns'] - solution['risk_free_rate'] # S&P500が利息を上回る割合\n",
    "    market_excess_cumulative = (1 + market_excess_returns).prod() # ↑の累積\n",
    "    market_mean_excess_return = (market_excess_cumulative) ** (1 / len(solution)) - 1 # train: 0.0003066067595838273 幾何平均，割合化\n",
    "    market_std = solution['forward_returns'].std() # S&P500のリターンの標準偏差\n",
    "    \n",
    "    market_volatility = float(market_std * np.sqrt(trading_days_per_yr) * 100) # train: 16.748459963166347 %\n",
    "    \n",
    "    # Calculate the volatility penalty\n",
    "    # ボラティリティペナルティを計算\n",
    "    # -> 市場のボラティリティの1.2倍を超える場合のペナルティ\n",
    "    excess_vol = max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n",
    "    vol_penalty = 1 + excess_vol\n",
    "\n",
    "    # Calculate the return penalty\n",
    "    # リターンペナルティを計算\n",
    "    # -> 市場のリターンを下回る場合のペナルティ\n",
    "    return_gap = max(\n",
    "        0,\n",
    "        (market_mean_excess_return - strategy_mean_excess_return) * 100 * trading_days_per_yr,\n",
    "    )\n",
    "    return_penalty = 1 + (return_gap**2) / 100\n",
    "\n",
    "    # Adjust the Sharpe ratio by the volatility and return penalty\n",
    "    # ペナルティ値の反映\n",
    "    adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n",
    "\n",
    "    # print(\"strategy_excess_returns NaN数:\", solution['strategy_returns'].isna().sum())\n",
    "    # print(\"strategy_std:\", strategy_std)\n",
    "    # print(\"strategy_excess_cumulative:\", strategy_excess_cumulative)\n",
    "    # print(\"market_excess_cumulative:\", market_excess_cumulative)\n",
    "    # print(\"adjusted_sharpe:\", adjusted_sharpe)\n",
    "    try:\n",
    "        intermediate_res.append((strategy_mean_excess_return, strategy_std, sharpe, vol_penalty, return_penalty)) # 各値を記録(debug)\n",
    "        return min(float(adjusted_sharpe), 1_000_000), intermediate_res # float変換，上限100万\n",
    "    except NameError:\n",
    "        return min(float(adjusted_sharpe), 1_000_000) # float変換，上限100万"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836dbfa5",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68cf4221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner validation は各 fold の train の末尾 180 を推奨（固定 val を使い回すより過学習が減る）\n",
    "inner_val_len = 180\n",
    "\n",
    "def _best_m_from_inner_val(y_pred_inner, sol_inner, m_grid=None, lambda_reg=0.0):\n",
    "    # m を粗く走査 → 近傍で微調整（高速で十分）\n",
    "    if m_grid is None:\n",
    "        m_grid = np.concatenate([\n",
    "            np.linspace(0.05, 0.5, 10),      # 小さめ\n",
    "            np.linspace(0.5, 2.0, 16),       # 中程度\n",
    "            np.linspace(2.0, 5.0, 7)         # 大きめ\n",
    "        ])\n",
    "    best_m, best_score = None, -np.inf\n",
    "    for m in m_grid:\n",
    "        alloc = convert_ret_to_signal(m * y_pred_inner, ret_signal_params)\n",
    "        sub = pd.DataFrame({\"prediction\": alloc}).reset_index(drop=True)\n",
    "        s, _ = score(sol_inner, sub, \"\", [])\n",
    "        s -= lambda_reg * (m**2)  # 過学習抑制したい場合\n",
    "        if s > best_score:\n",
    "            best_score, best_m = s, m\n",
    "\n",
    "    # 近傍で微調整（任意）\n",
    "    lo = max(0.01, best_m * 0.5); hi = best_m * 1.5\n",
    "    for m in np.linspace(lo, hi, 15):\n",
    "\n",
    "        \n",
    "        alloc = convert_ret_to_signal(m * y_pred_inner, ret_signal_params)\n",
    "        sub = pd.DataFrame({\"prediction\": alloc}).reset_index(drop=True)\n",
    "        s, _ = score(sol_inner, sub, \"\", [])\n",
    "        s -= lambda_reg * (m**2)\n",
    "        if s > best_score:\n",
    "            best_score, best_m = s, m\n",
    "    return float(best_m), float(best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c876fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1585ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list_dict = {}\n",
    "def cross_validate(allocation_model, label=\"\", min_train_size=1500, test_size=180):\n",
    "    \"\"\"\n",
    "    時系列を考慮した交差検証を行う\n",
    "    検証インデックス：\n",
    "    range(len(train) - test_size, min_train_size, - test_size)\n",
    "    例えば、trainデータが2000行、test_size=120、min_train_size=1500の場合、\n",
    "    検証用のインデックスは：\n",
    "    range(2000 - 120, 1500, -120) = range(1880, 1500, -120)\n",
    "    = (1880, 1760, 1640, 1520)\n",
    "    となり、各foldで未来のデータを使用せずに評価することができる．\n",
    "    trainサイズはfoldが進む毎に減少し，min_train_sizeに達したら終了する．\n",
    "    減少させているのは未来リークを防ぐため．\n",
    "    \"\"\"\n",
    "    n = len(train)\n",
    "    oof = np.full(n, np.nan, dtype=float)\n",
    "    score_list = []\n",
    "    intermediate_res = []\n",
    "    val_list = []\n",
    "\n",
    "    # ===== 前処理（1回だけ） =====\n",
    "    # 学習に使わない列を除いた特徴量列を一度だけ確定\n",
    "    drop_cols = [\"date_id\", \"forward_returns\", \"risk_free_rate\", \"market_forward_excess_returns\"]\n",
    "    feature_cols = [c for c in train.columns if c not in drop_cols]\n",
    "\n",
    "    # 必要列を配列/ビューで保持（コピー最小化）\n",
    "    X_all = train[feature_cols]                  # DataFrame（ループ内は iloc でビュー切り）\n",
    "    y_all = train[\"forward_returns\"].to_numpy()  # 1D ndarray\n",
    "    rfr_all = train[\"risk_free_rate\"].to_numpy() # 1D ndarray\n",
    "\n",
    "    # バリデーション（固定で最後180）を一度だけ切り出し\n",
    "    val_idx_start = max(0, n - 180)\n",
    "    X_val = X_all.iloc[val_idx_start:]\n",
    "    y_val = y_all[val_idx_start:]\n",
    "    v_sol = pd.DataFrame(\n",
    "        {\n",
    "            \"forward_returns\": y_all[val_idx_start:],\n",
    "            \"risk_free_rate\":  rfr_all[val_idx_start:],\n",
    "        }\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    for fold, test_start in enumerate(\n",
    "        range(n - test_size, min_train_size, -test_size)\n",
    "    ):\n",
    "        print(Fore.CYAN + f\"=== Fold {fold} Test start at {test_start} ===\" + Style.RESET_ALL)\n",
    "        # 1. データ分割（中間DataFrameを作らず直接切る）\n",
    "        test_end = test_start + test_size\n",
    "\n",
    "        X_train = X_all.iloc[:test_start]\n",
    "        y_train = y_all[:test_start]\n",
    "\n",
    "        X_test = X_all.iloc[test_start:test_end]\n",
    "        y_test = y_all[test_start:test_end]  # 使わないが念のため残す（デバッグ等）\n",
    "        \n",
    "        # 評価用（score用のソリューション; 必要最小限のDF生成）\n",
    "        solution = pd.DataFrame(\n",
    "            {\n",
    "                \"forward_returns\": y_all[test_start:test_end],\n",
    "                \"risk_free_rate\":  rfr_all[test_start:test_end],\n",
    "            }\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "        # 1.5. SIGNALE_MULTIPLIER の最適化\n",
    "        # --- inner validation を train_fold の末尾から作る ---\n",
    "        inner_start = max(0, test_start - inner_val_len)\n",
    "        X_inner = X_all.iloc[inner_start:test_start]\n",
    "        y_inner = y_all[inner_start:test_start]\n",
    "        sol_inner = pd.DataFrame({\n",
    "            \"forward_returns\": y_all[inner_start:test_start],\n",
    "            \"risk_free_rate\":  rfr_all[inner_start:test_start],\n",
    "        }).reset_index(drop=True)\n",
    "\n",
    "        # 2. モデル学習\n",
    "        allocation_model.fit(X_train, y_train)\n",
    "\n",
    "        # 2.5. inner validation で best_m を決定\n",
    "        y_pred_inner = allocation_model.predict(X_inner)\n",
    "        best_m, _ = _best_m_from_inner_val(y_pred_inner, sol_inner)\n",
    "\n",
    "        # 3. 予測\n",
    "        y_pred = allocation_model.predict(X_test)\n",
    "        # allocation_list = np.clip(y_pred, 0, 2)  # 投資比率は0から2の間にクリップ\n",
    "        allocation_list = convert_ret_to_signal(y_pred, ret_signal_params, signal_multiplier=best_m)\n",
    "\n",
    "        # 4. 評価\n",
    "        submission = pd.DataFrame({\"prediction\": allocation_list}).reset_index(drop=True)\n",
    "        validation_score, intermediate_res = score(\n",
    "            solution, submission, \"\", intermediate_res\n",
    "        )\n",
    "\n",
    "        pred_val = allocation_model.predict(X_val)\n",
    "        val_allocation_list = convert_ret_to_signal(pred_val, ret_signal_params, signal_multiplier=best_m)\n",
    "        val_submission = pd.DataFrame({\"prediction\": val_allocation_list}).reset_index(drop=True)\n",
    "        val_score, _ = score(\n",
    "            v_sol, val_submission, \"\", intermediate_res\n",
    "        )\n",
    "        \n",
    "        vol_penalty = intermediate_res[-1][3]   # ボラティリティペナルティ\n",
    "        return_penalty = intermediate_res[-1][4]# リターンペナルティ\n",
    "        \n",
    "        display(HTML(\n",
    "            f\"<p  style='color: orange'>\"\n",
    "            f\"train(:{test_start:4}) test({test_start:4}:{test_end:4})<br>\"\n",
    "            f\"val_score: {validation_score:6.3f} {vol_penalty=:.2f} {return_penalty=:.2f}<br>\"\n",
    "            f\"score(submission) : {val_score}<br>\"\n",
    "            f\"best_multi : {best_m}<br>\"\n",
    "            f\"</p>\"\n",
    "        ))\n",
    "        \n",
    "        oof[test_start:test_end] = allocation_list\n",
    "        score_list.append(validation_score)\n",
    "        val_list.append(val_score)\n",
    "\n",
    "        # 最初のfold modelを保存しておく\n",
    "        # if fold == 0:\n",
    "        #     submit_model = allocation_model\n",
    "        # else :\n",
    "        #     break\n",
    "\n",
    "    # ===== 集計表示 =====\n",
    "    submit_model = allocation_model\n",
    "    display(HTML('<h2 style=\"text-align:center;color:orange\">======== Result ========</h2>'))\n",
    "    avg_validation_score = float(np.nanmean(score_list)) if len(score_list) else np.nan\n",
    "    print(f\"{label} Average Validation Score: {avg_validation_score:.6f}\")\n",
    "\n",
    "    # 全体スコア（インデックス揃え）s\n",
    "    # mask = np.isfinite(oof)\n",
    "    # solution_all = train.loc[mask, ['forward_returns','risk_free_rate']].reset_index(drop=True)\n",
    "    # submission_all = pd.DataFrame({'prediction': oof[mask]}).reset_index(drop=True)\n",
    "    # overall_score, intermediate_res = score(solution_all, submission_all, '', intermediate_res)\n",
    "    # if intermediate_res:\n",
    "    #     vol_penalty = intermediate_res[-1][3]\n",
    "    #     return_penalty = intermediate_res[-1][4]\n",
    "    # else:\n",
    "    #     vol_penalty = return_penalty = np.nan\n",
    "    # print(f\"{label} Overall Validation Score: {overall_score:.6f} vol_penalty={vol_penalty:.2f} return_penalty={return_penalty:.2f}\")\n",
    "\n",
    "    # 全体スコア（インデックス揃え）\n",
    "    mask = np.isfinite(oof)\n",
    "    if np.any(mask):\n",
    "        solution_all = pd.DataFrame(\n",
    "            {\n",
    "                \"forward_returns\": y_all[mask],\n",
    "                \"risk_free_rate\":  rfr_all[mask],\n",
    "            }\n",
    "        ).reset_index(drop=True)\n",
    "        submission_all = pd.DataFrame({'prediction': oof[mask]}).reset_index(drop=True)\n",
    "        overall_score, intermediate_res = score(solution_all, submission_all, '', intermediate_res)\n",
    "        vol_penalty = intermediate_res[-1][3] if intermediate_res else np.nan\n",
    "        return_penalty = intermediate_res[-1][4] if intermediate_res else np.nan\n",
    "        print(f\"{label} Overall Validation Score: {overall_score:.6f} vol_penalty={vol_penalty:.2f} return_penalty={return_penalty:.2f}\")\n",
    "    else:\n",
    "        print(f\"{label} Overall Validation Score: NaN (no valid OOF)\")\n",
    "\n",
    "\n",
    "\n",
    "    score_list_dict[label] = score_list\n",
    "    # 1回目のfoldのスコアを示す\n",
    "    if score_list:\n",
    "        print(f\"{label} First(Test) Fold Validation Score: {score_list[0]:.6f}\")\n",
    "\n",
    "    if val_list:\n",
    "        print(Fore.YELLOW + f\"All(Test) Fold Validation Score : {(sum(val_list) / len(val_list)):6.3f}\" + Style.RESET_ALL)\n",
    "        \n",
    "\n",
    "    # 分布可視化\n",
    "    vals = oof[mask]\n",
    "    if len(vals):\n",
    "        vmin, vmax = float(np.min(vals)), float(np.max(vals))\n",
    "        if vmin == vmax:\n",
    "            vmax = vmin + 1e-6\n",
    "        bins = np.linspace(vmin, vmax, 50)\n",
    "        plt.figure(figsize=(6, 2))\n",
    "        plt.hist(vals, bins=bins, density=False, color='c', edgecolor='k', linewidth=0.5)\n",
    "        plt.title(f'Allocation histogram of {label}')\n",
    "        plt.gca().get_yaxis().set_visible(False)\n",
    "        plt.xlim(vmin, vmax)\n",
    "        plt.show()\n",
    "\n",
    "    print(f\"Range of predictions: [{vmin:.6f}, {vmax:.6f}]\")\n",
    "    \n",
    "    # SIGNAL_MULTIPLIER の算出（元ロジック踏襲）\n",
    "    # ※ oofの分布に依存するため、maskチェックを入れる\n",
    "    if np.any(mask):\n",
    "        span = min(MAX_SIGNAL - 1.0, 1.0 - MIN_SIGNAL)  # 0-2なら span=1.0\n",
    "        q = np.percentile(np.abs(oof[mask]), 99)        # 上位1%に合わせる\n",
    "        SIGNAL_MULTIPLIER = (0.95 * span) / max(q, 1e-12)\n",
    "        print(f\"multi::{SIGNAL_MULTIPLIER}\")\n",
    "    else:\n",
    "        print(\"multi::NaN (no valid OOF)\")\n",
    "    \n",
    "\n",
    "    return submit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a3ca9afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 0 Test start at 8810 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21575\n",
      "[LightGBM] [Info] Number of data points in the train set: 8810, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000468\n",
      "[Inner Optimization] k=0.511, alpha=2.000, score=10.7940\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style='color: orange'>train(:8810) test(8810:8990)<br>val_score:  0.251 vol_penalty=1.63 return_penalty=1.00<br>score(submission) : 0.23915922123392805<br>best_multi : 7418.262552817526<br></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 1 Test start at 8630 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21573\n",
      "[LightGBM] [Info] Number of data points in the train set: 8630, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000460\n",
      "[Inner Optimization] k=1.133, alpha=1.000, score=10.0767\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p  style='color: orange'>train(:8630) test(8630:8810)<br>val_score:  1.070 vol_penalty=1.15 return_penalty=1.38<br>score(submission) : 0.04968569192128337<br>best_multi : 128.73292054538996<br></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Fold 2 Test start at 8450 ===\u001b[0m\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21575\n",
      "[LightGBM] [Info] Number of data points in the train set: 8450, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000453\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 単純なLightGBMモデルで試す\u001b[39;00m\n\u001b[1;32m      3\u001b[0m allocation_model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMRegressor(\n\u001b[1;32m      4\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m      5\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m submit_model \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mallocation_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLightGBM Model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[50], line 74\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(allocation_model, label, min_train_size, test_size)\u001b[0m\n\u001b[1;32m     68\u001b[0m sol_inner \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward_returns\u001b[39m\u001b[38;5;124m\"\u001b[39m: y_all[inner_start:test_start],\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrisk_free_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m:  rfr_all[inner_start:test_start],\n\u001b[1;32m     71\u001b[0m })\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# 2. モデル学習\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m \u001b[43mallocation_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# 2.5. inner validation で best_m を決定\u001b[39;00m\n\u001b[1;32m     77\u001b[0m y_pred_inner \u001b[38;5;241m=\u001b[39m allocation_model\u001b[38;5;241m.\u001b[39mpredict(X_inner)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:1092\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1077\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1089\u001b[0m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLGBMRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1092\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:885\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    882\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    883\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 885\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:276\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    269\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m    270\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    271\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[1;32m    272\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[1;32m    273\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[1;32m    274\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m--> 276\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:3891\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3890\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 3891\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3892\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3895\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 単純なLightGBMモデルで試す\n",
    "\n",
    "allocation_model = lgb.LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "submit_model = cross_validate(allocation_model, label=\"LightGBM Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427c0cc0",
   "metadata": {},
   "source": [
    "### Submissiohn\n",
    "- time-series streaming形式\n",
    "- Kaggle サーバーから1batchずつ送られるデータからsubmission.parquetを返す\n",
    "- 返り値検証があるため，指定された形式で返す\n",
    "- 指定形式\n",
    "  - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218685fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test: pl.DataFrame) -> float:\n",
    "    \"\"\"Replace this function with your inference code.\"\"\"\n",
    "    test_pd = test.to_pandas()\n",
    "    # display(test_pd.info())\n",
    "    if len(test_pd.columns) > 94:\n",
    "        test_pd = test_pd.drop(\n",
    "            [\"date_id\", \"is_scored\", \"lagged_forward_returns\", \"lagged_risk_free_rate\", \"lagged_market_forward_excess_returns\"], \n",
    "            axis = 1)\n",
    "    \n",
    "    preds = submit_model.predict(test_pd)\n",
    "    raw_pred: float = float(preds[0])\n",
    "    print(f\"predict:{raw_pred}\")\n",
    "    \n",
    "    # --- 出力（float or ndarray）---\n",
    "    # KaggleのAPI仕様上、float単体かSeries/DataFrameで返す必要あり float(preds[0]) if len(preds) == 1 else preds　\n",
    "    return convert_ret_to_signal(raw_pred, ret_signal_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b05b6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/templates.py:97: RuntimeWarning: 76891 seconds elapsed before server startup.\n",
      "                This exceeds the startup time limit of 900 seconds that the gateway will enforce\n",
      "                during the rerun on the hidden test set. Start the server before performing any time consuming steps.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "GatewayRuntimeError",
     "evalue": "(<GatewayRuntimeErrorType.GATEWAY_RAISED_EXCEPTION: 5>, 'Traceback (most recent call last):\\n  File \"/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/base_gateway.py\", line 134, in run\\n    predictions, row_ids = self.get_all_predictions()\\n  File \"/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/base_gateway.py\", line 109, in get_all_predictions\\n    for data_batch, row_ids in self.generate_data_batches():\\n  File \"/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/default_gateway.py\", line 29, in generate_data_batches\\n    test = pl.read_csv(self.competition_data_dir / \\'test.csv\\')\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/_utils/deprecation.py\", line 128, in wrapper\\n    return function(*args, **kwargs)\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/_utils/deprecation.py\", line 128, in wrapper\\n    return function(*args, **kwargs)\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/_utils/deprecation.py\", line 128, in wrapper\\n    return function(*args, **kwargs)\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/io/csv/functions.py\", line 549, in read_csv\\n    df = _read_csv_impl(\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/io/csv/functions.py\", line 697, in _read_csv_impl\\n    pydf = PyDataFrame.read_csv(\\nFileNotFoundError: No such file or directory (os error 2): /kaggle/input/hull-tactical-market-prediction/test.csv\\n')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGatewayRuntimeError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     inference_server\u001b[38;5;241m.\u001b[39mserve()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     \u001b[43minference_server\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_local_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/hull-tactical-market-prediction/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/templates.py:110\u001b[0m, in \u001b[0;36mInferenceServer.run_local_gateway\u001b[0;34m(self, data_paths, file_share_dir, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver\u001b[38;5;241m.\u001b[39mstop(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/templates.py:108\u001b[0m, in \u001b[0;36mInferenceServer.run_local_gateway\u001b[0;34m(self, data_paths, file_share_dir, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_gateway_for_test(data_paths, file_share_dir, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/base_gateway.py:153\u001b[0m, in \u001b[0;36mBaseGateway.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_result(error)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# For local testing\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[0;31mGatewayRuntimeError\u001b[0m: (<GatewayRuntimeErrorType.GATEWAY_RAISED_EXCEPTION: 5>, 'Traceback (most recent call last):\\n  File \"/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/base_gateway.py\", line 134, in run\\n    predictions, row_ids = self.get_all_predictions()\\n  File \"/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/core/base_gateway.py\", line 109, in get_all_predictions\\n    for data_batch, row_ids in self.generate_data_batches():\\n  File \"/home/masa1357/Dockerdata/kaggle/Kaggle_Hull-Tactical---Market-Prediction/kaggle_evaluation/default_gateway.py\", line 29, in generate_data_batches\\n    test = pl.read_csv(self.competition_data_dir / \\'test.csv\\')\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/_utils/deprecation.py\", line 128, in wrapper\\n    return function(*args, **kwargs)\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/_utils/deprecation.py\", line 128, in wrapper\\n    return function(*args, **kwargs)\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/_utils/deprecation.py\", line 128, in wrapper\\n    return function(*args, **kwargs)\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/io/csv/functions.py\", line 549, in read_csv\\n    df = _read_csv_impl(\\n  File \"/usr/local/lib/python3.10/dist-packages/polars/io/csv/functions.py\", line 697, in _read_csv_impl\\n    pydf = PyDataFrame.read_csv(\\nFileNotFoundError: No such file or directory (os error 2): /kaggle/input/hull-tactical-market-prediction/test.csv\\n')"
     ]
    }
   ],
   "source": [
    "# サーバー上でpredict(test_batch)を動かす\n",
    "inference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(('/kaggle/input/hull-tactical-market-prediction/',))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
